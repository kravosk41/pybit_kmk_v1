{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4d81d9f-199b-456a-a5a4-e374a3fc16fa",
   "metadata": {},
   "source": [
    "#  Managed Care - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a1e9b5-5472-429e-a5fa-e662f154b904",
   "metadata": {},
   "source": [
    "- TO DO - \n",
    "    - Do Code Review\n",
    "    - Potential Optimizations ? (remove mp prep outsite loop? etc)\n",
    "    - double check imported datasets\n",
    "    - Overall QC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dda1585-f3f7-4cf5-9c64-678e00cff912",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# importing modules\n",
    "import polars as pl\n",
    "import gc\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta,date\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1440ad3-fd57-4930-b02c-efbe139c0e15",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# load variables from JSON\n",
    "with open('vars_wk.json', 'r') as json_file:\n",
    "    js = json.load(json_file)\n",
    "\n",
    "bucket = js['bucket']\n",
    "data_date = js['data_date']\n",
    "monthly_data_date = js['monthly_data_date']\n",
    "QTD = js['QTD']\n",
    "YTD = js['YTD']\n",
    "\n",
    "# data_date = '20240802'\n",
    "# monthly_data_date = '202407'\n",
    "# QTD = 1\n",
    "# YTD = 7 \n",
    "#TODO: CONNECT TO JSON LATER\n",
    "\n",
    "dflib = f's3://{bucket}/BIT/dataframes/'\n",
    "pln = f's3://{bucket}/PYADM/weekly/archive/{data_date}/plantrak/' \n",
    "mpln = f's3://{bucket}/PYADM/monthly/archive/{monthly_data_date}/plantrak/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89615e97-64e1-4aaa-ba59-49eedd188d58",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Utility Functions -\n",
    "def load(df, lib=dflib):\n",
    "    globals()[df] = pl.read_parquet(f'{lib}{df}.parquet')\n",
    "def offload(df, name, lib=dflib, ef = 'NA' ):\n",
    "    file = f'{dflib}mc/{name}.parquet'\n",
    "\n",
    "    if ef == 'NA':\n",
    "        globals()[df].to_pandas().to_parquet(file, index =False)\n",
    "    else:\n",
    "        globals()[df][ef].to_pandas().to_parquet(file, index =False)\n",
    "\n",
    "    print('Exported : ', file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2169c1c-2cbf-471a-8f5c-d25f9a099535",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Imporing Dependencies\n",
    "prod_mapping = pl.read_csv(f's3://{bucket}/BIT/docs/productmapping_pybit.txt',separator='|')\n",
    "geo_code_mapper = pl.from_pandas(pd.read_excel(f's3://{bucket}/BIT/docs/geo_id_full.xlsx'))\n",
    "load('mp_spec_seg_dec')\n",
    "load('MASTER_UNI')\n",
    "fetch_products = ['LI1','LI2','LI3','TRU','AMT','LAC','MOT','LUB','IRL']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3146e33-0840-4437-81ad-8a1ac5357a1f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f4ce45-2c4a-43d6-b830-4945b72f6f26",
   "metadata": {},
   "source": [
    "## Importing Raw Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc709a0-90ba-4a98-9e66-c2056232f11a",
   "metadata": {},
   "source": [
    "### Formulary\n",
    "- _Using Both Weekly and Monthly for payer name list_\n",
    "- _only using Monthly for plan_type and plan_class_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6be19e-aed1-437e-b2e6-ef76b227b340",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Processing Formulary Datasets -\n",
    "columns_to_read = ['IMS_PLAN_ID','GROUP_TYPE','FORMULARY_GROUP_STATUS','PFAM_CD','PFAM_NAME','IRWD_FGN_NAME','BRAND']\n",
    "\n",
    "fm_monthly = pl.read_parquet(\n",
    "    mpln+'FORMULARY.parquet',columns = columns_to_read\n",
    ")\n",
    "\n",
    "fm_weekly = pl.read_parquet(\n",
    "    pln+'FORMULARY.parquet',columns = columns_to_read\n",
    ")\n",
    "\n",
    "# Consolidating list of Unique Payer Names -\n",
    "payer_names = (\n",
    "    fm_monthly.select('IRWD_FGN_NAME')\n",
    "    .vstack(fm_weekly.select('IRWD_FGN_NAME'))\n",
    "    .unique()\n",
    "    .sort('IRWD_FGN_NAME')\n",
    "    .with_row_index(offset=1)\n",
    "    .rename({'index':'payer_id'})\n",
    ")\n",
    "\n",
    "#FORMULARY\n",
    "group_type_mapping = {\n",
    "    'HIX' : 'Commercial','Com' : 'Commercial','Cash' : 'Cash','Voucher':'Voucher',\n",
    "    'FFS' : 'FFS','Mgd Medicaid' : 'Mgd Medicaid','Part D' : 'Part D','MAC A' : 'Others',\n",
    "}\n",
    "\n",
    "def classify_plan_class(status):\n",
    "    status = status.upper()\n",
    "    if status[:7] == \"COVERED\" or status[:6] == \"ON PDL\":\n",
    "        return \"COVERED\"\n",
    "    elif status[:9] == \"PREFERRED\":\n",
    "        return \"PREFERRED\"\n",
    "    elif status[:13] == \"NON-PREFERRED\":\n",
    "        return \"NON PREFERRED\"\n",
    "    elif status[:7] == \"NON-PDL\" or status[:11] == \"NOT COVERED\":\n",
    "        return \"NOT COVERED\"\n",
    "    else:\n",
    "        return \"N_A\"\n",
    "\n",
    "fm = fm_monthly.with_columns(\n",
    "        pl.when(pl.col('BRAND')=='IBR')\n",
    "        .then(pl.lit('IRL'))\n",
    "        .otherwise(pl.col('BRAND'))\n",
    "        .alias('BRAND')\n",
    ")\n",
    "\n",
    "fm = fm.filter((pl.col('PFAM_CD')==(pl.col('BRAND'))) | (pl.col('BRAND')==''))\n",
    "\n",
    "fm = (\n",
    "    fm\n",
    "    .with_columns(\n",
    "        pl.col('GROUP_TYPE').map_elements(lambda x: group_type_mapping.get(x,'Others'), return_dtype=pl.Utf8) #NOTE : IF new plan types flow , they will go to Others by default\n",
    "        .fill_null('Others')\n",
    "        .alias('plan_type'),\n",
    "        pl.col('IMS_PLAN_ID').cast(pl.Int64)\n",
    "    )\n",
    "    .rename({'IMS_PLAN_ID':'PlanID'})\n",
    "    .drop('GROUP_TYPE')\n",
    "    .with_columns(pl.col('FORMULARY_GROUP_STATUS').fill_null(pl.lit('N_A')))\n",
    "    .with_columns(pl.col('FORMULARY_GROUP_STATUS').map_elements(classify_plan_class,return_dtype=pl.String).alias('plan_class'))\n",
    "    .drop('FORMULARY_GROUP_STATUS')\n",
    "    .unique()\n",
    ")\n",
    "\n",
    "###############\n",
    "# HARD CODED - \n",
    "fm = fm.with_columns(pl.when(pl.col(\"PlanID\") == 13670614).then(pl.lit('Others')).otherwise(pl.col(\"plan_type\")).alias(\"plan_type\"))\n",
    "###############\n",
    "fm2 = (\n",
    "    fm\n",
    "    .select('PFAM_CD','IRWD_FGN_NAME','plan_class').unique()\n",
    "    .group_by(['IRWD_FGN_NAME','PFAM_CD'])\n",
    "    .agg(\n",
    "        pl.col('plan_class').unique().str.concat(' / ').alias('plan_class')\n",
    "    )\n",
    "    .with_columns(pl.col('plan_class').str.to_titlecase())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbd7b9e-93f4-4ce3-a708-42f5908b640f",
   "metadata": {},
   "source": [
    "### Plantrak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1eebce-22a0-4521-9816-9c05dee6ea75",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Import and prepare Raw data - # INPUT : Adm Files # OUTPUT : ln\n",
    "ln = (\n",
    "    pl.read_parquet(mpln+'LAX_N.parquet',columns=['IID','MonthKey','PFAM_CD','PROD_CD','PlanID','TUF','TRX','TUN']) \n",
    "    .rename({'MonthKey':'PeriodKey'})\n",
    "    .filter(pl.col('PROD_CD').is_in(fetch_products)) #only keep data for BIT products\n",
    "    .with_columns(pl.col('PeriodKey').cast(pl.Utf8).str.to_date(\"%Y%m%d\")) #Convert Categorical column Back to date\n",
    ")\n",
    "date_list = ln['PeriodKey'].unique().sort(descending=True)\n",
    "\n",
    "# Any PlanIds startign with -0000002 should be excluded\n",
    "ln = (\n",
    "    ln\n",
    "    .with_columns(pl.col('PlanID').cast(pl.Utf8).str.zfill(10).alias('planid_chr'))\n",
    "    .filter(~pl.col('planid_chr').str.starts_with('000002'))\n",
    "    .drop('planid_chr')\n",
    ")\n",
    "\n",
    "ln = ln.join(\n",
    "    (pl.DataFrame(date_list).with_row_index(offset = 1).rename({'index':'num_month'})),\n",
    "    on = 'PeriodKey', how = 'left'\n",
    ")\n",
    "\n",
    "ln = (\n",
    "    ln\n",
    "    .join(fm.select(['PlanID','IRWD_FGN_NAME']).unique(),on='PlanID',how='left')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b41b99-0241-407d-b039-220a251bb581",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# GENETATOR FUNCTION FOR DATACUTS  # INPUT : ln # OUTPUT : ln1\n",
    "\n",
    "#helper dict object - \n",
    "filter_cond_dict = {\n",
    "    '1c' : pl.col('num_month')==1,'1p' : pl.col('num_month')==2,\n",
    "    '3c' : pl.col('num_month').is_in([1,2,3]),'3p' : pl.col('num_month').is_in([4,5,6]),\n",
    "    '6c' : pl.col('num_month').is_in([1,2,3,4,5,6]),'6p' : pl.col('num_month').is_in([7,8,9,10,11,12]),\n",
    "    '12c' : pl.col('num_month').is_in([i for i in range(1,13)]),'12p' : pl.col('num_month').is_in([i for i in range(13,25)]),\n",
    "    'qtdc' : pl.col('num_month').is_in([i for i in range(1,QTD+1)]),'qtdp' : pl.col('num_month').is_in([i for i in range(4,4+QTD)]),\n",
    "    'ytdc' : pl.col('num_month').is_in([i for i in range(1,YTD+1)]),'ytdp' : pl.col('num_month').is_in([i for i in range(13,13+YTD)])\n",
    "}\n",
    "\n",
    "def get_data_cuts(df,fl):\n",
    "    result = pl.DataFrame()\n",
    "    for period,cond in filter_cond_dict.items():\n",
    "        df_filter = df.filter(cond)\n",
    "        df_filter = (\n",
    "            df_filter\n",
    "            .group_by(['IID','IRWD_FGN_NAME','PFAM_CD','PROD_CD'])\n",
    "            .agg(\n",
    "                pl.col('TUF').sum().alias(f'TUF_{period}'),\n",
    "                pl.col('TRX').sum().alias(f'TRX_{period}'),\n",
    "                pl.col('TUN').sum().alias(f'TUN_{period}')\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if period == '1c':\n",
    "            result = df_filter\n",
    "        else:\n",
    "            result = result.join(df_filter,on =['IID','IRWD_FGN_NAME','PFAM_CD','PROD_CD'],how = 'outer_coalesce')\n",
    "\n",
    "    # Pulling in Plan Type -\n",
    "    result = (\n",
    "        result\n",
    "        .join(\n",
    "            fm.select(['IRWD_FGN_NAME','PFAM_CD','plan_type']).unique(),\n",
    "            on = ['IRWD_FGN_NAME', 'PFAM_CD'], how = 'left'\n",
    "        )\n",
    "        .with_columns(\n",
    "            pl.col('plan_type').fill_null(pl.lit('Others')),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Pulling in Plan Class\n",
    "    result = (\n",
    "        result.join(fm2, on=['IRWD_FGN_NAME', 'PFAM_CD'], how='left')\n",
    "        .with_columns(\n",
    "            pl.col('plan_class').fill_null(pl.lit('N_a'))\n",
    "        )\n",
    "    )\n",
    "    if fl == 1:\n",
    "        # Dropping Records with Voucher , FFS , Medicaid\n",
    "        result = result.filter(\n",
    "            ~(pl.col('plan_type').is_in(['Voucher','Mgd Medicaid','FFS']))\n",
    "        )\n",
    "\n",
    "    #Joining Payer ID-\n",
    "    result = result.join(payer_names, on ='IRWD_FGN_NAME', how = 'left')\n",
    "\n",
    "    # adding product_id\n",
    "    result = (\n",
    "        result\n",
    "        .join(\n",
    "            prod_mapping.select(['code','product_id','parent_product_id']),\n",
    "            left_on = 'PROD_CD', right_on='code', how = 'left'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return (result)\n",
    "\n",
    "ln1 = get_data_cuts(ln,1)\n",
    "ln1_pmix = get_data_cuts(ln,0) #this will have medicad ffs and voucher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62b32da-7771-4a89-ae73-f94faa570b54",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Adding Parent Product Rows - # INPUT ln1 # OUTPUT : ln2\n",
    "data_cut_list = [f'TUF_{p}' for p in filter_cond_dict.keys()] + [f'TRX_{p}' for p in filter_cond_dict.keys()] + [f'TUN_{p}' for p in filter_cond_dict.keys()]\n",
    "def get_parent_rows(ln1):\n",
    "    prod_agg_expn_list = {\n",
    "        col : pl.col(col).sum() for col in data_cut_list\n",
    "    }\n",
    "    prod_agg_expn_list.update({'plan_type':pl.col('plan_type').first()})\n",
    "    \n",
    "    #lin and amt-\n",
    "    \n",
    "    ln1_235 = (\n",
    "        ln1\n",
    "        .filter(pl.col('parent_product_id').is_in([2,35]))\n",
    "        .group_by(['IID','IRWD_FGN_NAME','payer_id','parent_product_id'])\n",
    "        .agg(\n",
    "            **{**prod_agg_expn_list,'plan_class':pl.col('plan_class').first()}\n",
    "        )\n",
    "        .rename({'parent_product_id':'product_id'})\n",
    "    )\n",
    "    \n",
    "    \n",
    "    #for lax mkt - \n",
    "    ln1_1 = (\n",
    "        ln1\n",
    "        .group_by(['IID','IRWD_FGN_NAME','payer_id'])\n",
    "        .agg(**prod_agg_expn_list)\n",
    "        .with_columns(pl.lit(1).alias('product_id').cast(pl.Int64),pl.lit('N_a').alias('plan_class'))\n",
    "        .select(ln1_235.columns)\n",
    "    )\n",
    "    \n",
    "    ln2 = (\n",
    "        ln1.select(ln1_235.columns)\n",
    "        .vstack(ln1_235)\n",
    "        .vstack(ln1_1)\n",
    "    )\n",
    "    \n",
    "    # Adding Geography Information and Removing Plans not present in Formulary & any White Space HCPs-\n",
    "    ln2 = (\n",
    "        ln2\n",
    "        .join(mp_spec_seg_dec[['IID','geography_id']],on='IID',how='left')\n",
    "        .join(geo_code_mapper,on = 'geography_id', how = 'left')\n",
    "        .filter(pl.col('payer_id').is_not_null())\n",
    "        .filter(pl.col('geography_id').is_not_null()) \n",
    "        .fill_null(0.0) # Filling Nulls inside Data Cuts for Consistency.\n",
    "    \n",
    "        # DTYPE FIXES \n",
    "        .with_columns(\n",
    "            pl.col('IID').cast(pl.Int64),\n",
    "            pl.col('payer_id').cast(pl.Int64),\n",
    "            pl.col('geography_id').cast(pl.Int64),\n",
    "            pl.col('region_geography_id').cast(pl.Int64),\n",
    "            pl.col('area_geography_id').cast(pl.Int64),\n",
    "            pl.col('nation_geography_id').cast(pl.Int64),\n",
    "        )\n",
    "    )\n",
    "    return (ln2)\n",
    "    \n",
    "ln2 = get_parent_rows(ln1)\n",
    "ln2_pmix = get_parent_rows(ln1_pmix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9a4d3c-ee8f-4fe3-961a-73a0d3791861",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Generator Function for datacuts : #Input :  ln #Output : ln1_planid\n",
    "def get_data_cuts_planid(df):\n",
    "    result = pl.DataFrame()\n",
    "    for period,cond in filter_cond_dict.items():\n",
    "        df_filter = df.filter(cond)\n",
    "        df_filter = (df_filter.group_by(['IID','PlanID','PFAM_CD','PROD_CD']).agg(pl.col('TUF').sum().alias(f'TUF_{period}')))\n",
    "        if period == '1c':\n",
    "            result = df_filter\n",
    "        else:\n",
    "            result = result.join(df_filter,on =['IID','PlanID','PFAM_CD','PROD_CD'],how = 'outer_coalesce')\n",
    "\n",
    "    result = (\n",
    "        result\n",
    "        # Pulling Payer Name\n",
    "        #.join(fm.select(['PlanID','IRWD_FGN_NAME']).unique(),on='PlanID',how='left') \n",
    "        # dropping PlanIDs not present in Formulary\n",
    "        #.filter(pl.col('IRWD_FGN_NAME').is_not_null())\n",
    "        # Pulling Plan Type\n",
    "        .join(fm.select(['PlanID','PFAM_CD','plan_type']).unique(),on = ['PlanID', 'PFAM_CD'], how = 'left') \n",
    "        #.with_columns(pl.col('plan_type').fill_null(pl.lit('Others')))\n",
    "        .filter(pl.col('plan_type').is_not_null())\n",
    "        #Pulling Plan Class\n",
    "        .join(fm[['PlanID','PFAM_CD','plan_class']], on=['PlanID', 'PFAM_CD'], how='left') \n",
    "        #.with_columns(pl.col('plan_class').fill_null(pl.lit('N_a')))\n",
    "        # Dropping Records with Voucher , FFS , Medicaid\n",
    "        .filter(~(pl.col('plan_type').is_in(['Voucher','Mgd Medicaid','FFS'])))\n",
    "        #Joining Payer ID-\n",
    "        #.join(payer_names, on ='IRWD_FGN_NAME', how = 'left')\n",
    "        # adding product_id\n",
    "        .join(prod_mapping.select(['code','product_id','parent_product_id']),left_on = 'PROD_CD', right_on='code', how = 'left')\n",
    "    )\n",
    "    return (result)\n",
    "\n",
    "ln1_planid = get_data_cuts_planid(ln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a7679e-ba14-425c-a665-d3ee435f9499",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Adding Parent Product Rows - # INPUT ln1_planid # OUTPUT : ln2_planid\n",
    "prod_agg_expn_list = {\n",
    "    col : pl.col(col).sum() for col in data_cut_list[0:12]\n",
    "}\n",
    "\n",
    "ln2_planid = ln1_planid.drop(['PFAM_CD','PROD_CD','plan_type'])\n",
    "\n",
    "#lin and amt-\n",
    "ln2_planid_2_35 = (\n",
    "    ln2_planid\n",
    "    .filter(pl.col('parent_product_id').is_in([2,35]))\n",
    "    .group_by(['IID','PlanID','parent_product_id','plan_class'])\n",
    "    .agg(**prod_agg_expn_list)\n",
    "    .rename({'parent_product_id':'product_id'})\n",
    ")\n",
    "\n",
    "#for lax mkt - \n",
    "ln2_planid_1 = (\n",
    "    ln2_planid\n",
    "    .group_by(['IID','PlanID','plan_class'])\n",
    "    .agg(**prod_agg_expn_list)\n",
    "    .with_columns(pl.lit(1).alias('product_id').cast(pl.Int64))\n",
    ")\n",
    "\n",
    "ln2_planid = (\n",
    "    ln2_planid.select(ln2_planid_2_35.columns)\n",
    "    .vstack(ln2_planid_2_35)\n",
    "    .vstack(ln2_planid_1.select(ln2_planid_2_35.columns))\n",
    ")\n",
    "\n",
    "#Adding Columns -\n",
    "ln2_planid = (\n",
    "    ln2_planid\n",
    "    # Adding Geography Information\n",
    "    .join(mp_spec_seg_dec[['IID','geography_id']],on='IID',how='left')\n",
    "    .join(geo_code_mapper,on = 'geography_id', how = 'left')\n",
    "    # Pulling Payer Name\n",
    "    .join(fm.select(['PlanID','IRWD_FGN_NAME']).unique(),on='PlanID',how='left')\n",
    "    # Plan_Type\n",
    "    .join(fm.select(['PlanID','plan_type']).unique(), on ='PlanID',how='left')\n",
    "    #Joining Payer ID-\n",
    "    .join(payer_names, on ='IRWD_FGN_NAME', how = 'left')\n",
    "    # Removing Whitespace HCPs - \n",
    "    .filter(pl.col('geography_id').is_not_null()) \n",
    "    .fill_null(0.0) # Filling Nulls inside Data Cuts for Consistency.\n",
    "\n",
    "    # DTYPE FIXES \n",
    "    .with_columns(\n",
    "        pl.col('IID').cast(pl.Int64),\n",
    "        pl.col('PlanID').cast(pl.Int64),\n",
    "        pl.col('payer_id').cast(pl.Int64),\n",
    "        pl.col('geography_id').cast(pl.Int64),\n",
    "        pl.col('region_geography_id').cast(pl.Int64),\n",
    "        pl.col('area_geography_id').cast(pl.Int64),\n",
    "        pl.col('nation_geography_id').cast(pl.Int64),\n",
    "    )\n",
    "\n",
    "    # Sequence -\n",
    "    .select(\n",
    "        ['IID','PlanID','product_id','plan_class','plan_type','payer_id','IRWD_FGN_NAME','geography_id','region_geography_id','area_geography_id','nation_geography_id'] + data_cut_list[0:12]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05587729-c467-4b80-9fdc-63da7c2755b4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# FOR MEMORY CONSERVATION \n",
    "del ln\n",
    "del ln1\n",
    "del ln1_pmix\n",
    "\n",
    "# offload('ln2','ln2')\n",
    "# offload('ln2_planid','ln2_planid')\n",
    "\n",
    "# for i in range(4):\n",
    "#     offload('top_payers',f'top_payers_{i}',ef=i)\n",
    "#     offload('top_hcps',f'top_hcps_{i}',ef=i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed17a2c-c8ea-4684-bf33-15d7e6880732",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fbb06f-f57f-4534-85f7-3d5a663b4ba8",
   "metadata": {},
   "source": [
    "## Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbd166c-4a9e-49bb-9a0e-be3bafdfe6f6",
   "metadata": {},
   "source": [
    "1. top_plans  - For a given Geography ID and given Payer Type : Top 10 Payer IDs [Based on IBSC 6m Volume]\n",
    "2. top_hcps - For a given payer Top 30 HCPs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ac6af4-3ca6-4549-9719-b916dd13ec70",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Top 10 Payers For a Given Geography and PlanType -> #INPUT : ln2 # OUTPUT : top_payers\n",
    "\n",
    "levels = ['geography_id','region_geography_id','area_geography_id','nation_geography_id']\n",
    "def get_top_payers(ln2,g):\n",
    "\n",
    "    ln2 = ln2.filter(product_id = 1) # Only Keeping IBSC Market Volume.\n",
    "    \n",
    "    df = (\n",
    "        ln2\n",
    "        .group_by([g,'plan_type','payer_id'])\n",
    "        .agg(TUF = pl.col('TUF_6c').sum())\n",
    "        .with_columns(\n",
    "            pl.col('TUF')\n",
    "            .rank(\"ordinal\",descending=True)\n",
    "            .over([g,'plan_type'])\n",
    "            .alias(\"rank\")\n",
    "        )\n",
    "        .filter(pl.col('rank') <= 10)\n",
    "    )\n",
    "    \n",
    "    df_total = (\n",
    "        ln2\n",
    "        .group_by([g,'payer_id'])\n",
    "        .agg(TUF = pl.col('TUF_6c').sum())\n",
    "        .with_columns(plan_type = pl.lit('Total'))\n",
    "        .with_columns(\n",
    "            pl.col('TUF')\n",
    "            .rank(\"ordinal\",descending=True)\n",
    "            .over([g,'plan_type'])\n",
    "            .alias(\"rank\")\n",
    "        )\n",
    "        .filter(pl.col('rank') <= 10)\n",
    "        .select(df.columns)\n",
    "    )\n",
    "    \n",
    "    df_pdc = (\n",
    "        ln2\n",
    "        .filter(pl.col('plan_type').is_in(['Part D', 'Commercial']))\n",
    "        .group_by([g,'payer_id'])\n",
    "        .agg(TUF = pl.col('TUF_6c').sum())\n",
    "        .with_columns(plan_type = pl.lit('Part D and Commercial'))\n",
    "        .with_columns(\n",
    "            pl.col('TUF')\n",
    "            .rank(\"ordinal\",descending=True)\n",
    "            .over([g,'plan_type'])\n",
    "            .alias(\"rank\")\n",
    "        )\n",
    "        .filter(pl.col('rank') <= 20)\n",
    "        .select(df.columns)\n",
    "    )\n",
    "    \n",
    "    df = df.vstack(df_total).vstack(df_pdc).sort(by = [g,'plan_type','rank']).drop(['TUF','rank'])\n",
    "    \n",
    "    return (df)\n",
    "\n",
    "# Consolidating results for all Geography Levels - \n",
    "top_payers = [ \n",
    "    get_top_payers(ln2,levels[0]),\n",
    "    get_top_payers(ln2,levels[1]),\n",
    "    get_top_payers(ln2,levels[2]),\n",
    "    get_top_payers(ln2,levels[3])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df52160-a239-43b0-a883-c274896899ba",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Top 30 HCPs For a Given Geography and PlanType and Payer_ID -> #INPUT : ln2 # OUTPUT : top_hcps | needs top_payers to be in memory\n",
    "def get_top_hcps(ln2,g,i):\n",
    "    \n",
    "    # Pick Up LN2 - >\n",
    "    ln2 = (\n",
    "        ln2\n",
    "        .filter(product_id = 1)\n",
    "        .with_columns(\n",
    "            pl.lit('Total').alias('plan_type_group1'),\n",
    "            pl.when(pl.col('plan_type').is_in(['Part D', 'Commercial'])).then(pl.lit('Part D and Commercial')).otherwise(None).alias('plan_type_group2')\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Join LN2 with top_payers to limit dataset\n",
    "    ln2_filter = (\n",
    "        ln2.join(top_payers[i],on = [g,'plan_type','payer_id'],how = 'inner')\n",
    "    )\n",
    "    \n",
    "    ln2_filter_t = (\n",
    "        ln2.join(\n",
    "            top_payers[i],\n",
    "            left_on = [g,'plan_type_group1','payer_id'],\n",
    "            right_on = [g,'plan_type','payer_id'],how = 'inner'\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    ln2_filter_pdc = (\n",
    "        ln2.join(\n",
    "            top_payers[i],\n",
    "            left_on = [g,'plan_type_group2','payer_id'],\n",
    "            right_on = [g,'plan_type','payer_id'],how = 'inner'\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Top 30 HCPs -\n",
    "    df = (\n",
    "        ln2_filter\n",
    "        .group_by([g,'plan_type','payer_id','IID'])\n",
    "        .agg(TUF = pl.col('TUF_6c').sum())\n",
    "        .with_columns(pl.col('TUF').rank(\"ordinal\",descending=True).over([g,'plan_type','payer_id']).alias(\"rank\"))\n",
    "        .filter(pl.col('rank') <= 30)\n",
    "    )\n",
    "    \n",
    "    df_total = (\n",
    "        ln2_filter_t\n",
    "        .group_by([g,'plan_type_group1','payer_id','IID'])\n",
    "        .agg(TUF = pl.col('TUF_6c').sum())\n",
    "        .with_columns(pl.col('TUF').rank(\"ordinal\",descending=True).over([g,'plan_type_group1','payer_id']).alias(\"rank\"))\n",
    "        .filter(pl.col('rank') <= 30)\n",
    "        .rename({'plan_type_group1':'plan_type'})\n",
    "    )\n",
    "    \n",
    "    df_pdc = (\n",
    "        ln2_filter_pdc\n",
    "        .group_by([g,'plan_type_group2','payer_id','IID'])\n",
    "        .agg(TUF = pl.col('TUF_6c').sum())\n",
    "        .with_columns(pl.col('TUF').rank(\"ordinal\",descending=True).over([g,'plan_type_group2','payer_id']).alias(\"rank\"))\n",
    "        .filter(pl.col('rank') <= 30)\n",
    "        .rename({'plan_type_group2':'plan_type'})\n",
    "    )\n",
    "    \n",
    "    df = (\n",
    "        df\n",
    "        .vstack(df_total)\n",
    "        .vstack(df_pdc)\n",
    "        .sort(by = [g,'plan_type','payer_id','rank'])\n",
    "        .drop(['TUF','rank'])\n",
    "    )\n",
    "    \n",
    "    return (df)\n",
    "\n",
    "def get_top_hcps_total(df,g):\n",
    "    df = (\n",
    "        df\n",
    "        .filter(product_id = 1)\n",
    "        .with_columns(\n",
    "            pl.lit('Total').alias('plan_type_group1'),\n",
    "            pl.when(pl.col('plan_type').is_in(['Part D', 'Commercial'])).then(pl.lit('Part D and Commercial')).otherwise(None).alias('plan_type_group2')\n",
    "        )\n",
    "    )\n",
    "    df1 = (\n",
    "        df\n",
    "        .group_by([g,'plan_type','IID']).agg(TUF = pl.col('TUF_6c').sum())\n",
    "        .with_columns(pl.col('TUF').rank(\"ordinal\",descending=True).over([g,'plan_type']).alias(\"rank\"))\n",
    "        .filter(pl.col('rank') <= 30)\n",
    "    )\n",
    "    df1_total = (\n",
    "        df\n",
    "        .group_by([g,'plan_type_group1','IID']).agg(TUF = pl.col('TUF_6c').sum())\n",
    "        .with_columns(pl.col('TUF').rank(\"ordinal\",descending=True).over([g,'plan_type_group1']).alias(\"rank\"))\n",
    "        .filter(pl.col('rank') <= 30)\n",
    "        .rename({'plan_type_group1':'plan_type'})\n",
    "    )\n",
    "    df1_pdc = (\n",
    "        df\n",
    "        .filter(pl.col('plan_type_group2').is_not_null())\n",
    "        .group_by([g,'plan_type_group2','IID']).agg(TUF = pl.col('TUF_6c').sum())\n",
    "        .with_columns(pl.col('TUF').rank(\"ordinal\",descending=True).over([g,'plan_type_group2']).alias(\"rank\"))\n",
    "        .filter(pl.col('rank') <= 30)\n",
    "        .rename({'plan_type_group2':'plan_type'})\n",
    "    )\n",
    "    df1 = (\n",
    "        df1\n",
    "        .vstack(df1_total)\n",
    "        .vstack(df1_pdc)\n",
    "        .sort(by = [g,'plan_type','rank'])\n",
    "        .drop(['TUF','rank'])\n",
    "        .with_columns(pl.lit(-1).cast(pl.Int64).alias('payer_id')) # Setting this to -1 instaed of 'Total' , cannot vstack without it , str wont match with payer_id of other dataset.\n",
    "        .select([g,'plan_type','payer_id','IID'])\n",
    "    )\n",
    "    return (df1)\n",
    "\n",
    "top_hcps = [\n",
    "    get_top_hcps(ln2,levels[0],0).vstack(get_top_hcps_total(ln2,levels[0])),\n",
    "    get_top_hcps(ln2,levels[1],1).vstack(get_top_hcps_total(ln2,levels[1])),\n",
    "    get_top_hcps(ln2,levels[2],2).vstack(get_top_hcps_total(ln2,levels[2])),\n",
    "    get_top_hcps(ln2,levels[3],3).vstack(get_top_hcps_total(ln2,levels[3]))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99439ed4-d678-41f2-9fc7-086a66cb3433",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#adding columns to facilitate filter joins \n",
    "ln2 = (\n",
    "    ln2\n",
    "    .with_columns(\n",
    "        pl.lit('Total').alias('plan_type_group1'),\n",
    "        pl.when(pl.col('plan_type').is_in(['Part D', 'Commercial'])).then(pl.lit('Part D and Commercial')).otherwise(None).alias('plan_type_group2')\n",
    "    )\n",
    ")\n",
    "\n",
    "ln2_planid = (\n",
    "    ln2_planid\n",
    "    .with_columns(\n",
    "        pl.lit('Total').alias('plan_type_group1'),\n",
    "        pl.when(pl.col('plan_type').is_in(['Part D', 'Commercial'])).then(pl.lit('Part D and Commercial')).otherwise(None).alias('plan_type_group2')\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b1d956-e62c-4e35-8c7e-f24b919f0b82",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Storing data for re-use in MC -2 \n",
    "[offload('top_hcps',f'top_hcps_{i}',ef = i) for i in range(4)]\n",
    "[offload('top_payers',f'top_payers_{i}',ef = i) for i in range(4)]\n",
    "print('Top Payers and Plans Exported !')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c667e7e-51c3-4894-b9ec-9888221e154c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745e2579-6f34-4e3c-b84e-6d9e9ea1dfa9",
   "metadata": {},
   "source": [
    "First Drill-down functions -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a6c0de-e09e-4e2c-8b45-5cba7f05c054",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# cur_vol , pri_vol , vol_change, prc_vol_growth, vol_change_ind, cur_trx, cur_tun\n",
    "def process_1():\n",
    "    res = []\n",
    "    for i in range(4):\n",
    "        g = levels[i]\n",
    "        source_df = (\n",
    "            ln2\n",
    "            .select([g,'plan_type','plan_type_group1','plan_type_group2','payer_id','product_id',f'TUF{period}c',f'TUF{period}p',f'TRX{period}c',f'TUN{period}c'])\n",
    "            .rename({f'TUF{period}c':'cur_vol',f'TUF{period}p':'pri_vol',f'TRX{period}c':'cur_trx',f'TUN{period}c':'cur_tun'})\n",
    "        )\n",
    "        agg_expn = {\n",
    "\t\t\t'cur_vol':pl.col('cur_vol').sum(),'pri_vol':pl.col('pri_vol').sum(),\n",
    "\t\t\t'cur_trx':pl.col('cur_trx').sum(),'cur_tun':pl.col('cur_tun').sum()\n",
    "\t\t}\n",
    "        df = (source_df.group_by([g,'plan_type','product_id']).agg(**agg_expn))\n",
    "        df_t = (source_df.group_by([g,'plan_type_group1','product_id']).agg(**agg_expn).rename({'plan_type_group1' : 'plan_type'}).select(df.columns))\n",
    "        df_pdc = (\n",
    "            source_df.filter(pl.col('plan_type_group2').is_not_null()).group_by([g,'plan_type_group2','product_id'])\n",
    "            .agg(**agg_expn).rename({'plan_type_group2' : 'plan_type'}).select(df.columns)\n",
    "        )\n",
    "        df = df.vstack(df_t).vstack(df_pdc)\n",
    "\n",
    "        df = (\n",
    "            df\n",
    "            .with_columns(\n",
    "                vol_change = pl.col('cur_vol') - pl.col('pri_vol'),\n",
    "                prc_vol_growth = ((pl.col('cur_vol')/pl.col('pri_vol'))-1).replace([np.inf,np.nan],[None,None]),\n",
    "                avg_trx_size = (pl.col('cur_tun')/pl.col('cur_trx')).replace([np.inf,np.nan],[None,None])\n",
    "            )\n",
    "            .with_columns(\n",
    "                pl.when(pl.col('vol_change')/pl.col('pri_vol') > 0.02).then(pl.lit('P'))\n",
    "                .when(pl.col('vol_change')/pl.col('pri_vol') < -0.02).then(pl.lit('Q'))\n",
    "                .when(pl.col('vol_change')==0).then(None)\n",
    "                .otherwise(None).alias('vol_change_ind')\n",
    "            )\n",
    "            .drop(['cur_trx','cur_tun'])\n",
    "        )\n",
    "        res.append(df)\n",
    "    return (res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149dde91-4086-4112-91e5-b65abddfc14c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# sales_dist\n",
    "def process_2(df):\n",
    "    for i in range(4):\n",
    "        g = levels[i]\n",
    "        f = df[i]\n",
    "        f_total = (\n",
    "            f\n",
    "            .filter(pl.col('plan_type')=='Total').select([g,'product_id','cur_vol'])\n",
    "            .rename({'cur_vol':'Total_cur_vol'})\n",
    "        )\n",
    "        f = (\n",
    "            f\n",
    "            .join(f_total,on = [g,'product_id'],how='left')\n",
    "            .with_columns((pl.col('cur_vol')/pl.col('Total_cur_vol')).replace(np.nan,0).alias('sales_dist'))\n",
    "            .drop('Total_cur_vol')\n",
    "        )\n",
    "        df[i] = f\n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d32044-5b6e-4228-93a3-638029827b6c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# sales_dist_bnch\n",
    "def process_3(df):\n",
    "    for i in range(4):\n",
    "        g = levels[i]\n",
    "        f = df[i]\n",
    "        if i != 3:\n",
    "            f_parent = (\n",
    "                df[i+1]\n",
    "                .select([levels[i+1],'plan_type','product_id','sales_dist'])\n",
    "                .rename({'sales_dist':'sales_dist_bnch'})\n",
    "            )\n",
    "            f = (\n",
    "                f\n",
    "                .join(geo_code_mapper.select(levels[i],levels[i+1]).unique(),on = g , how='left')\n",
    "                .join(f_parent, on = [levels[i+1],'plan_type','product_id'],how = 'left')\n",
    "                .drop(levels[i+1])\n",
    "            )\n",
    "        else:\n",
    "            f = (\n",
    "                f\n",
    "                .with_columns(sales_dist_bnch = pl.col('sales_dist'))\n",
    "            )\n",
    "        df[i] = f\n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0089be28-166c-4ab4-b562-c7b3a0af8e1b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# prc_vol_growth_bnch\n",
    "def process_4(df):\n",
    "    for i in range(4):\n",
    "        g = levels[i]\n",
    "        f = df[i]\n",
    "        # for terr ->\n",
    "        f_region = (\n",
    "            df[1].select([levels[1],'plan_type','product_id','prc_vol_growth']).rename({'prc_vol_growth':'prc_vol_growth_bnch'})\n",
    "        )\n",
    "        # for Region, Area ->\n",
    "        f_nation = (\n",
    "            df[3].select([levels[3],'plan_type','product_id','prc_vol_growth']).rename({'prc_vol_growth':'prc_vol_growth_bnch'})\n",
    "        )\n",
    "\n",
    "        if i == 0:\n",
    "            f = (\n",
    "                f\n",
    "                .join(geo_code_mapper.select(levels[i],levels[i+1]).unique(),on = g , how='left')\n",
    "                .join(f_region, on = [levels[i+1],'plan_type','product_id'],how = 'left')\n",
    "                .drop(levels[i+1])\n",
    "            )\n",
    "        elif (( i==1 ) | (i ==2)):\n",
    "            f = (\n",
    "                f\n",
    "                .join(geo_code_mapper.select(levels[i],levels[3]).unique(),on = g , how='left')\n",
    "                .join(f_nation, on = [levels[3],'plan_type','product_id'],how = 'left')\n",
    "                .drop(levels[3])\n",
    "            )\n",
    "        else:\n",
    "            f = (\n",
    "                f\n",
    "                .with_columns(prc_vol_growth_bnch = pl.col('prc_vol_growth'))\n",
    "            )\n",
    "        df[i] = f\n",
    "\n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbe0174-4ca2-4a5f-b5b4-e2cd714b231c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# cur_shr, pri_shr, shr_change, prc_shr_growth, shr_change_ind\n",
    "def process_5(df):\n",
    "    for i in range(4):\n",
    "        g = levels[i]\n",
    "        f = df[i]\n",
    "        f_ibsc = (\n",
    "            f\n",
    "            .filter(product_id = 1)\n",
    "            .select([g,'plan_type','cur_vol','pri_vol'])\n",
    "            .rename({'cur_vol':'lax_cur_vol','pri_vol':'lax_pri_vol'})\n",
    "        )\n",
    "        f = (\n",
    "            f\n",
    "            .join(f_ibsc,on = [g,'plan_type'],how = 'left')\n",
    "            .with_columns(\n",
    "                (pl.col('cur_vol') / pl.col('lax_cur_vol')).alias('cur_shr'),\n",
    "                (pl.col('pri_vol') / pl.col('lax_pri_vol')).alias('pri_shr')\n",
    "            )\n",
    "            .with_columns(\n",
    "                shr_change = pl.col('cur_shr') - pl.col('pri_shr'),\n",
    "                prc_shr_growth = ((pl.col('cur_shr')/pl.col('pri_shr'))-1).replace([np.inf,np.nan],[None,None])\n",
    "            )\n",
    "            .with_columns(\n",
    "                pl.when(pl.col('shr_change')/pl.col('pri_shr') > 0.02).then(pl.lit('P'))\n",
    "                .when(pl.col('shr_change')/pl.col('pri_shr') < -0.02).then(pl.lit('Q'))\n",
    "                .when(pl.col('shr_change')==0).then(None)\n",
    "                .otherwise(None).alias('shr_change_ind')\n",
    "            )\n",
    "            .drop(['lax_cur_vol','lax_pri_vol'])\n",
    "        )\n",
    "        df[i] = f\n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca107054-6272-457a-b4ca-54ea3d7ecac7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# prc_shr_growth_bnch\n",
    "def process_6(df):\n",
    "    for i in range(4):\n",
    "        g = levels[i]\n",
    "        f = df[i]\n",
    "        # for terr ->\n",
    "        f_region = (\n",
    "            df[1].select([levels[1],'plan_type','product_id','prc_shr_growth']).rename({'prc_shr_growth':'prc_shr_growth_bnch'})\n",
    "        )\n",
    "        # for Region, Area ->\n",
    "        f_nation = (\n",
    "            df[3].select([levels[3],'plan_type','product_id','prc_shr_growth']).rename({'prc_shr_growth':'prc_shr_growth_bnch'})\n",
    "        )\n",
    "\n",
    "        if i == 0:\n",
    "            f = (\n",
    "                f\n",
    "                .join(geo_code_mapper.select(levels[i],levels[i+1]).unique(),on = g , how='left')\n",
    "                .join(f_region, on = [levels[i+1],'plan_type','product_id'],how = 'left')\n",
    "                .drop(levels[i+1])\n",
    "            )\n",
    "        elif (( i==1 ) | (i ==2)):\n",
    "            f = (\n",
    "                f\n",
    "                .join(geo_code_mapper.select(levels[i],levels[3]).unique(),on = g , how='left')\n",
    "                .join(f_nation, on = [levels[3],'plan_type','product_id'],how = 'left')\n",
    "                .drop(levels[3])\n",
    "            )\n",
    "        else:\n",
    "            f = (\n",
    "                f\n",
    "                .with_columns(prc_shr_growth_bnch = pl.col('prc_shr_growth'))\n",
    "            )\n",
    "        df[i] = f\n",
    "\n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0780c443-d032-40e3-86af-8899c4cd213f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# prc_vol_growth_ind ,prc_shr_growth_ind\n",
    "def process_7(df):\n",
    "    for i in range(4):\n",
    "        g = levels[i]\n",
    "        f = df[i]\n",
    "        f = (\n",
    "            f\n",
    "            .with_columns(\n",
    "                pl.when((pl.col('prc_vol_growth') >  pl.col('prc_vol_growth_bnch'))).then(pl.lit('L')).otherwise(pl.lit('\\\\N')).alias('prc_vol_growth_ind'),\n",
    "                pl.when((pl.col('prc_shr_growth') >  pl.col('prc_shr_growth_bnch'))).then(pl.lit('L')).otherwise(pl.lit('\\\\N')).alias('prc_shr_growth_ind')\n",
    "            )\n",
    "        )\n",
    "        df[i] = f\n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ba2d04-0cb6-4a68-9ee8-977d9b57bcae",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# For Payer Access\n",
    "def process_8(df):\n",
    "    for i in range(4):\n",
    "        g = levels[i]\n",
    "        f = df[i]\n",
    "\n",
    "        source_df = (\n",
    "            ln2_planid\n",
    "            .select(['PlanID','payer_id','product_id',g,'plan_class','plan_type','plan_type_group1','plan_type_group2',f'TUF{period}c'])\n",
    "            .rename({f'TUF{period}c':'cur_vol'})\n",
    "        )\n",
    "        agg_expn = {'cur_vol':pl.col('cur_vol').sum()}\n",
    "\n",
    "        source_df1 = (\n",
    "            source_df\n",
    "            .group_by([g,'plan_type','plan_class','product_id'])\n",
    "            .agg(**agg_expn)\n",
    "            .pivot(columns = 'plan_class',index = [g,'plan_type','product_id'],values = 'cur_vol',aggregate_function = 'sum',maintain_order = True)\n",
    "        )\n",
    "\n",
    "        source_df1_t = (\n",
    "            source_df\n",
    "            .group_by([g,'plan_type_group1','plan_class','product_id']).agg(**agg_expn).rename({'plan_type_group1' : 'plan_type'})\n",
    "            .pivot(columns = 'plan_class',index = [g,'plan_type','product_id'],values = 'cur_vol',aggregate_function = 'sum',maintain_order = True)\n",
    "            .select(source_df1.columns)\n",
    "        )\n",
    "\n",
    "        source_df1_pdc = (\n",
    "            source_df.filter(pl.col('plan_type_group2').is_not_null())\n",
    "            .group_by([g,'plan_type_group2','plan_class','product_id']).agg(**agg_expn).rename({'plan_type_group2' : 'plan_type'})\n",
    "            .pivot(columns = 'plan_class',index = [g,'plan_type','product_id'],values = 'cur_vol',aggregate_function = 'sum',maintain_order = True)\n",
    "            .select(source_df1.columns)\n",
    "        )\n",
    "\n",
    "        source_df1 = source_df1.vstack(source_df1_t).vstack(source_df1_pdc).fill_null(0)\n",
    "\n",
    "        f = f.join(source_df1,on=[g,'plan_type','product_id'],how='left')\n",
    "        df[i] = f\n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b58429-07b7-4eb5-aa5a-c7e4a7a0231a",
   "metadata": {},
   "source": [
    "Second Drill-down functions -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d3342d-cd4d-4620-9038-aac20ba10a9d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# cur_vol , pri_vol , vol_change, prc_vol_growth, vol_change_ind, cur_trx, cur_tun\n",
    "def process_9():\n",
    "    res = []\n",
    "    for i in range(4):\n",
    "        g = levels[i]\n",
    "        source_df = (\n",
    "            ln2\n",
    "            .select([g,'plan_type','plan_type_group1','plan_type_group2','payer_id','product_id',f'TUF{period}c',f'TUF{period}p',f'TRX{period}c',f'TUN{period}c'])\n",
    "            .rename({f'TUF{period}c':'cur_vol',f'TUF{period}p':'pri_vol',f'TRX{period}c':'cur_trx',f'TUN{period}c':'cur_tun'})\n",
    "        )\n",
    "        agg_expn = {\n",
    "\t\t\t'cur_vol':pl.col('cur_vol').sum(),'pri_vol':pl.col('pri_vol').sum(),\n",
    "\t\t\t'cur_trx':pl.col('cur_trx').sum(),'cur_tun':pl.col('cur_tun').sum()\n",
    "\t\t}\n",
    "        df = (\n",
    "            source_df\n",
    "            .join(top_payers[i],on = [g,'plan_type','payer_id'],how = 'inner')\n",
    "            .drop(['plan_type_group1','plan_type_group2'])\n",
    "            .group_by([g,'plan_type','product_id','payer_id']).agg(**agg_expn)\n",
    "        )\n",
    "        df_t = (\n",
    "            source_df\n",
    "            .join(\n",
    "                top_payers[i].filter(plan_type = 'Total'),\n",
    "                left_on = [g,'plan_type_group1','payer_id'],right_on = [g,'plan_type','payer_id'],how = 'inner'\n",
    "            )\n",
    "            .drop(['plan_type_group2','plan_type']).rename({'plan_type_group1' : 'plan_type'}).select(df.columns)\n",
    "            .group_by([g,'plan_type','product_id','payer_id']).agg(**agg_expn)\n",
    "        )\n",
    "        df_pdc = (\n",
    "            source_df\n",
    "            .join(\n",
    "                top_payers[i].filter(plan_type = 'Part D and Commercial'),\n",
    "                left_on = [g,'plan_type_group2','payer_id'],right_on = [g,'plan_type','payer_id'],how = 'inner'\n",
    "            )\n",
    "            .drop(['plan_type_group1','plan_type']).rename({'plan_type_group2' : 'plan_type'}).select(df.columns)\n",
    "            .group_by([g,'plan_type','product_id','payer_id']).agg(**agg_expn)\n",
    "        )\n",
    "        df = df.vstack(df_t).vstack(df_pdc)\n",
    "        df = (\n",
    "            df\n",
    "            .with_columns(\n",
    "                vol_change = pl.col('cur_vol') - pl.col('pri_vol'),\n",
    "                prc_vol_growth = ((pl.col('cur_vol')/pl.col('pri_vol'))-1).replace([np.inf,np.nan],[None,None]),\n",
    "                avg_trx_size = (pl.col('cur_tun')/pl.col('cur_trx')).replace([np.inf,np.nan],[None,None])\n",
    "            )\n",
    "            .with_columns(\n",
    "                pl.when(pl.col('vol_change')/pl.col('pri_vol') > 0.02).then(pl.lit('P'))\n",
    "                .when(pl.col('vol_change')/pl.col('pri_vol') < -0.02).then(pl.lit('Q'))\n",
    "                .when(pl.col('vol_change')==0).then(None)\n",
    "                .otherwise(None).alias('vol_change_ind')\n",
    "            )\n",
    "            .drop(['cur_trx','cur_tun'])\n",
    "        )\n",
    "\n",
    "        res.append(df)\n",
    "    return (res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35d2445-0fa3-403f-abdd-e1548cc60cff",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# sales_dist , sales_dist_bnch ,prc_vol_growth_bnch ,prc_shr_growth_bnch\n",
    "def process_10(df):\n",
    "    for i in range(4):\n",
    "        g = levels[i]\n",
    "        f = df[i]\n",
    "\n",
    "        source_df = (\n",
    "            temp1[i].filter(plan_type = 'Total').select([g,'product_id','cur_vol']).rename({'cur_vol':'Total_cur_vol'})\n",
    "        )\n",
    "        source_df2 = (\n",
    "            temp1[i].select([g,'plan_type','product_id','sales_dist','prc_vol_growth','prc_shr_growth'])\n",
    "            .rename({'sales_dist':'sales_dist_bnch','prc_vol_growth':'prc_vol_growth_bnch','prc_shr_growth':'prc_shr_growth_bnch'})\n",
    "        )\n",
    "        f = (\n",
    "            f\n",
    "            .join(source_df,on = [g,'product_id'],how='left')\n",
    "            .join(source_df2,on = [g,'plan_type','product_id'],how='left')\n",
    "            .with_columns((pl.col('cur_vol')/pl.col('Total_cur_vol')).replace(np.nan,0).alias('sales_dist'))\n",
    "            .drop('Total_cur_vol')\n",
    "        )\n",
    "        df[i] = f\n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf70c96-0a44-401a-bbe0-b074088a9a45",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# cur_shr, pri_shr, shr_change, prc_shr_growth, shr_change_ind\n",
    "def process_11(df):\n",
    "    for i in range(4):\n",
    "        g = levels[i]\n",
    "        f = df[i]\n",
    "        f_ibsc = (\n",
    "            f\n",
    "            .filter(product_id = 1)\n",
    "            .select([g,'plan_type','payer_id','cur_vol','pri_vol'])\n",
    "            .rename({'cur_vol':'lax_cur_vol','pri_vol':'lax_pri_vol'})\n",
    "        )\n",
    "        f = (\n",
    "            f\n",
    "            .join(f_ibsc,on = [g,'plan_type','payer_id'],how = 'left')\n",
    "            .with_columns(\n",
    "                (pl.col('cur_vol') / pl.col('lax_cur_vol')).alias('cur_shr'),\n",
    "                (pl.col('pri_vol') / pl.col('lax_pri_vol')).alias('pri_shr')\n",
    "            )\n",
    "            .with_columns(\n",
    "                shr_change = pl.col('cur_shr') - pl.col('pri_shr'),\n",
    "                prc_shr_growth = ((pl.col('cur_shr')/pl.col('pri_shr'))-1).replace([np.inf,np.nan],[None,None])\n",
    "            )\n",
    "            .with_columns(\n",
    "                pl.when(pl.col('shr_change')/pl.col('pri_shr') > 0.02).then(pl.lit('P'))\n",
    "                .when(pl.col('shr_change')/pl.col('pri_shr') < -0.02).then(pl.lit('Q'))\n",
    "                .when(pl.col('shr_change')==0).then(None)\n",
    "                .otherwise(None).alias('shr_change_ind')\n",
    "            )\n",
    "            .drop(['lax_cur_vol','lax_pri_vol'])\n",
    "        )\n",
    "        df[i] = f\n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3ac8b5-91f9-4bbc-a910-fb5ddf53e9e6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# For Payer Acess -\n",
    "def process_12(df):\n",
    "    for i in range(4):\n",
    "        g = levels[i]\n",
    "        f = df[i]\n",
    "        source_df = (\n",
    "            ln2_planid\n",
    "            .select(['PlanID','payer_id','product_id',g,'plan_class','plan_type','plan_type_group1','plan_type_group2',f'TUF{period}c'])\n",
    "            .rename({f'TUF{period}c':'cur_vol'})\n",
    "        )\n",
    "        agg_expn = {'cur_vol':pl.col('cur_vol').sum()}\n",
    "        source_df1 = (\n",
    "            source_df\n",
    "            .join(top_payers[i],on = [g,'plan_type','payer_id'],how = 'inner')\n",
    "            .drop(['plan_type_group1','plan_type_group2'])\n",
    "            .group_by([g,'plan_type','product_id','plan_class','payer_id']).agg(**agg_expn)\n",
    "            .pivot(columns = 'plan_class',index = [g,'plan_type','product_id','payer_id'],values = 'cur_vol',aggregate_function = 'sum',maintain_order = True)\n",
    "        )\n",
    "        source_df1_t = (\n",
    "            source_df\n",
    "            .join(top_payers[i],left_on = [g,'plan_type_group1','payer_id'],right_on = [g,'plan_type','payer_id'],how = 'inner')\n",
    "            .drop(['plan_type','plan_type_group2']).rename({'plan_type_group1' : 'plan_type'})\n",
    "            .group_by([g,'plan_type','product_id','plan_class','payer_id']).agg(**agg_expn)\n",
    "            .pivot(columns = 'plan_class',index = [g,'plan_type','product_id','payer_id'],values = 'cur_vol',aggregate_function = 'sum',maintain_order = True)\n",
    "            .select(source_df1.columns)\n",
    "        )\n",
    "        source_df1_pdc = (\n",
    "            source_df\n",
    "            .filter(pl.col('plan_type_group2').is_not_null())\n",
    "            .join(top_payers[i],left_on = [g,'plan_type_group2','payer_id'],right_on = [g,'plan_type','payer_id'],how = 'inner')\n",
    "            .drop(['plan_type','plan_type_group1']).rename({'plan_type_group2' : 'plan_type'})\n",
    "            .group_by([g,'plan_type','product_id','plan_class','payer_id']).agg(**agg_expn)\n",
    "            .pivot(columns = 'plan_class',index = [g,'plan_type','product_id','payer_id'],values = 'cur_vol',aggregate_function = 'sum',maintain_order = True)\n",
    "            .select(source_df1.columns)\n",
    "        )\n",
    "        source_df1 = source_df1.vstack(source_df1_t).vstack(source_df1_pdc).fill_null(0)\n",
    "        f = f.join(source_df1,on=[g,'plan_type','product_id','payer_id'],how='left')\n",
    "        df[i] = f\n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8026dabc-6872-4743-a7a2-d12fafd92b6d",
   "metadata": {},
   "source": [
    "Third Drill down Functions -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc8a062-c493-4f51-b979-819bd9430b0e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    " # cur_vol , pri_vol , vol_change, prc_vol_growth, vol_change_ind, cur_trx, cur_tun , avg_trx_size\n",
    "def process_13():\n",
    "    res = []\n",
    "    for i in range(4):\n",
    "        g = levels[i]\n",
    "        source_df = (\n",
    "            ln2\n",
    "            .select([g,'plan_type','plan_type_group1','plan_type_group2','payer_id','IID','product_id',f'TUF{period}c',f'TUF{period}p',f'TRX{period}c',f'TUN{period}c'])\n",
    "            .rename({f'TUF{period}c':'cur_vol',f'TUF{period}p':'pri_vol',f'TRX{period}c':'cur_trx',f'TUN{period}c':'cur_tun'})\n",
    "            .with_columns(pl.lit(-1).cast(pl.Int64).alias('payer_id_group1'))\n",
    "        )\n",
    "\n",
    "        agg_expn = {\n",
    "            'cur_vol':pl.col('cur_vol').sum(),'pri_vol':pl.col('pri_vol').sum(),\n",
    "            'cur_trx':pl.col('cur_trx').sum(),'cur_tun':pl.col('cur_tun').sum()\n",
    "        }\n",
    "\n",
    "        # Limit data to keep just top 30 HCPs \n",
    "        # For 4 main plan_type\n",
    "        # for top 10 Payers\n",
    "        df_1a = (\n",
    "            source_df\n",
    "            .join(top_hcps[i],on = [g,'plan_type','payer_id','IID'], how='inner')\n",
    "            .drop(['plan_type_group1','plan_type_group2'])\n",
    "            .group_by([g,'product_id','plan_type','payer_id','IID']).agg(**agg_expn)\n",
    "        )\n",
    "        # For 'total' payer_id\n",
    "        df_1b = (\n",
    "            source_df\n",
    "            .join(top_hcps[i],left_on = [g,'plan_type','payer_id_group1','IID'],right_on = [g,'plan_type','payer_id','IID'], how='inner')\n",
    "            .drop(['plan_type_group1','plan_type_group2','payer_id'])\n",
    "            .rename({'payer_id_group1':'payer_id'})\n",
    "            .group_by([g,'product_id','plan_type','payer_id','IID']).agg(**agg_expn)\n",
    "        )\n",
    "        df_1 = df_1a.vstack(df_1b)\n",
    "\n",
    "        # For plan_type = 'Total'\n",
    "        # For top 10 Payers\n",
    "        df_2a = (\n",
    "            source_df\n",
    "            .join(top_hcps[i],left_on = [g,'plan_type_group1','payer_id','IID'],right_on = [g,'plan_type','payer_id','IID'],how='inner')\n",
    "            .drop(['plan_type_group2','plan_type']).rename({'plan_type_group1' : 'plan_type'})\n",
    "            .group_by([g,'product_id','plan_type','payer_id','IID']).agg(**agg_expn)\n",
    "        )\n",
    "\n",
    "        # For 'total' payer_id\n",
    "        df_2b = (\n",
    "            source_df\n",
    "            .join(top_hcps[i],left_on = [g,'plan_type_group1','payer_id_group1','IID'],right_on = [g,'plan_type','payer_id','IID'],how='inner')\n",
    "            .drop(['plan_type_group2','plan_type','payer_id']).rename({'plan_type_group1' : 'plan_type','payer_id_group1':'payer_id'})\n",
    "            .group_by([g,'product_id','plan_type','payer_id','IID']).agg(**agg_expn)\n",
    "        )\n",
    "        df_2 = df_2a.vstack(df_2b)\n",
    "\n",
    "        # For plan_type = 'Part D and Com'\n",
    "        # For top 10 Payers\n",
    "        df_3a = (\n",
    "            source_df\n",
    "            .join(top_hcps[i],left_on = [g,'plan_type_group2','payer_id','IID'],right_on = [g,'plan_type','payer_id','IID'],how='inner')\n",
    "            .drop(['plan_type_group1','plan_type']).rename({'plan_type_group2' : 'plan_type'})\n",
    "            .group_by([g,'product_id','plan_type','payer_id','IID']).agg(**agg_expn)\n",
    "        )\n",
    "        # For 'total' payer_id\n",
    "        df_3b = (\n",
    "            source_df\n",
    "            .filter(pl.col('plan_type_group2').is_not_null())\n",
    "            .join(top_hcps[i],left_on = [g,'plan_type_group2','payer_id_group1','IID'],right_on = [g,'plan_type','payer_id','IID'],how='inner')\n",
    "            .drop(['plan_type_group1','plan_type','payer_id']).rename({'plan_type_group2' : 'plan_type','payer_id_group1':'payer_id'})\n",
    "            .group_by([g,'product_id','plan_type','payer_id','IID']).agg(**agg_expn)\n",
    "        )\n",
    "        df_3 = df_3a.vstack(df_3b)\n",
    "        df_4 = df_1.vstack(df_2).vstack(df_3)\n",
    "        #######################################################################\n",
    "        df = (\n",
    "            df_4\n",
    "            .with_columns(\n",
    "                vol_change = pl.col('cur_vol') - pl.col('pri_vol'),\n",
    "                prc_vol_growth = ((pl.col('cur_vol')/pl.col('pri_vol'))-1).replace([np.inf,np.nan],[None,None]),\n",
    "                avg_trx_size = (pl.col('cur_tun')/pl.col('cur_trx')).replace([np.inf,np.nan],[None,None])\n",
    "            )\n",
    "            .with_columns(\n",
    "                pl.when(pl.col('vol_change')/pl.col('pri_vol') > 0.02).then(pl.lit('P'))\n",
    "                .when(pl.col('vol_change')/pl.col('pri_vol') < -0.02).then(pl.lit('Q'))\n",
    "                .when(pl.col('vol_change')==0).then(None)\n",
    "                .otherwise(None).alias('vol_change_ind')\n",
    "            )\n",
    "            .drop(['cur_trx','cur_tun'])\n",
    "        )\n",
    "        res.append(df)\n",
    "    return (res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea6d626-3701-4981-919b-9338f35072d3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# sales_dist , sales_dist_bnch ,prc_vol_growth_bnch ,prc_shr_growth_bnch\n",
    "def process_14(df):\n",
    "    for i in range(4):\n",
    "        p,pt,pi,g = 'product_id','plan_type','payer_id',levels[i]\n",
    "        f = df[i]\n",
    "        source_df1 = (\n",
    "            temp2[i].select([g,p,pt,pi,'cur_vol','sales_dist','prc_vol_growth','prc_shr_growth'])\n",
    "            .vstack(\n",
    "                temp1[i].with_columns(pl.lit(-1).cast(pl.Int64).alias(pi)).select([g,p,pt,pi,'cur_vol','sales_dist','prc_vol_growth','prc_shr_growth'])\n",
    "            )\n",
    "            .rename({\n",
    "                'cur_vol':'Total_cur_vol','sales_dist':'sales_dist_bnch','prc_vol_growth':'prc_vol_growth_bnch',\n",
    "                'prc_shr_growth':'prc_shr_growth_bnch'\n",
    "            })\n",
    "        )\n",
    "        f = (\n",
    "            f\n",
    "            .join(source_df1,on =[g,p,pt,pi],how='left')\n",
    "            .with_columns((pl.col('cur_vol')/pl.col('Total_cur_vol')).replace(np.nan,0).alias('sales_dist'))\n",
    "            .drop('Total_cur_vol')\n",
    "        )\n",
    "        df[i] = f\n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc69ff05-c815-407f-a5ca-b87891bd0d9d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# cur_shr, pri_shr, shr_change, prc_shr_growth, shr_change_ind\n",
    "def process_15(df):\n",
    "    for i in range(4):\n",
    "        p,pt,pi,g = 'product_id','plan_type','payer_id',levels[i]\n",
    "        f = df[i]\n",
    "        f_ibsc = (\n",
    "            f\n",
    "            .filter(product_id = 1)\n",
    "            .select([g,'plan_type','payer_id','IID','cur_vol','pri_vol'])\n",
    "            .rename({'cur_vol':'lax_cur_vol','pri_vol':'lax_pri_vol'})\n",
    "        )\n",
    "        f = (\n",
    "            f\n",
    "            .join(f_ibsc,on = [g,'plan_type','payer_id','IID'],how = 'left')\n",
    "            .with_columns(\n",
    "                (pl.col('cur_vol') / pl.col('lax_cur_vol')).alias('cur_shr'),\n",
    "                (pl.col('pri_vol') / pl.col('lax_pri_vol')).alias('pri_shr')\n",
    "            )\n",
    "            .with_columns(\n",
    "                shr_change = pl.col('cur_shr') - pl.col('pri_shr'),\n",
    "                prc_shr_growth = ((pl.col('cur_shr')/pl.col('pri_shr'))-1).replace([np.inf,np.nan],[None,None])\n",
    "            )\n",
    "            .with_columns(\n",
    "                pl.when(pl.col('shr_change')/pl.col('pri_shr') > 0.02).then(pl.lit('P'))\n",
    "                .when(pl.col('shr_change')/pl.col('pri_shr') < -0.02).then(pl.lit('Q'))\n",
    "                .when(pl.col('shr_change')==0).then(None)\n",
    "                .otherwise(None).alias('shr_change_ind')\n",
    "            )\n",
    "            .drop(['lax_cur_vol','lax_pri_vol'])\n",
    "        )\n",
    "        df[i] = f\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c9fe3c-bfa6-4409-8698-a15f4fa8448e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# For Payer Access - \n",
    "def process_16(df):\n",
    "    for i in range(4):\n",
    "        p,pt,pi,g = 'product_id','plan_type','payer_id',levels[i]\n",
    "        f = df[i]\n",
    "        source_df = (\n",
    "            ln2_planid\n",
    "            .select(['IID','PlanID','payer_id','product_id',g,'plan_class','plan_type','plan_type_group1','plan_type_group2',f'TUF{period}c'])\n",
    "            .rename({f'TUF{period}c':'cur_vol'})\n",
    "            .with_columns(pl.lit(-1).cast(pl.Int64).alias('payer_id_group1'))\n",
    "        )\n",
    "        agg_expn = {'cur_vol':pl.col('cur_vol').sum()}\n",
    "        df_1a = (\n",
    "            source_df\n",
    "            .join(top_hcps[i],on = [g,'plan_type','payer_id','IID'], how='inner')\n",
    "            .drop(['plan_type_group1','plan_type_group2'])\n",
    "            .group_by([g,'plan_type','product_id','plan_class','payer_id','IID']).agg(**agg_expn)\n",
    "            .pivot(columns = 'plan_class',index = [g,'plan_type','product_id','payer_id','IID'],values = 'cur_vol',aggregate_function = 'sum',maintain_order = True)\n",
    "        )\n",
    "        df_1b = (\n",
    "            source_df\n",
    "            .join(top_hcps[i],left_on = [g,'plan_type','payer_id_group1','IID'],right_on = [g,'plan_type','payer_id','IID'], how='inner')\n",
    "            .drop(['plan_type_group1','plan_type_group2','payer_id'])\n",
    "            .rename({'payer_id_group1':'payer_id'})\n",
    "            .group_by([g,'plan_type','product_id','plan_class','payer_id','IID']).agg(**agg_expn)\n",
    "            .pivot(columns = 'plan_class',index = [g,'plan_type','product_id','payer_id','IID'],values = 'cur_vol',aggregate_function = 'sum',maintain_order = True)\n",
    "            .select(df_1a.columns)\n",
    "        )\n",
    "        df_1 = df_1a.vstack(df_1b)\n",
    "        \n",
    "        df_2a = (\n",
    "            source_df\n",
    "            .join(top_hcps[i],left_on = [g,'plan_type_group1','payer_id','IID'],right_on = [g,'plan_type','payer_id','IID'],how='inner')\n",
    "            .drop(['plan_type_group2','plan_type']).rename({'plan_type_group1' : 'plan_type'})\n",
    "            .group_by([g,'plan_type','product_id','plan_class','payer_id','IID']).agg(**agg_expn)\n",
    "            .pivot(columns = 'plan_class',index = [g,'plan_type','product_id','payer_id','IID'],values = 'cur_vol',aggregate_function = 'sum',maintain_order = True)\n",
    "        )\n",
    "        df_2b = (\n",
    "            source_df\n",
    "            .join(top_hcps[i],left_on = [g,'plan_type_group1','payer_id_group1','IID'],right_on = [g,'plan_type','payer_id','IID'],how='inner')\n",
    "            .drop(['plan_type_group2','plan_type','payer_id']).rename({'plan_type_group1' : 'plan_type','payer_id_group1':'payer_id'})\n",
    "            .group_by([g,'plan_type','product_id','plan_class','payer_id','IID']).agg(**agg_expn)\n",
    "            .pivot(columns = 'plan_class',index = [g,'plan_type','product_id','payer_id','IID'],values = 'cur_vol',aggregate_function = 'sum',maintain_order = True)\n",
    "            .select(df_2a.columns)\n",
    "        )\n",
    "        df_2 = df_2a.vstack(df_2b)\n",
    "        df_3a = (\n",
    "            source_df\n",
    "            .join(top_hcps[i],left_on = [g,'plan_type_group2','payer_id','IID'],right_on = [g,'plan_type','payer_id','IID'],how='inner')\n",
    "            .drop(['plan_type_group1','plan_type']).rename({'plan_type_group2' : 'plan_type'})\n",
    "            .group_by([g,'plan_type','product_id','plan_class','payer_id','IID']).agg(**agg_expn)\n",
    "            .pivot(columns = 'plan_class',index = [g,'plan_type','product_id','payer_id','IID'],values = 'cur_vol',aggregate_function = 'sum',maintain_order = True)\n",
    "        )\n",
    "        df_3b = (\n",
    "            source_df\n",
    "            .filter(pl.col('plan_type_group2').is_not_null())\n",
    "            .join(top_hcps[i],left_on = [g,'plan_type_group2','payer_id_group1','IID'],right_on = [g,'plan_type','payer_id','IID'],how='inner')\n",
    "            .drop(['plan_type_group1','plan_type','payer_id']).rename({'plan_type_group2' : 'plan_type','payer_id_group1':'payer_id'})\n",
    "            .group_by([g,'plan_type','product_id','plan_class','payer_id','IID']).agg(**agg_expn)\n",
    "            .pivot(columns = 'plan_class',index = [g,'plan_type','product_id','payer_id','IID'],values = 'cur_vol',aggregate_function = 'sum',maintain_order = True)\n",
    "            .select(df_3a.columns)\n",
    "        )\n",
    "        df_3 = df_3a.vstack(df_3b)\n",
    "        df_4 = df_1.vstack(df_2.select(df_1.columns)).vstack(df_3.select(df_1.columns)).fill_null(0)\n",
    "        \n",
    "        #######################################################################\n",
    "        \n",
    "        f = f.join(df_4,on=[g,'plan_type','product_id','payer_id','IID'],how='left').fill_null(0)\n",
    "        df[i] = f\n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3c279d-cdad-4d17-b454-9a54ab19167f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# For Payer Mix -\n",
    "def process_17(df):\n",
    "    col_expn = []\n",
    "    for c in ['Part D','Mgd Medicaid','Commercial','Cash','FFS','Others']:\n",
    "        expression = (pl.col(c)/pl.col('total')).replace(np.nan,0).alias(f'prc_{c}')\n",
    "        col_expn.append(expression)\n",
    "    iid_pmix_data = (\n",
    "        ln2_pmix\n",
    "        .select(['IID','product_id','plan_type',f'TUF{period}c'])\n",
    "        .rename({f'TUF{period}c':'TUF'})\n",
    "        .group_by(['IID','product_id','plan_type']).agg(TUF = pl.col('TUF').sum())\n",
    "        .pivot(\n",
    "            values = 'TUF',index = ['IID','product_id'],columns = 'plan_type',aggregate_function='sum',maintain_order=True\n",
    "        ).fill_null(0)\n",
    "        .with_columns(pl.sum_horizontal(['Part D','Mgd Medicaid','Commercial','Cash','FFS','Others','Voucher']).alias('total'))\n",
    "        .with_columns(*col_expn)\n",
    "        .drop(['Part D','Mgd Medicaid','Commercial','Cash','FFS','Others','Voucher','total'])\n",
    "    )\n",
    "    for i in range(4):\n",
    "        f = df[i]\n",
    "        f = (f.join(iid_pmix_data,on = ['IID','product_id'],how = 'left'))\n",
    "        df[i] = f\n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6587023-973c-4526-9c84-2757f76ba629",
   "metadata": {},
   "source": [
    "Miscellaneous Functions -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f8c229-a1b1-458c-adc3-3239d06e0d15",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# inputs : temp1, temp2, temp3 # output : temp4 -> all levels combined , all geos levels also combined \n",
    "def dataframe_reorg_util():\n",
    "    temp1_full = []\n",
    "    temp2_full = []\n",
    "    temp3_full = []\n",
    "    # For Layer 1 ->\n",
    "    for i in range(4):\n",
    "        column_order = temp3[i].columns\n",
    "        f = temp1[i]\n",
    "        f = (\n",
    "            f\n",
    "            .vstack(\n",
    "                f.filter(plan_type = 'Total').with_columns(pl.lit('\\\\N').alias('plan_type'))\n",
    "            )\n",
    "            .with_columns(*[pl.lit('\\\\N').alias(c) for c in ['IID','payer_id','prc_Cash','prc_Commercial','prc_FFS','prc_Mgd Medicaid','prc_Others','prc_Part D'] ])\n",
    "            .select(column_order)\n",
    "        )\n",
    "        temp1_full.append(f)\n",
    "    \n",
    "    cd = [[],[],[],[]] # For Matching dtype for vstack\n",
    "    for i in range(4):\n",
    "        for c,t in zip(temp1_full[i].columns,temp1_full[0].dtypes):\n",
    "            expression = pl.col(c).cast(t).alias(c)\n",
    "            cd[i].append(expression)\n",
    "    \n",
    "    # For Layer 2->\n",
    "    for i in range(4):\n",
    "        column_order = temp3[i].columns\n",
    "        f = temp2[i]\n",
    "        f = (\n",
    "            f\n",
    "            .vstack(\n",
    "                temp1[i].with_columns(pl.lit(-1).cast(pl.Int64).alias('payer_id')).select(temp2[i].columns)\n",
    "            )\n",
    "            .with_columns(*[pl.lit('\\\\N').alias(c) for c in ['IID','prc_Cash','prc_Commercial','prc_FFS','prc_Mgd Medicaid','prc_Others','prc_Part D'] ])\n",
    "            .select(column_order)\n",
    "            .with_columns(*cd[i])\n",
    "        )\n",
    "        temp2_full.append(f)\n",
    "    \n",
    "    # For Layer 3- >\n",
    "    for i in range(4):\n",
    "        f = temp3[i]\n",
    "        f = f.with_columns(*cd[i])\n",
    "        temp3_full.append(f)\n",
    "    \n",
    "    temp_main = []\n",
    "    for i in range(4):\n",
    "        temp_main.append(\n",
    "            temp1_full[i]\n",
    "            .vstack(temp2_full[i])\n",
    "            .vstack(temp3_full[i])\n",
    "        )\n",
    "    temp_final = (\n",
    "        temp_main[0]\n",
    "        .vstack(temp_main[1].rename({levels[1]:levels[0]}).select(temp_main[0].columns))\n",
    "        .vstack(temp_main[2].rename({levels[2]:levels[0]}).select(temp_main[0].columns))\n",
    "        .vstack(temp_main[3].rename({levels[3]:levels[0]}).select(temp_main[0].columns))\n",
    "    )\n",
    "    return(temp_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1280e74a-0cc7-4a70-b8c4-ce60fdabbe50",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Feed Creation - >\n",
    "def get_feed(df):\n",
    "    rename_mapping = {'geography_id' : 'GEOGRAPHY_ID',\n",
    "    'product_id' : 'PRODUCT_ID',\n",
    "    'plan_type' : 'PAYERTYPE',\n",
    "    'payer_id' : 'PAYER_ID',\n",
    "    'IID' : 'PHYSICIAN_ID',\n",
    "    'cur_vol' : 'CURRENT_VOL',\n",
    "    'pri_vol' : 'PRIOR_VOL',\n",
    "    'vol_change' : 'VOL_CHANGE',\n",
    "    'prc_vol_growth' : 'PRC_VOL_GROWTH',\n",
    "    'avg_trx_size' : 'AVG_TRX_SIZE',\n",
    "    'vol_change_ind' : 'VOL_CHANGE_IND',\n",
    "    'sales_dist_bnch' : 'SALES_DISTRIBUTION_BENCHMARK',\n",
    "    'prc_vol_growth_bnch' : 'PRC_BENCHMARK_VOL_GROWTH',\n",
    "    'prc_shr_growth_bnch' : 'PRC_BENCHMARK_SHR_GROWTH',\n",
    "    'sales_dist' : 'SALES_DISTRIBUTION',\n",
    "    'cur_shr' : 'CURRENT_SHR',\n",
    "    'pri_shr' : 'PRIOR_SHR',\n",
    "    'shr_change' : 'SHR_CHANGE',\n",
    "    'prc_shr_growth' : 'PRC_SHR_GROWTH',\n",
    "    'shr_change_ind' : 'SHR_CHANGE_IND',\n",
    "    'prc_vol_growth_ind' : 'VOL_GROWTH_IND',\n",
    "    'prc_shr_growth_ind' : 'SHR_GROWTH_IND',\n",
    "    'PREFERRED' : 'PREFERRED',\n",
    "    'COVERED' : 'COVERED',\n",
    "    'N_A' : 'NOT_AVAILABLE',\n",
    "    'NOT COVERED' : 'NOT_COVERED',\n",
    "    'prc_Part D' : 'MEDICARE_PART_D',\n",
    "    'prc_Mgd Medicaid' : 'MANAGED_MEDICAID',\n",
    "    'prc_Commercial' : 'COMMERCIAL',\n",
    "    'prc_Cash' : 'CASH',\n",
    "    'prc_FFS' : 'FFS',\n",
    "    'prc_Others' : 'OTHER'}\n",
    "    \n",
    "    export_order = ['PRODUCT_ID','GEOGRAPHY_ID','PAYERTYPE','PAYER_ID','PHYSICIAN_ID','REPORTTYPE','PERIOD','PAYER_NAME',\n",
    "    'PHYSICIAN_NAME','SALES_DISTRIBUTION','SALES_DISTRIBUTION_BENCHMARK','CURRENT_VOL','PRIOR_VOL','VOL_CHANGE',\n",
    "    'VOL_CHANGE_IND','PRC_VOL_GROWTH','PRC_BENCHMARK_VOL_GROWTH','VOL_GROWTH_IND','CURRENT_SHR',\n",
    "    'PRIOR_SHR','SHR_CHANGE','SHR_CHANGE_IND','PRC_SHR_GROWTH','PRC_BENCHMARK_SHR_GROWTH','SHR_GROWTH_IND',\n",
    "    'PREFERRED','COVERED','NOT_COVERED','NOT_AVAILABLE','COMMERCIAL','MEDICARE_PART_D','MANAGED_MEDICAID',\n",
    "    'FFS','CASH','OTHER','PREFERRED_MARKET_ACCESS','PREFERRED_MARKET_SHARE','AVG_TRX_SIZE','COVERED_PA_ST',\n",
    "    'UNKNOWN','NOT_APPLICABLE']\n",
    "    \n",
    "    mp = (\n",
    "        MASTER_UNI\n",
    "        .with_columns(pl.concat_str([pl.col('FirstName'),pl.col('LastName')],separator=' ',ignore_nulls=True).alias('PHYSICIAN_NAME'))\n",
    "        .select(['IID','PHYSICIAN_NAME']).rename({'IID':'PHYSICIAN_ID'})\n",
    "        .with_columns(pl.col('PHYSICIAN_ID').cast(pl.Utf8))\n",
    "    )\n",
    "    \n",
    "    df = (\n",
    "        df\n",
    "        .rename(rename_mapping) # Getting Feed Column Names\n",
    "        .with_columns(pl.col('PAYER_ID').replace('-1','TOTAL')) # Fixing payer_id for total rows in layer 2 (coud not do before for vstack purposes)\n",
    "        .with_columns(\n",
    "            pl.when(pl.col('PAYERTYPE')=='Others').then(pl.lit('OTHERS'))\n",
    "            .when(pl.col('PAYERTYPE')=='Commercial').then(pl.lit('COMMERCIAL'))\n",
    "            .when(pl.col('PAYERTYPE')=='Cash').then(pl.lit('CASH'))\n",
    "            .when(pl.col('PAYERTYPE')=='Total').then(pl.lit('TOTAL'))\n",
    "            .when(pl.col('PAYERTYPE')=='Part D').then(pl.lit('PART D'))\n",
    "            .when(pl.col('PAYERTYPE')=='Part D and Commercial').then(pl.lit('PARTANDCOM'))\n",
    "            .otherwise(pl.col('PAYERTYPE'))\n",
    "            .alias('PAYERTYPE')\n",
    "        )# Fixing Payertype Values to match sas feed.\n",
    "        .with_columns(\n",
    "            REPORTTYPE = pl.lit('MONTHLY'),\n",
    "            PERIOD = pl.lit(period_col_values[period_num])\n",
    "        )# Adding Report Type and Period Column\n",
    "        .join(payer_names.with_columns(pl.col('payer_id').cast(pl.Utf8).alias('PAYER_ID')).rename({'IRWD_FGN_NAME':'PAYER_NAME'}),on = 'PAYER_ID',how='left') # Adding Payer Names Back. (IRWD FGN NAME)\n",
    "        .with_columns(pl.when(pl.col('PAYER_ID')=='TOTAL').then(pl.lit('Total')).otherwise(pl.col('PAYER_NAME')).alias('PAYER_NAME')) # Accounting a payer name for 'total' row in layer 2\n",
    "        .join(mp,on='PHYSICIAN_ID',how='left').with_columns(pl.col('PHYSICIAN_NAME').fill_null('\\\\N')) # Adding HCP name\n",
    "        .with_columns(*[pl.lit('\\\\N').alias(c) for c in ['PREFERRED_MARKET_ACCESS','PREFERRED_MARKET_SHARE','COVERED_PA_ST','UNKNOWN','NOT_APPLICABLE']]) # Adding Blank Columns (Not calcualted)\n",
    "        .select(export_order) # Resetting Table Sequence\n",
    "    )\n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2b5052-19ba-4440-8d92-cd573d9aafd1",
   "metadata": {},
   "source": [
    "## Period Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8569344c-15b2-4f19-a207-6efa1c4e33a7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# MAIN EXECUTIVE LOOP - >\n",
    "period_col_values = {1:'1-MONTH',3:'3-MONTHS',6:'6-MONTHS',12:'12-MONTHS','qtd':'QTD','ytd':'YTD'}\n",
    "for period_num,PN in zip([1,3,6,12,'qtd','ytd'],[1,2,3,4,5,7]):\n",
    "    period = f'_{period_num}'\n",
    "    # LAYER 1\n",
    "    temp1 = process_1() # cur_vol , pri_vol , vol_change, prc_vol_growth, vol_change_ind, cur_trx, cur_tun , avg_trx_size\n",
    "    temp1 = process_2(temp1) # sales dist\n",
    "    temp1 = process_3(temp1) # sales dist_bnch\n",
    "    temp1 = process_4(temp1) # prc_vol_growth_bnch\n",
    "    temp1 = process_5(temp1)# cur_shr, pri_shr, shr_change, prc_shr_growth, shr_change_ind\n",
    "    temp1 = process_6(temp1) # prc_shr_growth_bnch\n",
    "    temp1 = process_7(temp1)# prc_vol_growth_ind ,prc_shr_growth_ind\n",
    "    temp1 = process_8(temp1)# Payer Access\n",
    "\n",
    "    # LAYER 2\n",
    "    temp2 = process_9() # cur_vol , pri_vol , vol_change, prc_vol_growth, vol_change_ind, cur_trx, cur_tun , avg_trx_size\n",
    "    temp2 = process_10(temp2) # sales_dist , sales_dist_bnch ,prc_vol_growth_bnch ,prc_shr_growth_bnch\n",
    "    temp2 = process_11(temp2) # cur_shr, pri_shr, shr_change, prc_shr_growth, shr_change_ind\n",
    "    temp2 = process_7(temp2) # prc_vol_growth_ind ,prc_shr_growth_ind\n",
    "    temp2 = process_12(temp2) # Payer Acess -\n",
    "\n",
    "    # LAYER 3\n",
    "    temp3 = process_13()  # cur_vol , pri_vol , vol_change, prc_vol_growth, vol_change_ind, cur_trx, cur_tun , avg_trx_size\n",
    "    temp3 = process_14(temp3) # sales_dist , sales_dist_bnch ,prc_vol_growth_bnch ,prc_shr_growth_bnch\n",
    "    temp3 = process_15(temp3) # cur_shr, pri_shr, shr_change, prc_shr_growth, shr_change_ind\n",
    "    temp3 = process_7(temp3) # prc_vol_growth_ind ,prc_shr_growth_ind\n",
    "    temp3 = process_16(temp3) # For Payer Access - \n",
    "    temp3 = process_17(temp3) # For Payer Mix -\n",
    "\n",
    "    # Consolidate -\n",
    "    temp4 = dataframe_reorg_util()\n",
    "    feed_dataset = get_feed(temp4)\n",
    "\n",
    "    outfile = f's3://vortex-staging-a65ced90/BIT/output/ManagedCare/Monthly_ManagedCare_SalesPerformance_P{PN}_Feed.txt'\n",
    "\n",
    "    feed_dataset.to_pandas().to_csv(outfile,sep='|', lineterminator='\\r\\n',index=False)\n",
    "\n",
    "    print('Exported Feed : ',PN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d044ed0d-36c2-4b1f-b77d-800aef704c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#97 Seconds for Data Prep 526 for loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7c0837-a9e5-40ba-a0b4-8dcbff448cd2",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
