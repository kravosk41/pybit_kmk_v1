{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4d81d9f-199b-456a-a5a4-e374a3fc16fa",
   "metadata": {},
   "source": [
    "#  Managed Care - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dda1585-f3f7-4cf5-9c64-678e00cff912",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# importing modules\n",
    "import polars as pl\n",
    "import gc\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta,date\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1440ad3-fd57-4930-b02c-efbe139c0e15",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# load variables from JSON\n",
    "with open('vars_wk.json', 'r') as json_file:\n",
    "    js = json.load(json_file)\n",
    "\n",
    "bucket = js['bucket']\n",
    "# data_date = js['data_date']\n",
    "# monthly_data_date = js['monthly_data_date']\n",
    "data_date = '20240712'\n",
    "monthly_data_date = '202406'\n",
    "QTD = 3\n",
    "YTD = 6 \n",
    "#TODO: CONNECT TO JSON LATER\n",
    "\n",
    "dflib = f's3://{bucket}/BIT/dataframes/'\n",
    "pln = f's3://{bucket}/PYADM/weekly/archive/{data_date}/plantrak/' \n",
    "mpln = f's3://{bucket}/PYADM/monthly/archive/{monthly_data_date}/plantrak/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89615e97-64e1-4aaa-ba59-49eedd188d58",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Utility Functions -\n",
    "def load(df, lib=dflib):\n",
    "    globals()[df] = pl.read_parquet(f'{lib}{df}.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2169c1c-2cbf-471a-8f5c-d25f9a099535",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Imporing Dependencies\n",
    "prod_mapping = pl.read_csv(f's3://{bucket}/BIT/docs/productmapping_pybit.txt',separator='|')\n",
    "geo_code_mapper = pl.from_pandas(pd.read_excel(f's3://{bucket}/BIT/docs/geo_id_full.xlsx'))\n",
    "load('mp_spec_seg_dec')\n",
    "#load('MASTER_UNI')\n",
    "fetch_products = ['LI1','LI2','LI3','TRU','AMT','LAC','MOT','LUB','IRL']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3146e33-0840-4437-81ad-8a1ac5357a1f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f4ce45-2c4a-43d6-b830-4945b72f6f26",
   "metadata": {},
   "source": [
    "## Importing Raw Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc709a0-90ba-4a98-9e66-c2056232f11a",
   "metadata": {},
   "source": [
    "### Formulary\n",
    "- _Using Both Weekly and Monthly for payer name list_\n",
    "- _only using Monthly for plan_type and plan_class_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d6be19e-aed1-437e-b2e6-ef76b227b340",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Processing Formulary Datasets -\n",
    "columns_to_read = ['IMS_PLAN_ID','GROUP_TYPE','FORMULARY_GROUP_STATUS','PFAM_CD','PFAM_NAME','IRWD_FGN_NAME','BRAND']\n",
    "\n",
    "fm_monthly = pl.read_parquet(\n",
    "    mpln+'FORMULARY.parquet',columns = columns_to_read\n",
    ")\n",
    "\n",
    "fm_weekly = pl.read_parquet(\n",
    "    pln+'FORMULARY.parquet',columns = columns_to_read\n",
    ")\n",
    "\n",
    "# Consolidating list of Unique Payer Names -\n",
    "payer_names = (\n",
    "    fm_monthly.select('IRWD_FGN_NAME')\n",
    "    .vstack(fm_weekly.select('IRWD_FGN_NAME'))\n",
    "    .unique()\n",
    "    .sort('IRWD_FGN_NAME')\n",
    "    .with_row_index(offset=1)\n",
    "    .rename({'index':'payer_id'})\n",
    ")\n",
    "\n",
    "#FORMULARY\n",
    "group_type_mapping = {\n",
    "    'HIX' : 'Commercial','Com' : 'Commercial','Cash' : 'Cash','Voucher':'Voucher',\n",
    "    'FFS' : 'FFS','Mgd Medicaid' : 'Mgd Medicaid','Part D' : 'Part D','MAC A' : 'Others',\n",
    "}\n",
    "\n",
    "def classify_plan_class(status):\n",
    "    status = status.upper()\n",
    "    if status[:7] == \"COVERED\" or status[:6] == \"ON PDL\":\n",
    "        return \"COVERED\"\n",
    "    elif status[:9] == \"PREFERRED\":\n",
    "        return \"PREFERRED\"\n",
    "    elif status[:13] == \"NON-PREFERRED\":\n",
    "        return \"NON PREFERRED\"\n",
    "    elif status[:7] == \"NON-PDL\" or status[:11] == \"NOT COVERED\":\n",
    "        return \"NOT COVERED\"\n",
    "    else:\n",
    "        return \"N_A\"\n",
    "\n",
    "fm = fm_monthly.with_columns(\n",
    "        pl.when(pl.col('BRAND')=='IBR')\n",
    "        .then(pl.lit('IRL'))\n",
    "        .otherwise(pl.col('BRAND'))\n",
    "        .alias('BRAND')\n",
    ")\n",
    "\n",
    "fm = fm.filter((pl.col('PFAM_CD')==(pl.col('BRAND'))) | (pl.col('BRAND')==''))\n",
    "\n",
    "fm = (\n",
    "    fm\n",
    "    .with_columns(\n",
    "        pl.col('GROUP_TYPE').map_elements(lambda x: group_type_mapping.get(x,'Others'), return_dtype=pl.Utf8) #NOTE : IF new plan types flow , they will go to Others by default\n",
    "        .fill_null('Others')\n",
    "        .alias('plan_type'),\n",
    "        pl.col('IMS_PLAN_ID').cast(pl.Int64)\n",
    "    )\n",
    "    .rename({'IMS_PLAN_ID':'PlanID'})\n",
    "    .drop('GROUP_TYPE')\n",
    "    .with_columns(pl.col('FORMULARY_GROUP_STATUS').fill_null(pl.lit('N_A')))\n",
    "    .with_columns(pl.col('FORMULARY_GROUP_STATUS').map_elements(classify_plan_class,return_dtype=pl.String).alias('plan_class'))\n",
    "    .drop('FORMULARY_GROUP_STATUS')\n",
    "    .unique()\n",
    ")\n",
    "\n",
    "###############\n",
    "# HARD CODED - \n",
    "fm = fm.with_columns(pl.when(pl.col(\"PlanID\") == 13670614).then(pl.lit('Others')).otherwise(pl.col(\"plan_type\")).alias(\"plan_type\"))\n",
    "###############\n",
    "fm2 = (\n",
    "    fm\n",
    "    .select('PFAM_CD','IRWD_FGN_NAME','plan_class').unique()\n",
    "    .group_by(['IRWD_FGN_NAME','PFAM_CD'])\n",
    "    .agg(\n",
    "        pl.col('plan_class').unique().str.concat(' / ').alias('plan_class')\n",
    "    )\n",
    "    .with_columns(pl.col('plan_class').str.to_titlecase())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbd7b9e-93f4-4ce3-a708-42f5908b640f",
   "metadata": {},
   "source": [
    "### Plantrak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f1eebce-22a0-4521-9816-9c05dee6ea75",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Import and prepare Raw data - # INPUT : Adm Files # OUTPUT : ln\n",
    "ln = (\n",
    "    pl.read_parquet(mpln+'LAX_N.parquet',columns=['IID','MonthKey','PFAM_CD','PROD_CD','PlanID','TUF','TRX','TUN']) \n",
    "    .rename({'MonthKey':'PeriodKey'})\n",
    "    .filter(pl.col('PROD_CD').is_in(fetch_products)) #only keep data for BIT products\n",
    "    .with_columns(pl.col('PeriodKey').cast(pl.Utf8).str.to_date(\"%Y%m%d\")) #Convert Categorical column Back to date\n",
    ")\n",
    "date_list = ln['PeriodKey'].unique().sort(descending=True)\n",
    "\n",
    "# Any PlanIds startign with -0000002 should be excluded\n",
    "ln = (\n",
    "    ln\n",
    "    .with_columns(pl.col('PlanID').cast(pl.Utf8).str.zfill(10).alias('planid_chr'))\n",
    "    .filter(~pl.col('planid_chr').str.starts_with('000002'))\n",
    "    .drop('planid_chr')\n",
    ")\n",
    "\n",
    "ln = ln.join(\n",
    "    (pl.DataFrame(date_list).with_row_index(offset = 1).rename({'index':'num_month'})),\n",
    "    on = 'PeriodKey', how = 'left'\n",
    ")\n",
    "\n",
    "ln = (\n",
    "    ln\n",
    "    .join(fm.select(['PlanID','IRWD_FGN_NAME']).unique(),on='PlanID',how='left')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4b41b99-0241-407d-b039-220a251bb581",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# GENETATOR FUNCTION FOR DATACUTS  # INPUT : ln # OUTPUT : ln1\n",
    "\n",
    "#helper dict object - \n",
    "filter_cond_dict = {\n",
    "    '1c' : pl.col('num_month')==1,'1p' : pl.col('num_month')==2,\n",
    "    '3c' : pl.col('num_month').is_in([1,2,3]),'3p' : pl.col('num_month').is_in([4,5,6]),\n",
    "    '6c' : pl.col('num_month').is_in([1,2,3,4,5,6]),'6p' : pl.col('num_month').is_in([7,8,9,10,11,12]),\n",
    "    '12c' : pl.col('num_month').is_in([i for i in range(1,13)]),'12p' : pl.col('num_month').is_in([i for i in range(13,25)]),\n",
    "    'qtdc' : pl.col('num_month').is_in([i for i in range(1,QTD+1)]),'qtdp' : pl.col('num_month').is_in([i for i in range(4,4+QTD)]),\n",
    "    'ytdc' : pl.col('num_month').is_in([i for i in range(1,YTD+1)]),'ytdp' : pl.col('num_month').is_in([i for i in range(13,13+YTD)])\n",
    "}\n",
    "\n",
    "def get_data_cuts(df):\n",
    "    result = pl.DataFrame()\n",
    "    for period,cond in filter_cond_dict.items():\n",
    "        df_filter = df.filter(cond)\n",
    "        df_filter = (\n",
    "            df_filter\n",
    "            .group_by(['IID','IRWD_FGN_NAME','PFAM_CD','PROD_CD'])\n",
    "            .agg(\n",
    "                pl.col('TUF').sum().alias(f'TUF_{period}'),\n",
    "                pl.col('TRX').sum().alias(f'TRX_{period}'),\n",
    "                pl.col('TUN').sum().alias(f'TUN_{period}')\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if period == '1c':\n",
    "            result = df_filter\n",
    "        else:\n",
    "            result = result.join(df_filter,on =['IID','IRWD_FGN_NAME','PFAM_CD','PROD_CD'],how = 'outer_coalesce')\n",
    "\n",
    "    # Pulling in Plan Type -\n",
    "    result = (\n",
    "        result\n",
    "        .join(\n",
    "            fm.select(['IRWD_FGN_NAME','PFAM_CD','plan_type']).unique(),\n",
    "            on = ['IRWD_FGN_NAME', 'PFAM_CD'], how = 'left'\n",
    "        )\n",
    "        .with_columns(\n",
    "            pl.col('plan_type').fill_null(pl.lit('Others')),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Pulling in Plan Class\n",
    "    result = (\n",
    "        result.join(fm2, on=['IRWD_FGN_NAME', 'PFAM_CD'], how='left')\n",
    "        .with_columns(\n",
    "            pl.col('plan_class').fill_null(pl.lit('N_a'))\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Dropping Records with Voucher , FFS , Medicaid\n",
    "    result = result.filter(\n",
    "        ~(pl.col('plan_type').is_in(['Voucher','Mgd Medicaid','FFS']))\n",
    "    )\n",
    "\n",
    "    #Joining Payer ID-\n",
    "    result = result.join(payer_names, on ='IRWD_FGN_NAME', how = 'left')\n",
    "\n",
    "    # adding product_id\n",
    "    result = (\n",
    "        result\n",
    "        .join(\n",
    "            prod_mapping.select(['code','product_id','parent_product_id']),\n",
    "            left_on = 'PROD_CD', right_on='code', how = 'left'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return (result)\n",
    "\n",
    "ln1 = get_data_cuts(ln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b62b32da-7771-4a89-ae73-f94faa570b54",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Adding Parent Product Rows - # INPUT ln1 # OUTPUT : ln2\n",
    "data_cut_list = [f'TUF_{p}' for p in filter_cond_dict.keys()] + [f'TRX_{p}' for p in filter_cond_dict.keys()] + [f'TUN_{p}' for p in filter_cond_dict.keys()]\n",
    "\n",
    "prod_agg_expn_list = {\n",
    "    col : pl.col(col).sum() for col in data_cut_list\n",
    "}\n",
    "prod_agg_expn_list.update({'plan_type':pl.col('plan_type').first()})\n",
    "\n",
    "#lin and amt-\n",
    "\n",
    "ln1_235 = (\n",
    "    ln1\n",
    "    .filter(pl.col('parent_product_id').is_in([2,35]))\n",
    "    .group_by(['IID','IRWD_FGN_NAME','payer_id','parent_product_id'])\n",
    "    .agg(\n",
    "        **{**prod_agg_expn_list,'plan_class':pl.col('plan_class').first()}\n",
    "    )\n",
    "    .rename({'parent_product_id':'product_id'})\n",
    ")\n",
    "\n",
    "\n",
    "#for lax mkt - \n",
    "ln1_1 = (\n",
    "    ln1\n",
    "    .group_by(['IID','IRWD_FGN_NAME','payer_id'])\n",
    "    .agg(**prod_agg_expn_list)\n",
    "    .with_columns(pl.lit(1).alias('product_id').cast(pl.Int64),pl.lit('N_a').alias('plan_class'))\n",
    "    .select(ln1_235.columns)\n",
    ")\n",
    "\n",
    "ln2 = (\n",
    "    ln1.select(ln1_235.columns)\n",
    "    .vstack(ln1_235)\n",
    "    .vstack(ln1_1)\n",
    ")\n",
    "\n",
    "# Adding Geography Information and Removing Plans not present in Formulary & any White Space HCPs-\n",
    "ln2 = (\n",
    "    ln2\n",
    "    .join(mp_spec_seg_dec[['IID','geography_id']],on='IID',how='left')\n",
    "    .join(geo_code_mapper,on = 'geography_id', how = 'left')\n",
    "    .filter(pl.col('payer_id').is_not_null())\n",
    "    .filter(pl.col('geography_id').is_not_null()) \n",
    "    .fill_null(0.0) # Filling Nulls inside Data Cuts for Consistency.\n",
    "\n",
    "    # DTYPE FIXES \n",
    "    .with_columns(\n",
    "        pl.col('IID').cast(pl.Int64),\n",
    "        pl.col('payer_id').cast(pl.Int64),\n",
    "        pl.col('geography_id').cast(pl.Int64),\n",
    "        pl.col('region_geography_id').cast(pl.Int64),\n",
    "        pl.col('area_geography_id').cast(pl.Int64),\n",
    "        pl.col('nation_geography_id').cast(pl.Int64),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed17a2c-c8ea-4684-bf33-15d7e6880732",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fbb06f-f57f-4534-85f7-3d5a663b4ba8",
   "metadata": {},
   "source": [
    "## Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbd166c-4a9e-49bb-9a0e-be3bafdfe6f6",
   "metadata": {},
   "source": [
    "1. top_plans  - For a given Geography ID and given Payer Type : Top 10 Payer IDs [Based on IBSC 6m Volume]\n",
    "2. top_hcps - For a given payer Top 30 HCPs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c6ac6af4-3ca6-4549-9719-b916dd13ec70",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Top 10 Payers For a Given Geography and PlanType -> #INPUT : ln2 # OUTPUT : top_payers\n",
    "\n",
    "levels = ['geography_id','region_geography_id','area_geography_id','nation_geography_id']\n",
    "def get_top_payers(ln2,g):\n",
    "\n",
    "    ln2 = ln2.filter(product_id = 1) # Only Keeping IBSC Market Volume.\n",
    "    \n",
    "    df = (\n",
    "        ln2\n",
    "        .group_by([g,'plan_type','payer_id'])\n",
    "        .agg(TUF = pl.col('TUF_6c').sum())\n",
    "        .with_columns(\n",
    "            pl.col('TUF')\n",
    "            .rank(\"ordinal\",descending=True)\n",
    "            .over([g,'plan_type'])\n",
    "            .alias(\"rank\")\n",
    "        )\n",
    "        .filter(pl.col('rank') <= 10)\n",
    "    )\n",
    "    \n",
    "    df_total = (\n",
    "        ln2\n",
    "        .group_by([g,'payer_id'])\n",
    "        .agg(TUF = pl.col('TUF_6c').sum())\n",
    "        .with_columns(plan_type = pl.lit('Total'))\n",
    "        .with_columns(\n",
    "            pl.col('TUF')\n",
    "            .rank(\"ordinal\",descending=True)\n",
    "            .over([g,'plan_type'])\n",
    "            .alias(\"rank\")\n",
    "        )\n",
    "        .filter(pl.col('rank') <= 10)\n",
    "        .select(df.columns)\n",
    "    )\n",
    "    \n",
    "    df_pdc = (\n",
    "        ln2\n",
    "        .filter(pl.col('plan_type').is_in(['Part D', 'Commercial']))\n",
    "        .group_by([g,'payer_id'])\n",
    "        .agg(TUF = pl.col('TUF_6c').sum())\n",
    "        .with_columns(plan_type = pl.lit('Part D and Commercial'))\n",
    "        .with_columns(\n",
    "            pl.col('TUF')\n",
    "            .rank(\"ordinal\",descending=True)\n",
    "            .over([g,'plan_type'])\n",
    "            .alias(\"rank\")\n",
    "        )\n",
    "        .filter(pl.col('rank') <= 20)\n",
    "        .select(df.columns)\n",
    "    )\n",
    "    \n",
    "    df = df.vstack(df_total).vstack(df_pdc).sort(by = [g,'plan_type','rank']).drop(['TUF','rank'])\n",
    "    \n",
    "    return (df)\n",
    "\n",
    "# Consolidating results for all Geography Levels - \n",
    "top_payers = [ \n",
    "    get_top_payers(ln2,levels[0]),\n",
    "    get_top_payers(ln2,levels[1]),\n",
    "    get_top_payers(ln2,levels[2]),\n",
    "    get_top_payers(ln2,levels[3])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b2ff1851-a168-4991-ae2a-43640362897a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Top 30 HCPs For a Given Geography and PlanType and Payer_ID -> #INPUT : ln2 # OUTPUT : top_hcps | needs top_payers to be in memory\n",
    "def get_top_hcps(ln2,g,i):\n",
    "    \n",
    "    # Pick Up LN2 - >\n",
    "    ln2 = (\n",
    "        ln2\n",
    "        .filter(product_id = 1)\n",
    "        .with_columns(\n",
    "            pl.lit('Total').alias('plan_type_group1'),\n",
    "            pl.when(pl.col('plan_type').is_in(['Part D', 'Commercial'])).then(pl.lit('Part D and Commercial')).otherwise(None).alias('plan_type_group2')\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Join LN2 with top_payers to limit dataset\n",
    "    ln2_filter = (\n",
    "        ln2.join(top_payers[i],on = [g,'plan_type','payer_id'],how = 'inner')\n",
    "    )\n",
    "    \n",
    "    ln2_filter_t = (\n",
    "        ln2.join(\n",
    "            top_payers[i],\n",
    "            left_on = [g,'plan_type_group1','payer_id'],\n",
    "            right_on = [g,'plan_type','payer_id'],how = 'inner'\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    ln2_filter_pdc = (\n",
    "        ln2.join(\n",
    "            top_payers[i],\n",
    "            left_on = [g,'plan_type_group2','payer_id'],\n",
    "            right_on = [g,'plan_type','payer_id'],how = 'inner'\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Top 30 HCPs -\n",
    "    df = (\n",
    "        ln2_filter\n",
    "        .group_by([g,'plan_type','payer_id','IID'])\n",
    "        .agg(TUF = pl.col('TUF_6c').sum())\n",
    "        .with_columns(pl.col('TUF').rank(\"ordinal\",descending=True).over([g,'plan_type','payer_id']).alias(\"rank\"))\n",
    "        .filter(pl.col('rank') <= 30)\n",
    "    )\n",
    "    \n",
    "    df_total = (\n",
    "        ln2_filter_t\n",
    "        .group_by([g,'plan_type_group1','payer_id','IID'])\n",
    "        .agg(TUF = pl.col('TUF_6c').sum())\n",
    "        .with_columns(pl.col('TUF').rank(\"ordinal\",descending=True).over([g,'plan_type_group1','payer_id']).alias(\"rank\"))\n",
    "        .filter(pl.col('rank') <= 30)\n",
    "        .rename({'plan_type_group1':'plan_type'})\n",
    "    )\n",
    "    \n",
    "    df_pdc = (\n",
    "        ln2_filter_pdc\n",
    "        .group_by([g,'plan_type_group2','payer_id','IID'])\n",
    "        .agg(TUF = pl.col('TUF_6c').sum())\n",
    "        .with_columns(pl.col('TUF').rank(\"ordinal\",descending=True).over([g,'plan_type_group2','payer_id']).alias(\"rank\"))\n",
    "        .filter(pl.col('rank') <= 30)\n",
    "        .rename({'plan_type_group2':'plan_type'})\n",
    "    )\n",
    "    \n",
    "    df = (\n",
    "        df\n",
    "        .vstack(df_total)\n",
    "        .vstack(df_pdc)\n",
    "        .sort(by = [g,'plan_type','payer_id','rank'])\n",
    "        .drop(['TUF','rank'])\n",
    "    )\n",
    "    \n",
    "    return (df)\n",
    "\n",
    "top_hcps = [\n",
    "    get_top_hcps(ln2,levels[0],0),\n",
    "    get_top_hcps(ln2,levels[1],1),\n",
    "    get_top_hcps(ln2,levels[2],2),\n",
    "    get_top_hcps(ln2,levels[3],3)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "712a8927-2daf-42f9-8c0c-9a54ad025fd4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#adding columns to facilitate filter joins \n",
    "ln2 = (\n",
    "    ln2\n",
    "    .with_columns(\n",
    "        pl.lit('Total').alias('plan_type_group1'),\n",
    "        pl.when(pl.col('plan_type').is_in(['Part D', 'Commercial'])).then(pl.lit('Part D and Commercial')).otherwise(None).alias('plan_type_group2')\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c667e7e-51c3-4894-b9ec-9888221e154c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745e2579-6f34-4e3c-b84e-6d9e9ea1dfa9",
   "metadata": {},
   "source": [
    "First Drill-down functions -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c6a6c0de-e09e-4e2c-8b45-5cba7f05c054",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# cur_vol , pri_vol , vol_change, prc_vol_growth, vol_change_ind, cur_trx, cur_tun\n",
    "def process_1():\n",
    "    res = []\n",
    "    for i in range(4):\n",
    "        g = levels[i]\n",
    "        source_df = (\n",
    "            ln2\n",
    "            .select([g,'plan_type','plan_type_group1','plan_type_group2','payer_id','product_id',f'TUF{period}c',f'TUF{period}p',f'TRX{period}c',f'TUN{period}c'])\n",
    "            .rename({f'TUF{period}c':'cur_vol',f'TUF{period}p':'pri_vol',f'TRX{period}c':'cur_trx',f'TUN{period}c':'cur_tun'})\n",
    "        )\n",
    "        agg_expn = {\n",
    "\t\t\t'cur_vol':pl.col('cur_vol').sum(),'pri_vol':pl.col('pri_vol').sum(),\n",
    "\t\t\t'cur_trx':pl.col('cur_trx').sum(),'cur_tun':pl.col('cur_tun').sum()\n",
    "\t\t}\n",
    "        df = (source_df.group_by([g,'plan_type','product_id']).agg(**agg_expn))\n",
    "        df_t = (source_df.group_by([g,'plan_type_group1','product_id']).agg(**agg_expn).rename({'plan_type_group1' : 'plan_type'}).select(df.columns))\n",
    "        df_pdc = (\n",
    "            source_df.filter(pl.col('plan_type_group2').is_not_null()).group_by([g,'plan_type_group2','product_id'])\n",
    "            .agg(**agg_expn).rename({'plan_type_group2' : 'plan_type'}).select(df.columns)\n",
    "        )\n",
    "        df = df.vstack(df_t).vstack(df_pdc)\n",
    "\n",
    "        df = (\n",
    "            df\n",
    "            .with_columns(\n",
    "                vol_change = pl.col('cur_vol') - pl.col('pri_vol'),\n",
    "                prc_vol_growth = ((pl.col('cur_vol')/pl.col('pri_vol'))-1).replace([np.inf,np.nan],[None,None]),\n",
    "                avg_trx_size = (pl.col('cur_tun')/pl.col('cur_trx')).replace([np.inf,np.nan],[None,None])\n",
    "            )\n",
    "            .with_columns(\n",
    "                pl.when(pl.col('vol_change')/pl.col('pri_vol') > 0.02).then(pl.lit('P'))\n",
    "                .when(pl.col('vol_change')/pl.col('pri_vol') < -0.02).then(pl.lit('Q'))\n",
    "                .when(pl.col('vol_change')==0).then(None)\n",
    "                .otherwise(None).alias('vol_change_ind')\n",
    "            )\n",
    "            .drop(['cur_trx','cur_tun'])\n",
    "        )\n",
    "        res.append(df)\n",
    "    return (res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "149dde91-4086-4112-91e5-b65abddfc14c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# sales_dist\n",
    "def process_2(df):\n",
    "    for i in range(4):\n",
    "        g = levels[i]\n",
    "        f = df[i]\n",
    "        f_total = (\n",
    "            f\n",
    "            .filter(pl.col('plan_type')=='Total').select([g,'product_id','cur_vol'])\n",
    "            .rename({'cur_vol':'Total_cur_vol'})\n",
    "        )\n",
    "        f = (\n",
    "            f\n",
    "            .join(f_total,on = [g,'product_id'])\n",
    "            .with_columns((pl.col('cur_vol')/pl.col('Total_cur_vol')).replace(np.nan,0).alias('sales_dist'))\n",
    "            .drop('Total_cur_vol')\n",
    "        )\n",
    "        df[i] = f\n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c4d32044-5b6e-4228-93a3-638029827b6c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# sales_dist_bnch\n",
    "def process_3(df):\n",
    "    for i in range(4):\n",
    "        g = levels[i]\n",
    "        f = df[i]\n",
    "        if i != 3:\n",
    "            f_parent = (\n",
    "                df[i+1]\n",
    "                .select([levels[i+1],'plan_type','product_id','sales_dist'])\n",
    "                .rename({'sales_dist':'sales_dist_bnch'})\n",
    "            )\n",
    "            f = (\n",
    "                f\n",
    "                .join(geo_code_mapper.select(levels[i],levels[i+1]).unique(),on = g , how='left')\n",
    "                .join(f_parent, on = [levels[i+1],'plan_type','product_id'],how = 'left')\n",
    "                .drop(levels[i+1])\n",
    "            )\n",
    "        else:\n",
    "            f = (\n",
    "                f\n",
    "                .with_columns(sales_dist_bnch = pl.col('sales_dist'))\n",
    "            )\n",
    "        df[i] = f\n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0089be28-166c-4ab4-b562-c7b3a0af8e1b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# prc_vol_growth_bnch\n",
    "def process_4(df):\n",
    "    for i in range(4):\n",
    "        g = levels[i]\n",
    "        f = df[i]\n",
    "        # for terr ->\n",
    "        f_region = (\n",
    "            df[1].select([levels[1],'plan_type','product_id','prc_vol_growth']).rename({'prc_vol_growth':'prc_vol_growth_bnch'})\n",
    "        )\n",
    "        # for Region, Area ->\n",
    "        f_nation = (\n",
    "            df[3].select([levels[3],'plan_type','product_id','prc_vol_growth']).rename({'prc_vol_growth':'prc_vol_growth_bnch'})\n",
    "        )\n",
    "\n",
    "        if i == 0:\n",
    "            f = (\n",
    "                f\n",
    "                .join(geo_code_mapper.select(levels[i],levels[i+1]).unique(),on = g , how='left')\n",
    "                .join(f_region, on = [levels[i+1],'plan_type','product_id'],how = 'left')\n",
    "                .drop(levels[i+1])\n",
    "            )\n",
    "        elif (( i==1 ) | (i ==2)):\n",
    "            f = (\n",
    "                f\n",
    "                .join(geo_code_mapper.select(levels[i],levels[3]).unique(),on = g , how='left')\n",
    "                .join(f_nation, on = [levels[3],'plan_type','product_id'],how = 'left')\n",
    "                .drop(levels[3])\n",
    "            )\n",
    "        else:\n",
    "            f = (\n",
    "                f\n",
    "                .with_columns(prc_vol_growth_bnch = pl.col('prc_vol_growth'))\n",
    "            )\n",
    "        df[i] = f\n",
    "\n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3bbe0174-4ca2-4a5f-b5b4-e2cd714b231c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# cur_shr, pri_shr, shr_change, prc_shr_growth, shr_change_ind\n",
    "def process_5(df):\n",
    "    for i in range(4):\n",
    "        g = levels[i]\n",
    "        f = df[i]\n",
    "        f_ibsc = (\n",
    "            f\n",
    "            .filter(product_id = 1)\n",
    "            .select([g,'plan_type','cur_vol','pri_vol'])\n",
    "            .rename({'cur_vol':'lax_cur_vol','pri_vol':'lax_pri_vol'})\n",
    "        )\n",
    "        f = (\n",
    "            f\n",
    "            .join(f_ibsc,on = [g,'plan_type'],how = 'left')\n",
    "            .with_columns(\n",
    "                (pl.col('cur_vol') / pl.col('lax_cur_vol')).alias('cur_shr'),\n",
    "                (pl.col('pri_vol') / pl.col('lax_pri_vol')).alias('pri_shr')\n",
    "            )\n",
    "            .with_columns(\n",
    "                shr_change = pl.col('cur_shr') - pl.col('pri_shr'),\n",
    "                prc_shr_growth = ((pl.col('cur_shr')/pl.col('pri_shr'))-1).replace([np.inf,np.nan],[None,None])\n",
    "            )\n",
    "            .with_columns(\n",
    "                pl.when(pl.col('shr_change')/pl.col('pri_shr') > 0.02).then(pl.lit('P'))\n",
    "                .when(pl.col('shr_change')/pl.col('pri_shr') < -0.02).then(pl.lit('Q'))\n",
    "                .when(pl.col('shr_change')==0).then(None)\n",
    "                .otherwise(None).alias('shr_change_ind')\n",
    "            )\n",
    "            .drop(['lax_cur_vol','lax_pri_vol'])\n",
    "        )\n",
    "        df[i] = f\n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ca107054-6272-457a-b4ca-54ea3d7ecac7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# prc_shr_growth_bnch\n",
    "def process_6(df):\n",
    "    for i in range(4):\n",
    "        g = levels[i]\n",
    "        f = df[i]\n",
    "        # for terr ->\n",
    "        f_region = (\n",
    "            df[1].select([levels[1],'plan_type','product_id','prc_shr_growth']).rename({'prc_shr_growth':'prc_shr_growth_bnch'})\n",
    "        )\n",
    "        # for Region, Area ->\n",
    "        f_nation = (\n",
    "            df[3].select([levels[3],'plan_type','product_id','prc_shr_growth']).rename({'prc_shr_growth':'prc_shr_growth_bnch'})\n",
    "        )\n",
    "\n",
    "        if i == 0:\n",
    "            f = (\n",
    "                f\n",
    "                .join(geo_code_mapper.select(levels[i],levels[i+1]).unique(),on = g , how='left')\n",
    "                .join(f_region, on = [levels[i+1],'plan_type','product_id'],how = 'left')\n",
    "                .drop(levels[i+1])\n",
    "            )\n",
    "        elif (( i==1 ) | (i ==2)):\n",
    "            f = (\n",
    "                f\n",
    "                .join(geo_code_mapper.select(levels[i],levels[3]).unique(),on = g , how='left')\n",
    "                .join(f_nation, on = [levels[3],'plan_type','product_id'],how = 'left')\n",
    "                .drop(levels[3])\n",
    "            )\n",
    "        else:\n",
    "            f = (\n",
    "                f\n",
    "                .with_columns(prc_shr_growth_bnch = pl.col('prc_shr_growth'))\n",
    "            )\n",
    "        df[i] = f\n",
    "\n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0780c443-d032-40e3-86af-8899c4cd213f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# prc_vol_growth_ind ,prc_shr_growth_ind\n",
    "def process_7(df):\n",
    "    for i in range(4):\n",
    "        g = levels[i]\n",
    "        f = df[i]\n",
    "        f = (\n",
    "            f\n",
    "            .with_columns(\n",
    "                pl.when((pl.col('prc_vol_growth') >  pl.col('prc_vol_growth_bnch'))).then(pl.lit('L')).otherwise(pl.lit('\\\\N')).alias('prc_vol_growth_ind'),\n",
    "                pl.when((pl.col('prc_shr_growth') >  pl.col('prc_shr_growth_bnch'))).then(pl.lit('L')).otherwise(pl.lit('\\\\N')).alias('prc_shr_growth_ind')\n",
    "            )\n",
    "        )\n",
    "        df[i] = f\n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ce968b-93d3-4766-bc06-9b57cc5a562c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701bde74-4276-4870-92ab-7ad769f208db",
   "metadata": {},
   "source": [
    "#### Period Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "832ac8e5-f9d2-45d1-851f-43cb3beca35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "period = '_1'\n",
    "temp1 = process_1() # cur_vol , pri_vol , vol_change, prc_vol_growth, vol_change_ind, avg_trx_size\n",
    "temp1 = process_2(temp1) # sales dist\n",
    "temp1 = process_3(temp1) # sales dist_bnch\n",
    "temp1 = process_4(temp1) # prc_vol_growth_bnch\n",
    "temp1 = process_5(temp1)# cur_shr, pri_shr, shr_change, prc_shr_growth, shr_change_ind\n",
    "temp1 = process_6(temp1) # prc_shr_growth_bnch\n",
    "temp1 = process_7(temp1)# prc_vol_growth_ind ,prc_shr_growth_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cc8df5e2-2ba6-44da-b6db-03c33caf966a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 10)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>IID</th><th>PeriodKey</th><th>PFAM_CD</th><th>PROD_CD</th><th>PlanID</th><th>TUF</th><th>TRX</th><th>TUN</th><th>num_month</th><th>IRWD_FGN_NAME</th></tr><tr><td>i64</td><td>date</td><td>str</td><td>str</td><td>i64</td><td>f64</td><td>f64</td><td>f64</td><td>u32</td><td>str</td></tr></thead><tbody><tr><td>32746</td><td>2024-01-31</td><td>&quot;LIN&quot;</td><td>&quot;LI2&quot;</td><td>12830002</td><td>3.007</td><td>1.002</td><td>90.21</td><td>6</td><td>&quot;Bcbs Louisiana (La)  (Com)&quot;</td></tr><tr><td>2542575</td><td>2022-11-30</td><td>&quot;LIN&quot;</td><td>&quot;LI2&quot;</td><td>24291362</td><td>1.063</td><td>1.063</td><td>31.89</td><td>20</td><td>&quot;Uhc/Pacificare/Aarp Med D  (Pa…</td></tr><tr><td>1164750</td><td>2023-03-31</td><td>&quot;LIN&quot;</td><td>&quot;LI3&quot;</td><td>7000271211</td><td>0.863</td><td>0.863</td><td>25.88</td><td>16</td><td>&quot;Caremark Unspec  (Com)&quot;</td></tr><tr><td>158522</td><td>2023-12-31</td><td>&quot;LAC&quot;</td><td>&quot;LAC&quot;</td><td>24290725</td><td>0.651</td><td>1.123</td><td>530.96</td><td>7</td><td>&quot;Uhc/Pacificare/Aarp Med D  (Pa…</td></tr><tr><td>336679</td><td>2022-12-31</td><td>&quot;LAC&quot;</td><td>&quot;LAC&quot;</td><td>50720</td><td>2.207</td><td>1.333</td><td>1799.86</td><td>19</td><td>&quot;Cigna  (Part D)&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 10)\n",
       "┌─────────┬────────────┬─────────┬─────────┬───┬───────┬─────────┬───────────┬─────────────────────┐\n",
       "│ IID     ┆ PeriodKey  ┆ PFAM_CD ┆ PROD_CD ┆ … ┆ TRX   ┆ TUN     ┆ num_month ┆ IRWD_FGN_NAME       │\n",
       "│ ---     ┆ ---        ┆ ---     ┆ ---     ┆   ┆ ---   ┆ ---     ┆ ---       ┆ ---                 │\n",
       "│ i64     ┆ date       ┆ str     ┆ str     ┆   ┆ f64   ┆ f64     ┆ u32       ┆ str                 │\n",
       "╞═════════╪════════════╪═════════╪═════════╪═══╪═══════╪═════════╪═══════════╪═════════════════════╡\n",
       "│ 32746   ┆ 2024-01-31 ┆ LIN     ┆ LI2     ┆ … ┆ 1.002 ┆ 90.21   ┆ 6         ┆ Bcbs Louisiana (La) │\n",
       "│         ┆            ┆         ┆         ┆   ┆       ┆         ┆           ┆ (Com)               │\n",
       "│ 2542575 ┆ 2022-11-30 ┆ LIN     ┆ LI2     ┆ … ┆ 1.063 ┆ 31.89   ┆ 20        ┆ Uhc/Pacificare/Aarp │\n",
       "│         ┆            ┆         ┆         ┆   ┆       ┆         ┆           ┆ Med D  (Pa…         │\n",
       "│ 1164750 ┆ 2023-03-31 ┆ LIN     ┆ LI3     ┆ … ┆ 0.863 ┆ 25.88   ┆ 16        ┆ Caremark Unspec     │\n",
       "│         ┆            ┆         ┆         ┆   ┆       ┆         ┆           ┆ (Com)               │\n",
       "│ 158522  ┆ 2023-12-31 ┆ LAC     ┆ LAC     ┆ … ┆ 1.123 ┆ 530.96  ┆ 7         ┆ Uhc/Pacificare/Aarp │\n",
       "│         ┆            ┆         ┆         ┆   ┆       ┆         ┆           ┆ Med D  (Pa…         │\n",
       "│ 336679  ┆ 2022-12-31 ┆ LAC     ┆ LAC     ┆ … ┆ 1.333 ┆ 1799.86 ┆ 19        ┆ Cigna  (Part D)     │\n",
       "└─────────┴────────────┴─────────┴─────────┴───┴───────┴─────────┴───────────┴─────────────────────┘"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ln.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "240bbf91-c097-444f-9eb4-186c60969be8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_data_cuts_planid(df):\n",
    "    result = pl.DataFrame()\n",
    "    for period,cond in filter_cond_dict.items():\n",
    "        df_filter = df.filter(cond)\n",
    "        df_filter = (df_filter.group_by(['IID','PlanID','PFAM_CD','PROD_CD']).agg(pl.col('TUF').sum().alias(f'TUF_{period}')))\n",
    "        if period == '1c':\n",
    "            result = df_filter\n",
    "        else:\n",
    "            result = result.join(df_filter,on =['IID','PlanID','PFAM_CD','PROD_CD'],how = 'outer_coalesce')\n",
    "    \n",
    "    result = (\n",
    "        result\n",
    "        # Pulling Payer Name\n",
    "        .join(fm.select(['PlanID','IRWD_FGN_NAME']).unique(),on='PlanID',how='left') \n",
    "        # dropping PlanIDs not present in Formulary\n",
    "        .filter(pl.col('IRWD_FGN_NAME').is_not_null())\n",
    "        # Pulling Plan Type\n",
    "        .join(fm.select(['IRWD_FGN_NAME','PFAM_CD','plan_type']).unique(),on = ['IRWD_FGN_NAME', 'PFAM_CD'], how = 'left') \n",
    "        .with_columns(pl.col('plan_type').fill_null(pl.lit('Others')))\n",
    "        #Pulling Plan Class\n",
    "        .join(fm2, on=['IRWD_FGN_NAME', 'PFAM_CD'], how='left') \n",
    "        .with_columns(pl.col('plan_class').fill_null(pl.lit('N_a')))\n",
    "        # Dropping Records with Voucher , FFS , Medicaid\n",
    "        .filter(~(pl.col('plan_type').is_in(['Voucher','Mgd Medicaid','FFS'])))\n",
    "        #Joining Payer ID-\n",
    "        .join(payer_names, on ='IRWD_FGN_NAME', how = 'left')\n",
    "        # adding product_id\n",
    "        .join(prod_mapping.select(['code','product_id','parent_product_id']),left_on = 'PROD_CD', right_on='code', how = 'left')\n",
    "    )\n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a7fa404c-13f7-460f-9d86-1270c7afb54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ln1_planid = get_data_cuts_planid(ln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "463cd220-8b36-418e-bb31-12f1387fa0a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 20)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>geography_id</th><th>plan_type</th><th>product_id</th><th>cur_vol</th><th>pri_vol</th><th>vol_change</th><th>prc_vol_growth</th><th>avg_trx_size</th><th>vol_change_ind</th><th>sales_dist</th><th>sales_dist_bnch</th><th>prc_vol_growth_bnch</th><th>cur_shr</th><th>pri_shr</th><th>shr_change</th><th>prc_shr_growth</th><th>shr_change_ind</th><th>prc_shr_growth_bnch</th><th>prc_vol_growth_ind</th><th>prc_shr_growth_ind</th></tr><tr><td>i64</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>str</td><td>f64</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>55</td><td>&quot;Cash&quot;</td><td>5.0</td><td>1.946</td><td>0.976</td><td>0.97</td><td>0.993852</td><td>30.0</td><td>&quot;P&quot;</td><td>0.000911</td><td>0.003712</td><td>-0.23063</td><td>0.056044</td><td>0.018526</td><td>0.037518</td><td>2.025203</td><td>&quot;P&quot;</td><td>-0.139224</td><td>&quot;L&quot;</td><td>&quot;L&quot;</td></tr><tr><td>35</td><td>&quot;Cash&quot;</td><td>3.0</td><td>0.0</td><td>4.918</td><td>-4.918</td><td>-1.0</td><td>null</td><td>&quot;Q&quot;</td><td>0.0</td><td>0.000795</td><td>-0.5198</td><td>0.0</td><td>0.143323</td><td>-0.143323</td><td>-1.0</td><td>&quot;Q&quot;</td><td>-0.452921</td><td>&quot;\\N&quot;</td><td>&quot;\\N&quot;</td></tr><tr><td>65</td><td>&quot;Part D&quot;</td><td>8.0</td><td>948.947</td><td>951.618</td><td>-2.671</td><td>-0.002807</td><td>1110.447728</td><td>null</td><td>0.525013</td><td>0.56771</td><td>-0.102582</td><td>0.22055</td><td>0.210154</td><td>0.010395</td><td>0.049465</td><td>&quot;P&quot;</td><td>-0.02105</td><td>&quot;L&quot;</td><td>&quot;L&quot;</td></tr><tr><td>81</td><td>&quot;Commercial&quot;</td><td>35.0</td><td>439.871</td><td>428.128</td><td>11.743</td><td>0.027429</td><td>78.891459</td><td>&quot;P&quot;</td><td>0.638851</td><td>0.548539</td><td>-0.039255</td><td>0.11043</td><td>0.104077</td><td>0.006353</td><td>0.061037</td><td>&quot;P&quot;</td><td>0.000549</td><td>&quot;L&quot;</td><td>&quot;L&quot;</td></tr><tr><td>95</td><td>&quot;Commercial&quot;</td><td>2.0</td><td>2541.306</td><td>2614.423</td><td>-73.117</td><td>-0.027967</td><td>50.45237</td><td>&quot;Q&quot;</td><td>0.557729</td><td>0.498686</td><td>-0.025971</td><td>0.568248</td><td>0.56647</td><td>0.001778</td><td>0.003139</td><td>null</td><td>-0.000916</td><td>&quot;\\N&quot;</td><td>&quot;L&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 20)\n",
       "┌───────────┬───────────┬───────────┬──────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ geography ┆ plan_type ┆ product_i ┆ cur_vol  ┆ … ┆ shr_chang ┆ prc_shr_g ┆ prc_vol_g ┆ prc_shr_g │\n",
       "│ _id       ┆ ---       ┆ d         ┆ ---      ┆   ┆ e_ind     ┆ rowth_bnc ┆ rowth_ind ┆ rowth_ind │\n",
       "│ ---       ┆ str       ┆ ---       ┆ f64      ┆   ┆ ---       ┆ h         ┆ ---       ┆ ---       │\n",
       "│ i64       ┆           ┆ f64       ┆          ┆   ┆ str       ┆ ---       ┆ str       ┆ str       │\n",
       "│           ┆           ┆           ┆          ┆   ┆           ┆ f64       ┆           ┆           │\n",
       "╞═══════════╪═══════════╪═══════════╪══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 55        ┆ Cash      ┆ 5.0       ┆ 1.946    ┆ … ┆ P         ┆ -0.139224 ┆ L         ┆ L         │\n",
       "│ 35        ┆ Cash      ┆ 3.0       ┆ 0.0      ┆ … ┆ Q         ┆ -0.452921 ┆ \\N        ┆ \\N        │\n",
       "│ 65        ┆ Part D    ┆ 8.0       ┆ 948.947  ┆ … ┆ P         ┆ -0.02105  ┆ L         ┆ L         │\n",
       "│ 81        ┆ Commercia ┆ 35.0      ┆ 439.871  ┆ … ┆ P         ┆ 0.000549  ┆ L         ┆ L         │\n",
       "│           ┆ l         ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 95        ┆ Commercia ┆ 2.0       ┆ 2541.306 ┆ … ┆ null      ┆ -0.000916 ┆ \\N        ┆ L         │\n",
       "│           ┆ l         ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n",
       "└───────────┴───────────┴───────────┴──────────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp1[0].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
