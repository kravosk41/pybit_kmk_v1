{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9093d862-3996-4963-9ba0-2a631d59b4fa",
   "metadata": {},
   "source": [
    "# Managed Care - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c67f8016-f024-4138-85b9-58ef60b45afd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# importing modules\n",
    "import polars as pl\n",
    "import gc\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta,date\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "baa66e65-d365-40ee-9091-dbf15b58bd23",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# load variables from JSON\n",
    "with open('vars_wk.json', 'r') as json_file:\n",
    "    js = json.load(json_file)\n",
    "\n",
    "\n",
    "bucket = js['bucket']\n",
    "data_date = js['data_date']\n",
    "monthly_data_date = js['monthly_data_date']\n",
    "QTD = js['QTD']\n",
    "YTD = js['YTD']\n",
    "\n",
    "\n",
    "dflib = f's3://{bucket}/BIT/dataframes/'\n",
    "pln = f's3://{bucket}/PYADM/weekly/archive/{data_date}/plantrak/' \n",
    "mpln = f's3://{bucket}/PYADM/monthly/archive/{monthly_data_date}/plantrak/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de6eadf7-8b3f-4138-ace1-541a2a5ec32a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Utility Functions -\n",
    "def load(df, lib=dflib):\n",
    "    globals()[df] = pl.read_parquet(f'{lib}{df}.parquet')\n",
    "def offload(df, name, lib=dflib, ef = 'NA' ):\n",
    "    file = f'{dflib}mc/{name}.parquet'\n",
    "\n",
    "    if ef == 'NA':\n",
    "        globals()[df].to_pandas().to_parquet(file, index =False)\n",
    "    else:\n",
    "        globals()[df][ef].to_pandas().to_parquet(file, index =False)\n",
    "\n",
    "    print('Exported : ', file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "361f1d90-204a-4c91-899a-24da3080b7d0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Imporing Dependencies\n",
    "prod_mapping = pl.read_csv(f's3://{bucket}/BIT/docs/productmapping_pybit.txt',separator='|')\n",
    "geo_code_mapper = pl.from_pandas(pd.read_excel(f's3://{bucket}/BIT/docs/geo_id_full.xlsx'))\n",
    "load('mp_spec_seg_dec')\n",
    "load('MASTER_UNI')\n",
    "fetch_products = ['LI1','LI2','LI3','TRU','AMT','LAC','MOT','LUB','IRL']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0337aa-d1d3-4a54-9b73-b67d5f9897de",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3431f8-04c2-40c9-b23e-a550f174de85",
   "metadata": {},
   "source": [
    "#### Importing Raw Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddf0e30-9325-416a-b06c-a7c0097251ee",
   "metadata": {},
   "source": [
    "##### Formulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc723749-2447-4637-a0fc-a57aa71cdc10",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Processing Formulary Datasets -\n",
    "columns_to_read = ['IMS_PLAN_ID','GROUP_TYPE','FORMULARY_GROUP_STATUS','PFAM_CD','PFAM_NAME','IRWD_FGN_NAME','BRAND']\n",
    "\n",
    "fm_monthly = pl.read_parquet(\n",
    "    mpln+'FORMULARY.parquet',columns = columns_to_read\n",
    ")\n",
    "\n",
    "fm_weekly = pl.read_parquet(\n",
    "    pln+'FORMULARY.parquet',columns = columns_to_read\n",
    ")\n",
    "\n",
    "# Consolidating list of Unique Payer Names -\n",
    "payer_names = (\n",
    "    fm_monthly.select('IRWD_FGN_NAME')\n",
    "    .vstack(fm_weekly.select('IRWD_FGN_NAME'))\n",
    "    .unique()\n",
    "    .sort('IRWD_FGN_NAME')\n",
    "    .with_row_index(offset=1)\n",
    "    .rename({'index':'payer_id'})\n",
    ")\n",
    "\n",
    "#FORMULARY\n",
    "group_type_mapping = {\n",
    "    'HIX' : 'Commercial','Com' : 'Commercial','Cash' : 'Cash','Voucher':'Voucher',\n",
    "    'FFS' : 'FFS','Mgd Medicaid' : 'Mgd Medicaid','Part D' : 'Part D','MAC A' : 'Others',\n",
    "}\n",
    "\n",
    "def classify_plan_class(status):\n",
    "    status = status.upper()\n",
    "    if status[:7] == \"COVERED\" or status[:6] == \"ON PDL\":\n",
    "        return \"COVERED\"\n",
    "    elif status[:9] == \"PREFERRED\":\n",
    "        return \"PREFERRED\"\n",
    "    elif status[:13] == \"NON-PREFERRED\":\n",
    "        return \"NON PREFERRED\"\n",
    "    elif status[:7] == \"NON-PDL\" or status[:11] == \"NOT COVERED\":\n",
    "        return \"NOT COVERED\"\n",
    "    else:\n",
    "        return \"N_A\"\n",
    "\n",
    "fm = fm_monthly.with_columns(\n",
    "        pl.when(pl.col('BRAND')=='IBR')\n",
    "        .then(pl.lit('IRL'))\n",
    "        .otherwise(pl.col('BRAND'))\n",
    "        .alias('BRAND')\n",
    ")\n",
    "\n",
    "fm = fm.filter((pl.col('PFAM_CD')==(pl.col('BRAND'))) | (pl.col('BRAND')==''))\n",
    "\n",
    "fm = (\n",
    "    fm\n",
    "    .with_columns(\n",
    "        pl.col('GROUP_TYPE').map_elements(lambda x: group_type_mapping.get(x,'Others'), return_dtype=pl.Utf8) #NOTE : IF new plan types flow , they will go to Others by default\n",
    "        .fill_null('Others')\n",
    "        .alias('plan_type'),\n",
    "        pl.col('IMS_PLAN_ID').cast(pl.Int64)\n",
    "    )\n",
    "    .rename({'IMS_PLAN_ID':'PlanID'})\n",
    "    .drop('GROUP_TYPE')\n",
    "    .with_columns(pl.col('FORMULARY_GROUP_STATUS').fill_null(pl.lit('N_A')))\n",
    "    .with_columns(pl.col('FORMULARY_GROUP_STATUS').map_elements(classify_plan_class,return_dtype=pl.String).alias('plan_class'))\n",
    "    .drop('FORMULARY_GROUP_STATUS')\n",
    "    .unique()\n",
    ")\n",
    "\n",
    "###############\n",
    "# HARD CODED - \n",
    "fm = fm.with_columns(pl.when(pl.col(\"PlanID\") == 13670614).then(pl.lit('Others')).otherwise(pl.col(\"plan_type\")).alias(\"plan_type\"))\n",
    "###############\n",
    "fm2 = (\n",
    "    fm\n",
    "    .select('PFAM_CD','IRWD_FGN_NAME','plan_class').unique()\n",
    "    .group_by(['IRWD_FGN_NAME','PFAM_CD'])\n",
    "    .agg(\n",
    "        pl.col('plan_class').unique().str.concat(' / ').alias('plan_class')\n",
    "    )\n",
    "    .with_columns(pl.col('plan_class').str.to_titlecase())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fdbe71-87fa-4aec-bf58-9d17cafe822c",
   "metadata": {},
   "source": [
    "##### Plantrak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a68a8296-18d2-4ddf-8757-0fd173ded788",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Import and prepare Raw data - # INPUT : Adm Files # OUTPUT : ln\n",
    "ln = (\n",
    "    pl.read_parquet(mpln+'LAX_N.parquet',columns=['IID','MonthKey','PFAM_CD','PROD_CD','PlanID','TUF']) \n",
    "    .rename({'MonthKey':'PeriodKey'})\n",
    "    .filter(pl.col('PROD_CD').is_in(fetch_products)) #only keep data for BIT products\n",
    "    .with_columns(pl.col('PeriodKey').cast(pl.Utf8).str.to_date(\"%Y%m%d\")) #Convert Categorical column Back to date\n",
    ")\n",
    "date_list = ln['PeriodKey'].unique().sort(descending=True)\n",
    "\n",
    "# Any PlanIds startign with -0000002 should be excluded\n",
    "ln = (\n",
    "    ln\n",
    "    .with_columns(pl.col('PlanID').cast(pl.Utf8).str.zfill(10).alias('planid_chr'))\n",
    "    .filter(~pl.col('planid_chr').str.starts_with('000002'))\n",
    "    .drop('planid_chr')\n",
    ")\n",
    "\n",
    "ln = ln.join(\n",
    "    (pl.DataFrame(date_list).with_row_index(offset = 1).rename({'index':'num_month'})),\n",
    "    on = 'PeriodKey', how = 'left'\n",
    ")\n",
    "\n",
    "ln = (\n",
    "    ln\n",
    "    .join(fm.select(['PlanID','IRWD_FGN_NAME']).unique(),on='PlanID',how='left')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e49aeb27-f22e-4856-891e-e299135a4172",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Data Cuts and Restructure - # Input ln # Output = ln1\n",
    "ln1 = (\n",
    "    ln\n",
    "    .join(payer_names,on = 'IRWD_FGN_NAME',how='left')\n",
    "    .filter(pl.col('payer_id').is_not_null())\n",
    "    # Added payer_id \n",
    "    .filter(pl.col('num_month')<=13)\n",
    "    # Only need 13 Months of volume\n",
    "    .pivot(\n",
    "        values = 'TUF',\n",
    "        columns = 'num_month',\n",
    "        index = ['IID','PFAM_CD','PROD_CD','payer_id'],\n",
    "        aggregate_function='sum',maintain_order=True\n",
    "    )\n",
    "    .rename({f'{i}':f'VOL{i}' for i in range(1,14)})\n",
    "    # Pulling in plan type -\n",
    "    .join(fm.select(['IRWD_FGN_NAME','PFAM_CD','plan_type']).join(payer_names,on='IRWD_FGN_NAME',how='left').unique(),on = ['payer_id', 'PFAM_CD'], how = 'left')\n",
    "    .with_columns(pl.col('plan_type').fill_null(pl.lit('Others')))\n",
    "    # Dropping FFS , Medicaid , Voucher \n",
    "    .filter(~(pl.col('plan_type').is_in(['Voucher','Mgd Medicaid','FFS'])))\n",
    "    # product_id ->\n",
    "    .join(\n",
    "        prod_mapping.select(['code','product_id','parent_product_id']),\n",
    "        left_on = 'PROD_CD', right_on='code', how = 'left'\n",
    "    )\n",
    "    .select(['IID','payer_id','product_id','parent_product_id','plan_type'] + [f'VOL{i}' for i in range(1,14)]).fill_null(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90b26b20-3947-4c1e-818f-9fd5141e53b7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Adding Parent Product Rows # Input ln1 # Output ln2\n",
    "\n",
    "def get_parent_rows(ln1):\n",
    "    agg_dict = {c : pl.col(c).sum() for c in [f'VOL{i}' for i in range(1,14)]}\n",
    "    agg_dict.update({'plan_type':pl.col('plan_type').first()})\n",
    "    \n",
    "    #lin and amt-\n",
    "    ln1_235 = (\n",
    "        ln1\n",
    "        .filter(pl.col('parent_product_id').is_in([2,35]))\n",
    "        .group_by(['IID','payer_id','parent_product_id'])\n",
    "        .agg(**agg_dict)\n",
    "        .rename({'parent_product_id':'product_id'})\n",
    "    )\n",
    "    \n",
    "    #for lax mkt - \n",
    "    ln1_1 = (\n",
    "        ln1\n",
    "        .group_by(['IID','payer_id'])\n",
    "        .agg(**agg_dict)\n",
    "        .with_columns(pl.lit(1).alias('product_id').cast(pl.Int64),pl.lit('N_a').alias('plan_class'))\n",
    "        .select(ln1_235.columns)\n",
    "    )\n",
    "    \n",
    "    ln2 = (\n",
    "        ln1.select(ln1_235.columns)\n",
    "        .vstack(ln1_235)\n",
    "        .vstack(ln1_1)\n",
    "    )\n",
    "    \n",
    "    # Adding Geography Information and Removing any White Space HCPs-\n",
    "    ln2 = (\n",
    "        ln2\n",
    "        .join(mp_spec_seg_dec[['IID','geography_id']],on='IID',how='left')\n",
    "        .join(geo_code_mapper,on = 'geography_id', how = 'left')\n",
    "        .filter(pl.col('geography_id').is_not_null()) \n",
    "        # DTYPE FIXES \n",
    "        .with_columns(\n",
    "            pl.col('IID').cast(pl.Int64),\n",
    "            pl.col('payer_id').cast(pl.Int64),\n",
    "            pl.col('geography_id').cast(pl.Int64),\n",
    "            pl.col('region_geography_id').cast(pl.Int64),\n",
    "            pl.col('area_geography_id').cast(pl.Int64),\n",
    "            pl.col('nation_geography_id').cast(pl.Int64),\n",
    "        )\n",
    "    )\n",
    "    return (ln2)\n",
    "\n",
    "ln2 = get_parent_rows(ln1)\n",
    "\n",
    "#adding columns to facilitate filter joins \n",
    "ln2 = (\n",
    "    ln2\n",
    "    .with_columns(\n",
    "        pl.lit('Total').alias('plan_type_group1'),\n",
    "        pl.when(pl.col('plan_type').is_in(['Part D', 'Commercial'])).then(pl.lit('Part D and Commercial')).otherwise(None).alias('plan_type_group2')\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43a470f1-2046-4725-9e7b-f3585b1ef508",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Clean up-\n",
    "del ln\n",
    "del ln1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66d9e06-4a51-4b7a-ab24-7c7c6db40214",
   "metadata": {},
   "source": [
    "##### Ranking Datasets -(Loaded from MC-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64f00b0f-93a8-4491-9539-b3d3585957d3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Importing Parquets -\n",
    "top_hcps = []\n",
    "top_payers = []\n",
    "for i in range(4):\n",
    "    file1 = f's3://vortex-staging-a65ced90/BIT/dataframes/mc/top_hcps_{i}.parquet'\n",
    "    file2 = f's3://vortex-staging-a65ced90/BIT/dataframes/mc/top_payers_{i}.parquet'\n",
    "    top_hcps.append(pl.read_parquet(file1))\n",
    "    top_payers.append(pl.read_parquet(file2))\n",
    "levels = ['geography_id','region_geography_id','area_geography_id','nation_geography_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65e3ae9-63a9-47c0-a854-a9bbf208e9b9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645efe37-67e4-4dd9-aa54-004fde570e75",
   "metadata": {},
   "source": [
    "First Drill Down Functions -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d48e372-fb0f-4178-971b-8b22d732c0a1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Volume Trend - \n",
    "def process_1():\n",
    "    res = []\n",
    "    for i in range(4):\n",
    "        g = levels[i]\n",
    "        agg_expn = {c : pl.col(c).sum() for c in [f'VOL{i}' for i in range(1,14)]}\n",
    "        df = (ln2.group_by([g,'plan_type','product_id']).agg(**agg_expn))\n",
    "        df_t = (ln2.group_by([g,'plan_type_group1','product_id']).agg(**agg_expn).rename({'plan_type_group1' : 'plan_type'}).select(df.columns))\n",
    "        df_pdc = (\n",
    "            ln2.filter(pl.col('plan_type_group2').is_not_null()).group_by([g,'plan_type_group2','product_id'])\n",
    "            .agg(**agg_expn).rename({'plan_type_group2' : 'plan_type'}).select(df.columns)\n",
    "        )\n",
    "        df = df.vstack(df_t).vstack(df_pdc)\n",
    "        res.append(df)\n",
    "    return (res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13a5e30c-cca9-4763-acd2-4951c4698f80",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Share Trend\n",
    "def process_2(df):\n",
    "    for i in range(4):\n",
    "        g = levels[i]\n",
    "        f = df[i]\n",
    "        f_ibsc = (\n",
    "            f\n",
    "            .filter(product_id = 1)\n",
    "            .select([g,'plan_type'] + [f'VOL{i}' for i in range(1,14)])\n",
    "            .rename({f'VOL{i}':f'LVOL{i}' for i in range(1,14)})\n",
    "        )\n",
    "        f = (\n",
    "            f\n",
    "            .join(f_ibsc,on = [g,'plan_type'],how = 'left')\n",
    "            .with_columns(\n",
    "                *[(pl.col(f'VOL{i}')/pl.col(f'LVOL{i}')).alias(f'SHR{i}') for i in range(1,14)]\n",
    "            )\n",
    "            .drop([f'LVOL{i}' for i in range(1,14)])\n",
    "        )\n",
    "        df[i] = f\n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e653b562-17c8-4d3c-83f6-242afc0da9dc",
   "metadata": {},
   "source": [
    "Second Drill Down Functions -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c0ebdcd-0c5e-40e0-a7f4-678e56b869ac",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Volume Trend - \n",
    "def process_3():\n",
    "    res = []\n",
    "    agg_expn = {c : pl.col(c).sum() for c in [f'VOL{i}' for i in range(1,14)]}\n",
    "    for i in range(4):\n",
    "        g = levels[i]\n",
    "        df = (\n",
    "            ln2\n",
    "            .join(top_payers[i],on = [g,'plan_type','payer_id'],how = 'inner')\n",
    "            .drop(['plan_type_group1','plan_type_group2'])\n",
    "            .group_by([g,'plan_type','product_id','payer_id']).agg(**agg_expn)\n",
    "        )\n",
    "        df_t = (\n",
    "            ln2\n",
    "            .join(\n",
    "                top_payers[i].filter(plan_type = 'Total'),\n",
    "                left_on = [g,'plan_type_group1','payer_id'],right_on = [g,'plan_type','payer_id'],how = 'inner'\n",
    "            )\n",
    "            .drop(['plan_type_group2','plan_type']).rename({'plan_type_group1' : 'plan_type'}).select(df.columns)\n",
    "            .group_by([g,'plan_type','product_id','payer_id']).agg(**agg_expn)\n",
    "        )\n",
    "        df_pdc = (\n",
    "            ln2\n",
    "            .join(\n",
    "                top_payers[i].filter(plan_type = 'Part D and Commercial'),\n",
    "                left_on = [g,'plan_type_group2','payer_id'],right_on = [g,'plan_type','payer_id'],how = 'inner'\n",
    "            )\n",
    "            .drop(['plan_type_group1','plan_type']).rename({'plan_type_group2' : 'plan_type'}).select(df.columns)\n",
    "            .group_by([g,'plan_type','product_id','payer_id']).agg(**agg_expn)\n",
    "        )\n",
    "        df = df.vstack(df_t).vstack(df_pdc)\n",
    "        res.append(df)\n",
    "    return (res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e07f2ac1-93ba-4e23-b420-7d04dff82db6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Share Trend\n",
    "def process_4(df):\n",
    "    for i in range(4):\n",
    "        g = levels[i]\n",
    "        f = df[i]\n",
    "        f_ibsc = (\n",
    "            f\n",
    "            .filter(product_id = 1)\n",
    "            .select([g,'plan_type','payer_id'] + [f'VOL{i}' for i in range(1,14)])\n",
    "            .rename({f'VOL{i}':f'LVOL{i}' for i in range(1,14)})\n",
    "        )\n",
    "        f = (\n",
    "            f\n",
    "            .join(f_ibsc,on = [g,'plan_type','payer_id'],how = 'left')\n",
    "            .with_columns(\n",
    "                *[(pl.col(f'VOL{i}')/pl.col(f'LVOL{i}')).alias(f'SHR{i}') for i in range(1,14)]\n",
    "            )\n",
    "            .drop([f'LVOL{i}' for i in range(1,14)])\n",
    "        )\n",
    "        df[i] = f\n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1720ba-5d7d-4328-a730-6a11875fcd18",
   "metadata": {},
   "source": [
    "Third Drill Down Functions -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b04eca53-2cae-4ccd-ab1f-02fd3a434e04",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Volume Trend\n",
    "def process_5():\n",
    "    res = []\n",
    "    agg_expn = {c : pl.col(c).sum() for c in [f'VOL{i}' for i in range(1,14)]}\n",
    "    for i in range(4):\n",
    "        g = levels[i]\n",
    "        source_df = (\n",
    "            ln2.with_columns(pl.lit(-1).cast(pl.Int64).alias('payer_id_group1'))\n",
    "        )\n",
    "        # Limit data to keep just top 30 HCPs \n",
    "        # For 4 main plan_type\n",
    "        # for top 10 Payers\n",
    "        df_1a = (\n",
    "            source_df\n",
    "            .join(top_hcps[i],on = [g,'plan_type','payer_id','IID'], how='inner')\n",
    "            .drop(['plan_type_group1','plan_type_group2'])\n",
    "            .group_by([g,'product_id','plan_type','payer_id','IID']).agg(**agg_expn)\n",
    "        )\n",
    "        # For 'total' payer_id\n",
    "        df_1b = (\n",
    "            source_df\n",
    "            .join(top_hcps[i],left_on = [g,'plan_type','payer_id_group1','IID'],right_on = [g,'plan_type','payer_id','IID'], how='inner')\n",
    "            .drop(['plan_type_group1','plan_type_group2','payer_id'])\n",
    "            .rename({'payer_id_group1':'payer_id'})\n",
    "            .group_by([g,'product_id','plan_type','payer_id','IID']).agg(**agg_expn)\n",
    "        )\n",
    "        df_1 = df_1a.vstack(df_1b)\n",
    "\n",
    "        # For plan_type = 'Total'\n",
    "        # For top 10 Payers\n",
    "        df_2a = (\n",
    "            source_df\n",
    "            .join(top_hcps[i],left_on = [g,'plan_type_group1','payer_id','IID'],right_on = [g,'plan_type','payer_id','IID'],how='inner')\n",
    "            .drop(['plan_type_group2','plan_type']).rename({'plan_type_group1' : 'plan_type'})\n",
    "            .group_by([g,'product_id','plan_type','payer_id','IID']).agg(**agg_expn)\n",
    "        )\n",
    "\n",
    "        # For 'total' payer_id\n",
    "        df_2b = (\n",
    "            source_df\n",
    "            .join(top_hcps[i],left_on = [g,'plan_type_group1','payer_id_group1','IID'],right_on = [g,'plan_type','payer_id','IID'],how='inner')\n",
    "            .drop(['plan_type_group2','plan_type','payer_id']).rename({'plan_type_group1' : 'plan_type','payer_id_group1':'payer_id'})\n",
    "            .group_by([g,'product_id','plan_type','payer_id','IID']).agg(**agg_expn)\n",
    "        )\n",
    "        df_2 = df_2a.vstack(df_2b)\n",
    "\n",
    "        # For plan_type = 'Part D and Com'\n",
    "        # For top 10 Payers\n",
    "        df_3a = (\n",
    "            source_df\n",
    "            .join(top_hcps[i],left_on = [g,'plan_type_group2','payer_id','IID'],right_on = [g,'plan_type','payer_id','IID'],how='inner')\n",
    "            .drop(['plan_type_group1','plan_type']).rename({'plan_type_group2' : 'plan_type'})\n",
    "            .group_by([g,'product_id','plan_type','payer_id','IID']).agg(**agg_expn)\n",
    "        )\n",
    "        # For 'total' payer_id\n",
    "        df_3b = (\n",
    "            source_df\n",
    "            .filter(pl.col('plan_type_group2').is_not_null())\n",
    "            .join(top_hcps[i],left_on = [g,'plan_type_group2','payer_id_group1','IID'],right_on = [g,'plan_type','payer_id','IID'],how='inner')\n",
    "            .drop(['plan_type_group1','plan_type','payer_id']).rename({'plan_type_group2' : 'plan_type','payer_id_group1':'payer_id'})\n",
    "            .group_by([g,'product_id','plan_type','payer_id','IID']).agg(**agg_expn)\n",
    "        )\n",
    "        df_3 = df_3a.vstack(df_3b)\n",
    "        df_4 = df_1.vstack(df_2).vstack(df_3)\n",
    "        #######################################################################\n",
    "        res.append(df_4)\n",
    "    return (res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c53fe9e8-e8af-4d64-9ab9-9063cbd15534",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Share Trend\n",
    "def process_6(df):\n",
    "    for i in range(4):\n",
    "        g = levels[i]\n",
    "        f = df[i]\n",
    "        f_ibsc = (\n",
    "            f\n",
    "            .filter(product_id = 1)\n",
    "            .select([g,'plan_type','payer_id','IID'] + [f'VOL{i}' for i in range(1,14)])\n",
    "            .rename({f'VOL{i}':f'LVOL{i}' for i in range(1,14)})\n",
    "        )\n",
    "        f = (\n",
    "            f\n",
    "            .join(f_ibsc,on = [g,'plan_type','payer_id','IID'],how = 'left')\n",
    "            .with_columns(\n",
    "                *[(pl.col(f'VOL{i}')/pl.col(f'LVOL{i}')).alias(f'SHR{i}') for i in range(1,14)]\n",
    "            )\n",
    "            .drop([f'LVOL{i}' for i in range(1,14)])\n",
    "        )\n",
    "        df[i] = f\n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46b3177-5c7f-4ef0-b81e-2c6af07fa5e8",
   "metadata": {},
   "source": [
    "Miscellaneous Functions -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8efc4b69-06ec-4a47-aa21-6638ad187c3e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# inputs : temp1, temp2, temp3 # output : temp4 -> all levels combined , all geos levels also combined \n",
    "def dataframe_reorg_util():\n",
    "    temp1_full = []\n",
    "    temp2_full = []\n",
    "    temp3_full = []\n",
    "    # For Layer 1 ->\n",
    "    for i in range(4):\n",
    "        column_order = temp3[i].columns\n",
    "        f = temp1[i]\n",
    "        f = (\n",
    "            f\n",
    "            .vstack(\n",
    "                f.filter(plan_type = 'Total').with_columns(pl.lit('\\\\N').alias('plan_type'))\n",
    "            )\n",
    "            .with_columns(*[pl.lit('\\\\N').alias(c) for c in ['IID','payer_id'] ])\n",
    "            .select(column_order)\n",
    "        )\n",
    "        temp1_full.append(f)\n",
    "    \n",
    "    cd = [[],[],[],[]] # For Matching dtype for vstack\n",
    "    for i in range(4):\n",
    "        for c,t in zip(temp1_full[i].columns,temp1_full[0].dtypes):\n",
    "            expression = pl.col(c).cast(t).alias(c)\n",
    "            cd[i].append(expression)\n",
    "    \n",
    "    # For Layer 2->\n",
    "    for i in range(4):\n",
    "        column_order = temp3[i].columns\n",
    "        f = temp2[i]\n",
    "        f = (\n",
    "            f\n",
    "            .vstack(\n",
    "                temp1[i].with_columns(pl.lit(-1).cast(pl.Int64).alias('payer_id')).select(temp2[i].columns)\n",
    "            )\n",
    "            .with_columns(*[pl.lit('\\\\N').alias(c) for c in ['IID'] ])\n",
    "            .select(column_order)\n",
    "            .with_columns(*cd[i])\n",
    "        )\n",
    "        temp2_full.append(f)\n",
    "    \n",
    "    # For Layer 3- >\n",
    "    for i in range(4):\n",
    "        f = temp3[i]\n",
    "        f = f.with_columns(*cd[i])\n",
    "        temp3_full.append(f)\n",
    "    \n",
    "    temp_main = []\n",
    "    for i in range(4):\n",
    "        temp_main.append(\n",
    "            temp1_full[i]\n",
    "            .vstack(temp2_full[i])\n",
    "            .vstack(temp3_full[i])\n",
    "        )\n",
    "    temp_final = (\n",
    "        temp_main[0]\n",
    "        .vstack(temp_main[1].rename({levels[1]:levels[0]}).select(temp_main[0].columns))\n",
    "        .vstack(temp_main[2].rename({levels[2]:levels[0]}).select(temp_main[0].columns))\n",
    "        .vstack(temp_main[3].rename({levels[3]:levels[0]}).select(temp_main[0].columns))\n",
    "    )\n",
    "    return(temp_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30bdcc5f-09b9-4f42-a89a-79a80d644cb8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Feed Creation - >\n",
    "def get_feed(df):\n",
    "    rename_mapping = {'geography_id' : 'GEOGRAPHY_ID',\n",
    "    'product_id' : 'PRODUCT_ID',\n",
    "    'plan_type' : 'PAYERTYPE',\n",
    "    'payer_id' : 'PAYER_ID',\n",
    "    'IID' : 'PHYSICIAN_ID',}\n",
    "\n",
    "    export_order = (\n",
    "        ['PRODUCT_ID','GEOGRAPHY_ID','PAYERTYPE','PAYER_ID','PHYSICIAN_ID','REPORTTYPE','PAYER_NAME','PHYSICIAN_NAME'] + \n",
    "        [f'VOL{i}' for i in range(1,14)] +\n",
    "        [f'SHR{i}' for i in range(1,14)]\n",
    "    )\n",
    "\n",
    "    mp = (\n",
    "        MASTER_UNI\n",
    "        .with_columns(pl.concat_str([pl.col('FirstName'),pl.col('LastName')],separator=' ',ignore_nulls=True).alias('PHYSICIAN_NAME'))\n",
    "        .select(['IID','PHYSICIAN_NAME']).rename({'IID':'PHYSICIAN_ID'})\n",
    "        .with_columns(pl.col('PHYSICIAN_ID').cast(pl.Utf8))\n",
    "    )\n",
    "\n",
    "    df = (\n",
    "        df\n",
    "        .rename(rename_mapping) # Getting Feed Column Names\n",
    "        .with_columns(pl.col('PAYER_ID').replace('-1','TOTAL')) # Fixing payer_id for total rows in layer 2 (coud not do before for vstack purposes)\n",
    "        .with_columns(\n",
    "            pl.when(pl.col('PAYERTYPE')=='Others').then(pl.lit('OTHERS'))\n",
    "            .when(pl.col('PAYERTYPE')=='Commercial').then(pl.lit('COMMERCIAL'))\n",
    "            .when(pl.col('PAYERTYPE')=='Cash').then(pl.lit('CASH'))\n",
    "            .when(pl.col('PAYERTYPE')=='Total').then(pl.lit('TOTAL'))\n",
    "            .when(pl.col('PAYERTYPE')=='Part D').then(pl.lit('PART D'))\n",
    "            .when(pl.col('PAYERTYPE')=='Part D and Commercial').then(pl.lit('PARTANDCOM'))\n",
    "            .otherwise(pl.col('PAYERTYPE'))\n",
    "            .alias('PAYERTYPE')\n",
    "        )# Fixing Payertype Values to match sas feed.\n",
    "        # Adding Report Type\n",
    "        .with_columns(REPORTTYPE = pl.lit('MONTHLY'))\n",
    "        .join(payer_names.with_columns(pl.col('payer_id').cast(pl.Utf8).alias('PAYER_ID')).rename({'IRWD_FGN_NAME':'PAYER_NAME'}),on = 'PAYER_ID',how='left') # Adding Payer Names Back. (IRWD FGN NAME)\n",
    "        .with_columns(pl.when(pl.col('PAYER_ID')=='TOTAL').then(pl.lit('Total')).otherwise(pl.col('PAYER_NAME')).alias('PAYER_NAME')) # Accounting a payer name for 'total' row in layer 2\n",
    "        .join(mp,on='PHYSICIAN_ID',how='left').with_columns(pl.col('PHYSICIAN_NAME').fill_null('\\\\N')) # Adding HCP name\n",
    "        .select(export_order) # Resetting Table Sequence\n",
    "    )\n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c126ab-46fb-45ca-95a1-9d748a4ece5f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4affdd-af39-40c0-8c34-87344c0e2d54",
   "metadata": {},
   "source": [
    "### Function Call ->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa2c35dc-afb3-4ac9-a06e-58b97f8a67e4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# MAIN EXECUTIVE CALLS ->\n",
    "# LAYER 1\n",
    "temp1 = process_1()\n",
    "temp1 = process_2(temp1)\n",
    "\n",
    "# LAYER 2 -\n",
    "temp2 = process_3()\n",
    "temp2 = process_4(temp2)\n",
    "\n",
    "# LAYER 3-\n",
    "temp3 = process_5()\n",
    "temp3 = process_6(temp3)\n",
    "\n",
    "# Consolidate -\n",
    "temp4 = dataframe_reorg_util()\n",
    "feed_dataset = get_feed(temp4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c8a3ad3-a718-440e-8f91-e8e68880cf54",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported Trend Feed\n"
     ]
    }
   ],
   "source": [
    "# EXPORTING FEED - \n",
    "outfile = f's3://vortex-staging-a65ced90/BIT/output/ManagedCare/Monthly_ManagedCare_Trend_Feed.txt'\n",
    "feed_dataset.to_pandas().to_csv(outfile,sep='|', lineterminator='\\r\\n',index=False)\n",
    "print('Exported Trend Feed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c178c628-05cd-473a-9ba5-cfe4a900c83c",
   "metadata": {},
   "source": [
    "---\n",
    "# X FEED \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1395be30-ef94-4633-95c6-6556454a6085",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported X Feed\n"
     ]
    }
   ],
   "source": [
    "# Get the current year from system time\n",
    "current_year = datetime.now().year\n",
    "# Generate the list of months in the format 'MMM-YY'\n",
    "start,end = datetime(current_year,YTD,1),datetime(current_year-1,YTD,1)\n",
    "months = pd.date_range(start,end,periods=13).strftime('%b-%y').tolist()[::-1]\n",
    "x_feed = pl.DataFrame({'X' : [i for i in range(13,0,-1)],'Name' : months}).sort('X')\n",
    "\n",
    "# EXPORTING FEED - \n",
    "outfile = f's3://vortex-staging-a65ced90/BIT/output/ManagedCare/Monthly_ManagedCare_X_Feed.txt'\n",
    "x_feed.to_pandas().to_csv(outfile,sep='|', lineterminator='\\r\\n',index=False)\n",
    "print('Exported X Feed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6e9050-ebca-4bd7-b2dc-061f0763d4e2",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
