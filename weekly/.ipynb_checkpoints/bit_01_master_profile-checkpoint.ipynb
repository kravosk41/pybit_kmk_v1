{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import gc\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20240816', '2024Q3', 'Q3', '2024-10-01', '2024 Q3', 'vortex-staging-a65ced90', '2024-08-30', '2024-7-01', '2024-09-30', 9, 7, 2, '202407', '20240902', '2024-05-31', '20240708', 'IBSC Primary Payer Type_2024Q1']\n"
     ]
    }
   ],
   "source": [
    "# load variables from JSON\n",
    "with open('vars_wk.json', 'r') as json_file:\n",
    "    js = json.load(json_file)\n",
    "\n",
    "data_date = js['data_date']\n",
    "qtr_data = js['qtr_data']\n",
    "qtr_ntnw = js['qtr_ntnw']\n",
    "fir_nqrt = datetime.datetime.strptime(js['fir_nqrt'],'%Y-%m-%d').date()\n",
    "targeting_folder = js['targeting_folder']\n",
    "\n",
    "bucket = js['bucket']\n",
    "\n",
    "# FOR QC\n",
    "print([v for k,v in js.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "frzmstr = f's3://{bucket}/PYADM/quaterly/{qtr_data}/reference/'\n",
    "master = f's3://{bucket}/PYADM/weekly/archive/{data_date}/reference/'\n",
    "inex = f's3://{bucket}/PYADM/reference/{qtr_data}/'\n",
    "geo = f's3://{bucket}/PYADM/quaterly/{qtr_data}/geography/'\n",
    "lincall = f's3://{bucket}/PYADM/quaterly/{qtr_data}/target/post/'\n",
    "dflib = f's3://{bucket}/BIT/dataframes/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Reading Frozen MP -\n",
    "FROZEN_MASTER = pl.read_parquet(\n",
    "    f'{frzmstr}CUSTOMER_MASTER_IC_LIN.parquet'\n",
    ")\n",
    "\n",
    "# Adding this Rename Step to match Net New column name\n",
    "FROZEN_MASTER = FROZEN_MASTER.rename(\n",
    "    {\n",
    "        'Territory':'Territory_IW1',\n",
    "        'Territory_Name':'Territory_Name_IW1'\n",
    "    }\n",
    ")\n",
    "\n",
    "# Filtering -\n",
    "FROZEN_MASTER = FROZEN_MASTER.filter(\n",
    "    (pl.col('SPEC_INCL_LIN') == 'Y') &\n",
    "    (pl.col('CustomerStatusCode') == 'Active') &\n",
    "    (pl.col('MatchCode') != '01')\n",
    ")\n",
    "\n",
    "FROZEN_MASTER = FROZEN_MASTER.drop(['ACCT_TERR_END_DATE', 'ACCT_TERR_START_DATE']) \n",
    "# dropping to make schema same as Net New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Reading Net New - \n",
    "NET_NEW = pl.read_parquet(\n",
    "    f'{master}NET_NEW_{qtr_ntnw}.parquet'\n",
    ")\n",
    "\n",
    "# Filtering -\n",
    "NET_NEW = NET_NEW.filter(\n",
    "    (pl.col('SPEC_INCL_LIN') == 'Y') &\n",
    "    (pl.col('CustomerStatusCode') == 'Active') &\n",
    "    (pl.col('IC_INCL_LIN') == 1) &\n",
    "    (pl.col('MatchCode') != '01') & \n",
    "    (pl.col('CustomerEffectiveStartDate') < fir_nqrt)\n",
    ")\n",
    "\n",
    "NET_NEW = NET_NEW.drop(['IC_INCL_LIN', 'SOURCE','NPI_ID','NPI_StartDate','NPI_EndDate']) # Dropping to name schema same as Frozen MP\n",
    "NET_NEW = NET_NEW.with_columns(pl.col('DeceasedYear').cast(pl.Utf8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "## To fix Schema error -\n",
    "for c in ['FormerName','DegreeName','AddressSiteEmail','SpecialtyGroupCode','TAXONOMYID']:\n",
    "    NET_NEW = NET_NEW.with_columns(pl.col(c).cast(pl.Utf8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# bug\n",
    "NET_NEW = NET_NEW.drop('AddressFlagType_x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combining Net New and Frozen MP\n",
    "FROZEN_MASTER = FROZEN_MASTER.select(pl.col(NET_NEW.columns)) # Equalizing Schema \n",
    "\n",
    "MASTER_UNI = pl.DataFrame()\n",
    "\n",
    "MASTER_UNI = NET_NEW.vstack(FROZEN_MASTER) \n",
    "#Note for Dev : vstack,concat,extend all work differently to get same result, read more on them.\n",
    "\n",
    "#cleaning -\n",
    "del FROZEN_MASTER\n",
    "del NET_NEW\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#\"Update by devanshi\" - #CHANGE:Change Sequence for cond2 and cond3 and test - UPDATE  | REMOVE cond3\n",
    "MASTER_UNI = MASTER_UNI.with_columns(pl.lit('Other').alias('CREDENTIAL'))\n",
    "\n",
    "cond1 = MASTER_UNI[\"ProfessionalDesignation\"].is_in(\n",
    "    [\"DC\", \"DDS\", \"DMD\", \"DO\", \"DOM\", \"DPM\", \"DVM\", \"MD\", \"ND\", \"OD\", \"OP\", \"PHD\", \"VMD\"]\n",
    ")\n",
    "cond2 = MASTER_UNI[\"ProfessionalDesignation\"].is_in([\"NP\", \"PA\"])\n",
    "cond3 = (MASTER_UNI[\"ProfessionalDesignation\"] == \"NP\") & (MASTER_UNI[\"DegreeName\"] == \"REGISTERED NURSE\")\n",
    "\n",
    "MASTER_UNI = MASTER_UNI.with_columns(\n",
    "    pl.when(cond1).then(pl.lit(\"MD/DO\"))\n",
    "    .when(cond2).then(pl.lit(\"NP/PA\"))\n",
    "    .when(cond3).then(pl.lit(\"Other\"))\n",
    "    .otherwise(MASTER_UNI[\"CREDENTIAL\"])\n",
    "    .alias(\"CREDENTIAL\")\n",
    ")\n",
    "\n",
    "#sorting - \n",
    "MASTER_UNI = MASTER_UNI.sort('IID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing legal exclusions\n",
    "LEGAL_EXCLUSIONS = pl.read_parquet(\n",
    "    f'{inex}jami_inclexcl.parquet',\n",
    "    columns = ['IID','TYPE']\n",
    ")\n",
    "\n",
    "LEGAL_EXCLUSIONS = LEGAL_EXCLUSIONS.filter(\n",
    "    (pl.col('TYPE') == 'Legal Removals') | (pl.col('TYPE') == 'Unknown Address')\n",
    ")\n",
    "\n",
    "MASTER_UNI_1 = MASTER_UNI.filter(\n",
    "    ~pl.col('IID')\n",
    "    .is_in(LEGAL_EXCLUSIONS['IID'].unique())\n",
    ")\n",
    "\n",
    "#Dropping Geo columns so that we can pull then in from ztt\n",
    "MASTER_UNI_2 = MASTER_UNI_1.drop(['Territory_IW1','Territory_Name_IW1','Region','Region_Name','Area','Area_Name'])\n",
    "\n",
    "#cleaning - \n",
    "del MASTER_UNI\n",
    "del MASTER_UNI_1\n",
    "del LEGAL_EXCLUSIONS\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>ZIP</th><th>Frequency</th></tr><tr><td>str</td><td>u32</td></tr></thead><tbody><tr><td>null</td><td>1494</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 2)\n",
       "┌──────┬───────────┐\n",
       "│ ZIP  ┆ Frequency │\n",
       "│ ---  ┆ ---       │\n",
       "│ str  ┆ u32       │\n",
       "╞══════╪═══════════╡\n",
       "│ null ┆ 1494      │\n",
       "└──────┴───────────┘"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # FOR QC ##\n",
    "# Number of Recors with no ZIP\n",
    "zip_freq = MASTER_UNI_2['ZIP'].value_counts().sort('ZIP')\n",
    "zip_freq.columns = ['ZIP', 'Frequency']\n",
    "zip_freq[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ADDING ZIP ALIGNMENT AND HIERARCHY INFORMATION\n",
    "ZIP_TO_TERR = pl.read_parquet(\n",
    "    f'{geo}zip_to_terr.parquet'\n",
    ")\n",
    "ZIP_TO_TERR = ZIP_TO_TERR.rename({'Zip':'ZIP'})\n",
    "\n",
    "MASTER_UNI_3 = MASTER_UNI_2.join(\n",
    "    ZIP_TO_TERR,\n",
    "    on = 'ZIP',\n",
    "    how = 'left'\n",
    ")\n",
    "\n",
    "#cleaning -\n",
    "del MASTER_UNI_2\n",
    "del ZIP_TO_TERR\n",
    "gc.collect()\n",
    "\n",
    "whitespace_terrs = [\n",
    "    \"\", \"1111-99999-11\", \"1111-99999-21\", \"1111-99999-12\", \"1111-99999-13\",  \"1111-99999-99\"\n",
    "]\n",
    "#removing whitepsace\n",
    "MASTER_UNI_3 = MASTER_UNI_3.filter(\n",
    "    ~pl.col('Territory')\n",
    "    .is_in(whitespace_terrs)\n",
    ")\n",
    "\n",
    "#sorting - \n",
    "MASTER_UNI_3 = MASTER_UNI_3.sort('IID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Adding target and call plan info to master\n",
    "IWCALL = pl.read_parquet(\n",
    "    f'{lincall}IRWD_CALL_PLAN.parquet',\n",
    "    columns = ['IID','P1']\n",
    ")\n",
    "IWCALL = IWCALL.sort('IID')\n",
    "IWCALL = IWCALL.rename({'P1':'IW_P1'})\n",
    "IWCALL = IWCALL.with_columns(\n",
    "    [\n",
    "        pl.lit('').alias('IW_P2'), \n",
    "        pl.lit('').alias('IW_P3'),\n",
    "        pl.lit(1).alias('IW_CALL_PLAN_FLAG')\n",
    "    ]\n",
    ")\n",
    "\n",
    "ALG_CALL_PLAN = pl.read_parquet(\n",
    "    f'{lincall}ABBVIE_TARGET.parquet',\n",
    "    columns = ['IID']\n",
    ")\n",
    "\n",
    "ALG_CALL_PLAN = ALG_CALL_PLAN.with_columns([pl.lit(1).alias('ALG_CALL_PLAN_FLAG')])\n",
    "\n",
    "ALG_CALL_PLAN = ALG_CALL_PLAN.sort('IID')\n",
    "\n",
    "MASTER_UNI_4 = MASTER_UNI_3.rename({'SpecialtyCode':'specialty_cd'})\n",
    "MASTER_UNI_4 = MASTER_UNI_4.join(IWCALL, on='IID', how='left').join(ALG_CALL_PLAN, on='IID', how='left')\n",
    "MASTER_UNI_4 = MASTER_UNI_4.with_columns(\n",
    "    [\n",
    "        pl.when(pl.col('IW_CALL_PLAN_FLAG').is_not_null()).then(1).otherwise(0).alias('iw_target_flag'),\n",
    "        pl.when(pl.col('ALG_CALL_PLAN_FLAG').is_not_null() & pl.col('IW_CALL_PLAN_FLAG').is_null())\n",
    "        .then(1).otherwise(0).alias('alg_tgt_flag')\n",
    "    ]\n",
    ")\n",
    "MASTER_UNI_4 = MASTER_UNI_4.drop(['IW_CALL_PLAN_FLAG','ALG_CALL_PLAN_FLAG'])\n",
    "\n",
    "del MASTER_UNI_3\n",
    "del IWCALL\n",
    "del ALG_CALL_PLAN\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Adding specialty inclusion/exclusion and ff info to master\n",
    "SPEC_INCL = pl.read_parquet(\n",
    "    f'{frzmstr}qtrspec_SPEC_INCL_LIN.parquet',\n",
    "    columns = ['SPECIALTY_CD','SPEC_INCL']\n",
    ")\n",
    "SPEC_INCL = SPEC_INCL.rename({'SPEC_INCL':'spec_incl_lin',\n",
    "                              'SPECIALTY_CD':'specialty_cd'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "MASTER_UNI_5 = MASTER_UNI_4.join(\n",
    "    SPEC_INCL,\n",
    "    on = 'specialty_cd',\n",
    "    how = 'left'\n",
    ")\n",
    "\n",
    "MASTER_UNI_5 = MASTER_UNI_5.with_columns(\n",
    "    pl.col('Territory').str.slice(offset=11, length=2)\n",
    "    .alias('ff')\n",
    ") #Unsure of Use , subjet to removal\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Adding Spec_Group info\n",
    "SPEC_GROUPS = pl.from_pandas(pd.read_excel(f's3://{bucket}/BIT/docs/Product Def.xlsx',sheet_name='Specialty Groupings'))\n",
    "SPEC_GROUPS = SPEC_GROUPS.drop('Market')\n",
    "SPEC_GROUPS = SPEC_GROUPS.rename({'Specialty Group':'specialty_group','Specialty':'specialty_cd'})\n",
    "\n",
    "MASTER_UNI_5 = MASTER_UNI_5.join(\n",
    "    SPEC_GROUPS,\n",
    "    on = 'specialty_cd',\n",
    "    how = 'left'\n",
    ")\n",
    "MASTER_UNI_5 = MASTER_UNI_5.with_columns(pl.col('specialty_group').fill_null(\"A/O\"))\n",
    "\n",
    "MASTER_UNI_5 = MASTER_UNI_5.with_columns(\n",
    "    pl.when(pl.col('specialty_group') == 'All Others')\n",
    "    .then(pl.lit('A/O'))\n",
    "    .otherwise(pl.col('specialty_group'))\n",
    "    .alias('specialty_group')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "MASTER_UNI_5 = MASTER_UNI_5.select(\n",
    "    pl.col(\n",
    "        [\n",
    "            'IID','specialty_cd','SpecialtyDescription','specialty_group','CREDENTIAL','ZIP',\n",
    "            'ff','Territory','Territory_Name','Region','Region_Name','Area',\n",
    "            'Area_Name','IW_P1', 'IW_P2','IW_P3', 'CustomerStatusCode',  \n",
    "            'iw_target_flag', 'alg_tgt_flag', 'spec_incl_lin',\n",
    "            'FirstName','LastName','MiddleName','PDRPOptOutFlag', 'AddressLine1','AddressLine2','AddressLine3','AddressLine4',\n",
    "            'CityName','StateCode'\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Moved this section UP\n",
    "decile = pl.read_parquet(f'{lincall}ironwood_tgts_decile_{qtr_ntnw.lower()}pass1.parquet', columns = ['IID','KMK_LINZESS_DECILE'])\n",
    "\n",
    "decile.columns = ['IID','LINZESS_RATING'] #rename step\n",
    "decile[['LINZESS_RATING']] = decile[['LINZESS_RATING']].fill_null('zero')\n",
    "decile_mapping = {\n",
    "    0:'0-2',1:'0-2',2:'0-2',\n",
    "    3:'3-4',4:'3-4',\n",
    "    5:'5-7',6:'5-7',7:'5-7',\n",
    "    8:'8-10',9:'8-10',10:'8-10'\n",
    "}\n",
    "decile = decile.with_columns(LINZESS_RATING2 = pl.col('LINZESS_RATING').replace(decile_mapping))\n",
    "#decile = decile.drop('LINZESS_RATING') \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "MASTER_UNI_5 = MASTER_UNI_5.join(decile[['IID','LINZESS_RATING']],on='IID',how='left'\n",
    ").rename({'LINZESS_RATING':'DECILE'}\n",
    ").with_columns(pl.col('DECILE').fill_null(0))\n",
    "\n",
    "decile = decile.drop('LINZESS_RATING') #this is called 'deciles' in sas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "MASTER_UNI_5.to_pandas().to_parquet(f'{dflib}MASTER_UNI.parquet', compression='snappy')\n",
    "# Master Profile Done !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# segment spec and decile ->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "geo_mapping = pl.read_csv(f's3://{bucket}/BIT/docs/GeographyMapping.txt',separator='|')\n",
    "geo_mapping = geo_mapping.with_columns(\n",
    "    Code = pl.when(pl.col('Code').str.len_chars() == 8).then(pl.lit('1111-')+pl.col('Code')).otherwise(pl.col('Code'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "mp_spec_seg_dec = MASTER_UNI_5.clone()\n",
    "###\n",
    "seg_cond1 = mp_spec_seg_dec['alg_tgt_flag']==1\n",
    "seg_cond2 = mp_spec_seg_dec['iw_target_flag']==1\n",
    "\n",
    "mp_spec_seg_dec = mp_spec_seg_dec.with_columns(\n",
    "    segment = pl.when(seg_cond1).then(pl.lit('ALG-ONLY-TARGET')).when(seg_cond2).then(pl.lit('Target')).otherwise(pl.lit('Non-Target'))\n",
    ")\n",
    "mp_spec_seg_dec = mp_spec_seg_dec.join(\n",
    "    decile,\n",
    "    on = ['IID'],how='left'\n",
    ")\n",
    "\n",
    "mp_spec_seg_dec = mp_spec_seg_dec.join(\n",
    "    geo_mapping,\n",
    "    left_on = 'Territory',right_on='Code',how = 'left'\n",
    ")\n",
    "\n",
    "mp_spec_seg_dec = mp_spec_seg_dec.select(['IID','specialty_group','segment','LINZESS_RATING2','Geography_id'])\n",
    "mp_spec_seg_dec.columns = ['IID','specialty_group','segment','decile','geography_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# update :\n",
    "# to account for net new hcps , making null decile as '0-2'\n",
    "\n",
    "mp_spec_seg_dec = mp_spec_seg_dec.with_columns(pl.col('decile').fill_null('0-2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_spec_seg_dec.to_pandas().to_parquet(f'{dflib}mp_spec_seg_dec.parquet',compression='snappy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
