{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prescriber Payermix Feed\n",
    "- in sas this view is connected / dependant on a dataset from mgd care view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "import gc\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# load variables from JSON\n",
    "with open('vars_wk.json', 'r') as json_file:\n",
    "    js = json.load(json_file)\n",
    "\n",
    "data_date = js['data_date']\n",
    "monthly_data_date = js['monthly_data_date']\n",
    "bucket = js['bucket']\n",
    "\n",
    "dflib = f's3://{bucket}/BIT/dataframes/'\n",
    "pln = f's3://{bucket}/PYADM/weekly/archive/{data_date}/plantrak/'\n",
    "mpln = f's3://{bucket}/PYADM/monthly/archive/{monthly_data_date}/plantrak/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Utility Functions -\n",
    "def load(df, lib=dflib):\n",
    "    globals()[df] = pl.read_parquet(f'{lib}{df}.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Imporing Dependencies\n",
    "prod_mapping = pl.read_csv(f's3://{bucket}/BIT/docs/productmapping_pybit.txt',separator='|')\n",
    "geo_code_mapper = pl.from_pandas(pd.read_excel(f's3://{bucket}/BIT/docs/geo_id_full.xlsx'))\n",
    "load('mp_spec_seg_dec')\n",
    "load('MASTER_UNI')\n",
    "fetch_products = ['LI1','LI2','LI3','TRU','AMT','LAC','MOT','LUB','IRL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#FORMULARY\n",
    "group_type_mapping = {\n",
    "    'HIX' : 'Commerical','Com' : 'Commerical','Cash' : 'Cash','Voucher' : 'Others',\n",
    "    'FFS' : 'FFS','Mgd Medicaid' : 'Mgd Medicaid','Part D' : 'Part D','MAC A' : 'Others',\n",
    "}\n",
    "\n",
    "def classify_plan_class(status):\n",
    "    status = status.upper()\n",
    "    if status[:7] == \"COVERED\" or status[:6] == \"ON PDL\":\n",
    "        return \"COVERED\"\n",
    "    elif status[:9] == \"PREFERRED\":\n",
    "        return \"PREFERRED\"\n",
    "    elif status[:13] == \"NON-PREFERRED\":\n",
    "        return \"NON PREFERRED\"\n",
    "    elif status[:7] == \"NON-PDL\" or status[:11] == \"NOT COVERED\":\n",
    "        return \"NOT COVERED\"\n",
    "    else:\n",
    "        return \"N_A\"\n",
    "\n",
    "fm = pl.read_parquet(pln+'FORMULARY.parquet',columns = ['IMS_PLAN_ID','GROUP_TYPE','FORMULARY_GROUP_STATUS','PFAM_CD'])\n",
    "fm = (\n",
    "    fm\n",
    "    .with_columns(\n",
    "        pl.col('GROUP_TYPE').map_elements(lambda x: group_type_mapping.get(x,'Others'), return_dtype=pl.Utf8) #NOTE : IF new plan types flow , they will go to Others by default\n",
    "        .fill_null('Others')\n",
    "        .alias('plan_type'),\n",
    "        pl.col('IMS_PLAN_ID').cast(pl.Int64)\n",
    "    )\n",
    "    .rename({'IMS_PLAN_ID':'PlanID'})\n",
    "    .drop('GROUP_TYPE')\n",
    "    .with_columns(pl.col('FORMULARY_GROUP_STATUS').fill_null(pl.lit('N_A')))\n",
    "    .with_columns(pl.col('FORMULARY_GROUP_STATUS').map_elements(classify_plan_class,return_dtype=pl.String).alias('plan_class'))\n",
    "    .drop('FORMULARY_GROUP_STATUS')\n",
    "    .join(prod_mapping[['product_id','code']],left_on = 'PFAM_CD',right_on='code',how='left').drop('PFAM_CD')\n",
    "    .filter(pl.col('product_id').is_not_null())\n",
    "    .unique()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#PLANTRAK - 6 MONTH TUF at PROD , IID , PLAN LEVEL\n",
    "ln = (\n",
    "    pl.read_parquet(mpln+'LAX_N.parquet',columns=['IID','MonthKey','PROD_CD','PlanID','TUF']) #read req cols only\n",
    "    .rename({'MonthKey':'PeriodKey'})\n",
    "    .filter(pl.col('PROD_CD').is_in(fetch_products)) #only keep data for BIT products\n",
    "    .with_columns(pl.col('PeriodKey').cast(pl.Utf8).str.to_date(\"%Y%m%d\")) #Convert Categorical column Back to date\n",
    "    .join(prod_mapping[['product_id','code']],left_on = 'PROD_CD',right_on='code',how='left')\n",
    "    .drop('PROD_CD')\n",
    ")\n",
    "cut_off_date = ln['PeriodKey'].unique().sort(descending=True)[5] #filter date to only keep 6 months of data\n",
    "ln = ln.filter(pl.col('PeriodKey')>= cut_off_date)\n",
    "\n",
    "ln = (\n",
    "    ln\n",
    "    .filter(pl.col('PeriodKey')>= cut_off_date)\n",
    "    .group_by(['IID','PlanID','product_id']) #Rolling up lax_n for 6 month TUF at : IID and PlanID, prod level. \n",
    "    .agg(TUF = pl.col('TUF').sum()) #6 month TUF\n",
    ")\n",
    "\n",
    "# NOTE: make sure lax_n data is correct, should not have missing period keys as\n",
    "# top 6th unique period key is being used as a cut off date here\n",
    "# if wrong , then wrong amount of TUF will flow into the code\n",
    "\n",
    "# Doubt : (NOTE Rows will drop here since we are removing non geo IIDs) - Should I remove white space ppl?\n",
    "\n",
    "#Adding Parent Product Rows - DEFERED TO POST PIVOT CALCULATIONS : Reason : Formulary Does not have parent product ID's joining this with formulary will cause volume to go to n_a\n",
    "# def add_parent_product_rows(df):\n",
    "#     df = df.join(prod_mapping[['product_id','parent_product_id']],on='product_id',how='left')\n",
    "#     df_2_35 = df.filter(pl.col('parent_product_id').is_in([2,35]))\n",
    "#     df_2_35 = df_2_35.group_by(['IID','PlanID','parent_product_id']).agg(TUF = pl.col('TUF').sum()).rename({'parent_product_id':'product_id'})\n",
    "#     df_1 = df.group_by('IID','PlanID').agg(TUF = pl.col('TUF').sum()).with_columns(product_id = pl.lit(1)).with_columns(pl.col('product_id').cast(pl.Int64))\n",
    "\n",
    "#     # stack 1, 2_35 with df and return\n",
    "#     df = df.drop(['parent_product_id']) #dropping to make same shape\n",
    "#     vstack_helper = df.columns\n",
    "#     df = df.vstack(\n",
    "#         df_2_35.select(vstack_helper)\n",
    "#     ).vstack(\n",
    "#         df_1.select(vstack_helper)\n",
    "#     )\n",
    "\n",
    "#     return(df)\n",
    "\n",
    "# ln = add_parent_product_rows(ln)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Processing -\n",
    "# Rows will drop here as using inner join\n",
    "# Doubt : what to do with rx which is not there in formulary info?\n",
    "ln1 = (\n",
    "    ln.join(fm, on=['PlanID', 'product_id'], how='left') \n",
    "    .with_columns(\n",
    "        pl.col('plan_type').fill_null(pl.lit('Others')),\n",
    "        pl.col('plan_class').fill_null(pl.lit('N_A'))\n",
    "    )\n",
    ")\n",
    "\n",
    "ln_c = ln1.pivot(\n",
    "    values = 'TUF',index = ['IID','product_id'],\n",
    "    columns = 'plan_class',\n",
    "    aggregate_function = 'sum'\n",
    ").fill_null(0)\n",
    "\n",
    "ln_t = ln1.pivot(\n",
    "    values = 'TUF',index = ['IID','product_id'],\n",
    "    columns = 'plan_type',\n",
    "    aggregate_function = 'sum'\n",
    ").fill_null(0)\n",
    "\n",
    "# Adding Parent Product Rows\n",
    "def add_parent_product_rows(df):\n",
    "    agg_dict = {}\n",
    "    for col in df.columns[2:]:\n",
    "        agg_dict[col] = pl.col(col).sum()\n",
    "\n",
    "    df = df.join(prod_mapping[['product_id','parent_product_id']], on = 'product_id', how = 'left')\n",
    "    df_2_35 = df.filter(pl.col('parent_product_id').is_in([2,35]))\n",
    "    df_2_35 = df_2_35.group_by(['IID','parent_product_id']).agg(**agg_dict).rename({'parent_product_id':'product_id'})\n",
    "    \n",
    "    df_1 = df.group_by('IID').agg(**agg_dict).with_columns(product_id = pl.lit(1)).with_columns(pl.col('product_id').cast(pl.Int64))\n",
    "\n",
    "    # stack 1, 2_35 with df and return\n",
    "    df = df.drop(['parent_product_id']) #dropping to make same shape\n",
    "    vstack_helper = df.columns\n",
    "    df = df.vstack(\n",
    "        df_2_35.select(vstack_helper)\n",
    "    ).vstack(\n",
    "        df_1.select(vstack_helper)\n",
    "    )\n",
    "\n",
    "    return(df)\n",
    "ln_c = add_parent_product_rows(ln_c)\n",
    "ln_t = add_parent_product_rows(ln_t)\n",
    "\n",
    "ln2 = ln_c.join(ln_t,on=['IID','product_id'],how='left')\n",
    "\n",
    "ln2 = (\n",
    "    ln2\n",
    "    .with_columns(plan_type_sum = pl.sum_horizontal(['Part D', 'Commerical', 'Mgd Medicaid', 'FFS', 'Cash', 'Others']))\n",
    "    .with_columns(\n",
    "        Commerical_prc = pl.col('Commerical')/pl.col('plan_type_sum'),\n",
    "        Medicare_Part_D_prc = pl.col('Part D')/pl.col('plan_type_sum'),\n",
    "        Managed_Medicaid_prc = pl.col('Mgd Medicaid')/pl.col('plan_type_sum'),\n",
    "        FFS_prc = pl.col('FFS')/pl.col('plan_type_sum'),\n",
    "        Cash_prc = pl.col('Cash')/pl.col('plan_type_sum'),\n",
    "        Others_prc = pl.col('Others')/pl.col('plan_type_sum')\n",
    "    )\n",
    "    .with_columns(\n",
    "        qc = pl.sum_horizontal(['Commerical_prc','Medicare_Part_D_prc','Managed_Medicaid_prc', 'FFS_prc', 'Cash_prc', 'Others_prc'])\n",
    "    )# ONLY FOR QC | Will use it to drop 0 TUF rows\n",
    "    .filter(~pl.col('qc').is_nan())\n",
    "    .drop(['Part D', 'Commerical', 'Mgd Medicaid', 'FFS', 'Cash', 'Others','plan_type_sum','qc'])\n",
    "    .with_columns(\n",
    "        pl.lit(None).alias('Managed_Medicaid_prc'),\n",
    "        pl.lit(None).alias('FFS_prc')\n",
    "    )# removing data from mgd , ffs\n",
    ")\n",
    "\n",
    "ln2 = ln2.join(\n",
    "    MASTER_UNI.with_columns((pl.col('LastName')+', '+pl.col('FirstName')).alias('Physician_Name')).select(['IID','Physician_Name']),\n",
    "    on='IID',how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T14:09:43.646415Z",
     "iopub.status.busy": "2024-05-23T14:09:43.645905Z",
     "iopub.status.idle": "2024-05-23T14:09:43.649093Z",
     "shell.execute_reply": "2024-05-23T14:09:43.648482Z"
    }
   },
   "outputs": [],
   "source": [
    "# BUG : What to do with plans with more than one coverage status ? eg : IID 1631628"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T14:09:43.651890Z",
     "iopub.status.busy": "2024-05-23T14:09:43.651665Z",
     "iopub.status.idle": "2024-05-23T14:09:43.686069Z",
     "shell.execute_reply": "2024-05-23T14:09:43.685385Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Final Feed Creation -\n",
    "final_feed = ln2\n",
    "\n",
    "#Renaming existing columns according to feed\n",
    "column_mapping = {\n",
    "    \"IID\": \"Physician_ID\",\n",
    "    \"product_id\": \"Product_id\",\n",
    "    \"PREFERRED\": \"Preferred\",\n",
    "    \"COVERED\": \"Covered\",\n",
    "    \"NOT COVERED\": \"Not_Covered\",\n",
    "    \"N_A\": \"Not_Available\",\n",
    "    \"Commerical_prc\": \"Commercial\",\n",
    "    \"Medicare_Part_D_prc\": \"Medicare_Part_D\",\n",
    "    \"Managed_Medicaid_prc\": \"Managed_Medicaid\",\n",
    "    \"FFS_prc\": \"FFS\",\n",
    "    \"Cash_prc\": \"Cash\",\n",
    "    \"Others_prc\": \"Other\"\n",
    "}\n",
    "final_feed = final_feed.rename(column_mapping)\n",
    "#required new columns for feed\n",
    "col_to_addrt = ['ReportType']\n",
    "col_to_addna = ['Covered_PA_ST','Unknown','Not_Applicable']#Not_Applicable also have 0 in feed\n",
    "# func to add columns with desired value\n",
    "def addcol(df,columns_to_add,wtl):\n",
    "    for my_col in columns_to_add:\n",
    "        df = df.with_columns(pl.lit(wtl).alias(my_col))\n",
    "    return df\n",
    "final_feed = addcol(final_feed,col_to_addrt,'WEEKLY')\n",
    "final_feed = addcol(final_feed,col_to_addna,'\\\\N')\n",
    "# rearranging columns accoring to feed.\n",
    "req_cols = [\"Physician_Name\",\n",
    "    \"Physician_ID\",\n",
    "    \"Product_id\",\n",
    "    \"ReportType\",\n",
    "    \"Preferred\",\n",
    "    \"Covered\",\n",
    "    \"Not_Covered\",\n",
    "    \"Not_Available\",\n",
    "    \"Commercial\",\n",
    "    \"Medicare_Part_D\",\n",
    "    \"Managed_Medicaid\",\n",
    "    \"FFS\",\n",
    "    \"Cash\",\n",
    "    \"Other\",\n",
    "    \"Covered_PA_ST\",\n",
    "    \"Unknown\",\n",
    "    \"Not_Applicable\"]\n",
    "final_feed = final_feed.select(req_cols)# final data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T14:09:43.689352Z",
     "iopub.status.busy": "2024-05-23T14:09:43.688889Z",
     "iopub.status.idle": "2024-05-23T14:09:51.296274Z",
     "shell.execute_reply": "2024-05-23T14:09:51.295480Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Exporting -\n",
    "OUT = 's3://vortex-staging-a65ced90/BIT/output/Prescriber/Weekly/'\n",
    "final_feed.to_pandas().to_csv(f'{OUT}Weekly_Prescriber_PayerMix_Feed.txt', sep='|')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
