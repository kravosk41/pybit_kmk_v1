{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "107a6c13-a208-4f29-84c8-a750cef5da19",
   "metadata": {},
   "source": [
    "### LinzessSnapshot Sales Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fd0aa5-246b-4e64-8a10-919420653ed9",
   "metadata": {},
   "source": [
    "##### pending :\n",
    "- Rounding off values\n",
    "- Figure out a way to conver \"x.0\" values into just \"x\" -> Differing round off is observed in sas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2558e27e-528d-4a57-8d28-c06d0d531467",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "import gc\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "104dc13f-c387-4b8b-ad51-b5dae36cbe37",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# load variables from JSON\n",
    "with open('vars_wk.json', 'r') as json_file:\n",
    "    js = json.load(json_file)\n",
    "\n",
    "data_date = js['data_date']\n",
    "num_weeks_rx = js['num_weeks_rx']\n",
    "bucket = js['bucket']\n",
    "\n",
    "dflib = f's3://{bucket}/BIT/dataframes/'\n",
    "xpn = f's3://{bucket}/PYADM/weekly/archive/{data_date}/xponent/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f26a10b1-8f00-49e1-893c-0572361f4566",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Utility Functions -\n",
    "def load(df, lib=dflib):\n",
    "    globals()[df] = pl.read_parquet(f'{lib}{df}.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c819bd3-17b0-49b4-9e35-23b6c8272466",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Imporing Dependencies\n",
    "prod_mapping = pl.read_csv(f's3://{bucket}/BIT/docs/productmapping_pybit.txt',separator='|')\n",
    "geo_code_mapper = pl.from_pandas(pd.read_excel(f's3://{bucket}/BIT/docs/geo_id_full.xlsx'))\n",
    "load('mp_spec_seg_dec')\n",
    "load('MASTER_UNI')\n",
    "fetch_products = ['LI1','LI2','LI3','TRU','AMT','LAC','MOT','LUB','IRL']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091a0936-78dd-4cf3-b724-af1cd1694b78",
   "metadata": {},
   "source": [
    "### Generator Functions -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d45c8ac-bc2d-46b1-a8df-fceb232ace43",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# For Voucher Removal - \n",
    "def get_lin_voucher():\n",
    "    vch = pl.read_parquet(f'{xpn}LIN_VOUCHER.parquet') # n_rows=500\n",
    "    vch1 = pl.DataFrame()\n",
    "    for prod in ['LIN1','LIN2','LIN3']: # LINV\n",
    "        vch_prod = (\n",
    "            vch.select(\n",
    "                pl.col('IID'),\n",
    "                pl.col(f'{prod}TUF1').alias(f'vTUF_1c'),\n",
    "                pl.sum_horizontal([f'{prod}TUF{i}' for i in range(1,5)]).alias(f'vTUF_4c'),\n",
    "                pl.sum_horizontal([f'{prod}TUF{i}' for i in range(1,14)]).alias(f'vTUF_13c'),\n",
    "                pl.sum_horizontal([f'{prod}TUF{i}' for i in range(1,27)]).alias(f'vTUF_26c'),\n",
    "                pl.sum_horizontal([f'{prod}TUF{i}' for i in range(1,num_weeks_rx+1)]).alias(f'vTUF_qtdc'),\n",
    "                pl.col(f'{prod}TUF2').alias(f'vTUF_1p'),\n",
    "                pl.sum_horizontal([f'{prod}TUF{i}' for i in range(5,9)]).alias(f'vTUF_4p'),\n",
    "                pl.sum_horizontal([f'{prod}TUF{i}' for i in range(14,27)]).alias(f'vTUF_13p'),\n",
    "                pl.sum_horizontal([f'{prod}TUF{i}' for i in range(27,53)]).alias(f'vTUF_26p'),\n",
    "                pl.sum_horizontal([f'{prod}TUF{i}' for i in range(14,14+num_weeks_rx)]).alias(f'vTUF_qtdp'),\n",
    "                pl.sum_horizontal([f'{prod}TUF{i}' for i in range(1,106)]).alias(f'vTUF_all')\n",
    "            )\n",
    "            .with_columns(pl.lit(f'LI{prod[-1]}').alias('PROD_CD'))\n",
    "        )\n",
    "        if prod[-1] == '1':\n",
    "            vch1 = vch_prod.clone()\n",
    "        else:\n",
    "            vch1 = pl.concat([vch1, vch_prod])\n",
    "\n",
    "    # voucher_mapping = {'LI1': 4, 'LI2': 5, 'LI3': 3, 'LIV': 2}\n",
    "    # vch1 = vch1.with_columns(pl.col('PROD_CD').replace(voucher_mapping,return_dtype=pl.Int64).alias('product_id')).fill_null(0)#.drop('PROD_CD')\n",
    "    vch1 = vch1.fill_null(0)\n",
    "\n",
    "    return(vch1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a812341c-2013-43b1-81af-13b059e7687d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_summed_period_iid_metric(metric,prod_cd):\n",
    "    columns = ['IID','PROD_CD'] + [metric+str(i) for i in range(1,106)]\n",
    "    df = pl.read_parquet(xpn+'LAX.parquet',columns=columns).filter(pl.col('PROD_CD').is_in(prod_cd))\n",
    "\n",
    "    # 1,4,13,26 for current and prior period for a given Metric\n",
    "    df = df.select(\n",
    "        pl.col('IID'),pl.col('PROD_CD'),\n",
    "        pl.col(metric+'1').alias(metric+'_1c'),\n",
    "        pl.sum_horizontal([metric+str(i) for i in range(1,5)]).alias(metric+'_4c'),\n",
    "        pl.sum_horizontal([metric+str(i) for i in range(1,14)]).alias(metric+'_13c'),\n",
    "        pl.sum_horizontal([metric+str(i) for i in range(1,27)]).alias(metric+'_26c'),\n",
    "        pl.sum_horizontal([metric+str(i) for i in range(1,num_weeks_rx+1)]).alias(metric+'_qtdc'),\n",
    "\n",
    "        pl.col(metric+'2').alias(metric+'_1p'),\n",
    "        pl.sum_horizontal([metric+str(i) for i in range(5,9)]).alias(metric+'_4p'),\n",
    "        pl.sum_horizontal([metric+str(i) for i in range(14,27)]).alias(metric+'_13p'),\n",
    "        pl.sum_horizontal([metric+str(i) for i in range(27,53)]).alias(metric+'_26p'),\n",
    "        pl.sum_horizontal([metric+str(i) for i in range(14,14+num_weeks_rx)]).alias(metric+'_qtdp'),\n",
    "\n",
    "        pl.sum_horizontal([metric+str(i) for i in range(1,106)]).alias(metric+'_all')\n",
    "    )\n",
    "    # For Voucher Removal - \n",
    "    if metric == 'TUF':\n",
    "        dfv = get_lin_voucher()\n",
    "        df = df.join(dfv,on=['IID','PROD_CD'],how='left').fill_null(0)\n",
    "        cols_to_remove = dfv.columns[1:-1]\n",
    "        df = df.with_columns(\n",
    "            pl.col(f'{metric}_1c') -  pl.col(f'v{metric}_1c').alias(f'{metric}_1c'),\n",
    "            pl.col(f'{metric}_4c') -  pl.col(f'v{metric}_4c').alias(f'{metric}_4c'),\n",
    "            pl.col(f'{metric}_13c') -  pl.col(f'v{metric}_13c').alias(f'{metric}_13c'),\n",
    "            pl.col(f'{metric}_26c') -  pl.col(f'v{metric}_26c').alias(f'{metric}_26c'),\n",
    "            pl.col(f'{metric}_qtdc') -  pl.col(f'v{metric}_qtdc').alias(f'{metric}_qtdc'),\n",
    "            pl.col(f'{metric}_1p') -  pl.col(f'v{metric}_1p').alias(f'{metric}_1p'),\n",
    "            pl.col(f'{metric}_4p') -  pl.col(f'v{metric}_4p').alias(f'{metric}_4p'),\n",
    "            pl.col(f'{metric}_13p') -  pl.col(f'v{metric}_13p').alias(f'{metric}_13p'),\n",
    "            pl.col(f'{metric}_26p') -  pl.col(f'v{metric}_26p').alias(f'{metric}_26p'),\n",
    "            pl.col(f'{metric}_qtdp') -  pl.col(f'v{metric}_qtdp').alias(f'{metric}_qtdp'),\n",
    "            pl.col(f'{metric}_all') -  pl.col(f'v{metric}_all').alias(f'{metric}_all')\n",
    "        ).drop(cols_to_remove)\n",
    "\n",
    "    # Adding MP related columns\n",
    "    df = df.join(mp_spec_seg_dec,on='IID',how='left').filter(pl.col('geography_id').is_not_null())\n",
    "\n",
    "    return(df.drop(['specialty_group','segment','decile','geography_id']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "545f0934-c582-4644-bca0-e03f002fc3f6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def add_parent_product_rows(df):\n",
    "    agg_dict = {}\n",
    "    for col in df.columns[2:]:\n",
    "        agg_dict[col] = pl.col(col).sum()\n",
    "    \n",
    "    #join_cols = ['geography_id','plan_type','PlanID','IID']\n",
    "\n",
    "    df = df.join(prod_mapping[['code','product_id','parent_product_id']], left_on = 'PROD_CD',right_on = 'code', how = 'left')\n",
    "    df_2_35 = df.filter(pl.col('parent_product_id').is_in([2,35]))\n",
    "    df_2_35 = df_2_35.group_by(['IID','parent_product_id']).agg(**agg_dict).rename({'parent_product_id':'product_id'})\n",
    "    \n",
    "    df_1 = df.group_by('IID').agg(**agg_dict).with_columns(product_id = pl.lit(1)).with_columns(pl.col('product_id').cast(pl.Int64))\n",
    "\n",
    "    # stack 1, 2_35 with df and return\n",
    "    df = df.drop(['PROD_CD','parent_product_id']) #dropping to make same shape\n",
    "    vstack_helper = df.columns\n",
    "    df = df.vstack(\n",
    "        df_2_35.select(vstack_helper)\n",
    "    ).vstack(\n",
    "        df_1.select(vstack_helper)\n",
    "    )\n",
    "\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d39d66aa-bee4-44da-8ee8-ca4c579680f4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Raw Data Prep ETA - 21 Seconds\n",
    "all_products_tuf = get_summed_period_iid_metric('TUF',fetch_products)\n",
    "all_products_nuf = get_summed_period_iid_metric('NUF',fetch_products)\n",
    "all_products_trx = get_summed_period_iid_metric('TRX',fetch_products)\n",
    "all_products_nrx = get_summed_period_iid_metric('NRX',fetch_products)\n",
    "all_products_tun = get_summed_period_iid_metric('TUN',fetch_products)\n",
    "all_products_nun = get_summed_period_iid_metric('NUN',fetch_products)\n",
    "all_products_tuf = add_parent_product_rows(all_products_tuf)\n",
    "all_products_nuf = add_parent_product_rows(all_products_nuf)\n",
    "all_products_trx = add_parent_product_rows(all_products_trx)\n",
    "all_products_nrx = add_parent_product_rows(all_products_nrx)\n",
    "all_products_tun = add_parent_product_rows(all_products_tun)\n",
    "all_products_nun = add_parent_product_rows(all_products_nun)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9633f538-5c79-4fe5-a76a-b0b5608f833b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bcd8cf-4d70-46a4-a0cf-689334ddb76f",
   "metadata": {},
   "source": [
    "### Functions - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "113b284c-52cf-457a-b7db-d9e2ef161c97",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Cur Vol, Vol Change\n",
    "def process_1(df,metric,name):\n",
    "    source_df = (\n",
    "        globals()[f'all_products_{metric.lower()}'].filter(pl.col('product_id')==2)\n",
    "        .rename({f'{metric}{period}c' : f'cur_{name}_vol',f'{metric}{period}p' : f'pri_{name}_vol'})\n",
    "        .with_columns(\n",
    "            (pl.col(f'cur_{name}_vol')-pl.col(f'pri_{name}_vol')).alias(f'{name}_vol_change')\n",
    "        )\n",
    "        .select(['IID',f'cur_{name}_vol',f'{name}_vol_change',f'pri_{name}_vol'])\n",
    "    )\n",
    "    df = df.join(source_df,on='IID',how='left')\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "27bc0006-a4b9-49fe-b14b-c45d3950d526",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#run_rate\n",
    "def process_2(df,metric,name):\n",
    "    source_df = (\n",
    "        globals()[f'all_products_{metric.lower()}'].filter(pl.col('product_id')==2)\n",
    "        .with_columns(\n",
    "            pl.when((pl.col(f'{metric}_4c')==0)&(pl.col(f'{metric}_4p')==0)).then(pl.lit(0))\n",
    "            .otherwise(\n",
    "                ((pl.col(f'{metric}_4c') * 13) / 4) - pl.col(f'{metric}_13c')\n",
    "            )\n",
    "            .alias(f'run_rate_{name}_4v13')\n",
    "        )\n",
    "    )\n",
    "    df = df.join(source_df,on='IID',how='left')\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5432258c-81e4-4535-ac20-3d62c4aecc7e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Refil Rate :  TUF/NUF\n",
    "def process_3(df):\n",
    "    source_df = (\n",
    "        all_products_tuf.join(all_products_nuf,on=['IID',p],how='left')\n",
    "        .filter(pl.col('product_id')==2)\n",
    "        .with_columns(\n",
    "            refill_rate = pl.col(f'TUF{period}c')/pl.col(f'NUF{period}c')\n",
    "        )\n",
    "        .select(['IID','refill_rate'])\n",
    "    )\n",
    "    df = df.join(source_df,on='IID',how='left')\n",
    "    return(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0b615789-5945-455d-b942-68bf831d4060",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# percentage of Trx of Linzess Strengths\n",
    "def process_4(df):\n",
    "    source_df_cur = (\n",
    "        all_products_tuf.filter(pl.col('product_id').is_in([3,4,5]))\n",
    "        .select(['IID',f'TUF{period}c',p])\n",
    "        .pivot(index = 'IID',values = f'TUF{period}c',columns=p)\n",
    "    )\n",
    "    source_df_cur = source_df_cur.rename({f'{c}' : f'{c}_cur' for c in [i for i in source_df_cur.columns[1:]]})\n",
    "    \n",
    "    source_df_pri = (\n",
    "        all_products_tuf.filter(pl.col('product_id').is_in([3,4,5]))\n",
    "        .select(['IID',f'TUF{period}p',p])\n",
    "        .pivot(index = 'IID',values = f'TUF{period}p',columns=p)\n",
    "    )\n",
    "    source_df_pri = source_df_pri.rename({f'{c}' : f'{c}_pri' for c in [i for i in source_df_pri.columns[1:]]})\n",
    "    \n",
    "    df = (\n",
    "        df.join(source_df_cur,on='IID',how='left').join(source_df_pri,on='IID',how='left')\n",
    "        .with_columns(\n",
    "            prc_trx_lin72 = pl.col('3_cur')/pl.col('cur_trx_vol'),\n",
    "            prc_trx_lin145 = pl.col('4_cur')/pl.col('cur_trx_vol'),\n",
    "            prc_trx_lin290 = pl.col('5_cur')/pl.col('cur_trx_vol')\n",
    "        )\n",
    "        .with_columns(\n",
    "            pri_prc_trx_lin72 = pl.col('3_pri')/pl.col('pri_trx_vol'),\n",
    "            pri_prc_trx_lin145 = pl.col('4_pri')/pl.col('pri_trx_vol'),\n",
    "            pri_prc_trx_lin290 = pl.col('5_pri')/pl.col('pri_trx_vol')\n",
    "        )\n",
    "        .drop([f'{i}_cur' for i in range(3,6)] + [f'{i}_pri' for i in range(3,6)])\n",
    "        .fill_nan(0)\n",
    "    )\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bb07c719-2741-4ac8-879c-469ac580a515",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Avg Trx Size , Size Change\n",
    "def process_5(df):\n",
    "    source_df = (\n",
    "        all_products_tun.join(all_products_trx,on=['IID',p],how='left')\n",
    "        .filter(pl.col(p)==2)\n",
    "        .with_columns(\n",
    "            avg_trx_size = pl.col(f'TUN{period}c')/pl.col(f'TRX{period}c'),\n",
    "            prior_avg_trx_size = pl.col(f'TUN{period}p')/pl.col(f'TRX{period}p'),\n",
    "        )\n",
    "        .with_columns(\n",
    "            avg_trx_size_ch = pl.col('avg_trx_size')-pl.col('prior_avg_trx_size')\n",
    "        )\n",
    "        .select(['IID','avg_trx_size','avg_trx_size_ch'])\n",
    "    )\n",
    "    df = df.join(source_df,on='IID',how='left')\n",
    "    return(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7640c95d-8c71-4e82-9990-f312f2810976",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#prc 90 day trx\n",
    "def process_6(df):\n",
    "    source_df = (\n",
    "        all_products_tun.join(all_products_trx,on=['IID',p],how='left')\n",
    "        .filter(pl.col(p)==2)\n",
    "        .with_columns(\n",
    "            trx_90day_pct = -(1/2) + (pl.col(f'TUN{period}c')/(60*pl.col(f'TRX{period}c')))\n",
    "        )\n",
    "        .select(['IID','trx_90day_pct'])\n",
    "    )\n",
    "    df = df.join(source_df,on='IID',how='left')\n",
    "    return(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4608bcfc-2480-49b0-89a3-faebcabcf70d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#IBSC VOL, Vol Change, %Share\n",
    "def process_7(df):\n",
    "    source_df = (\n",
    "        all_products_tuf.filter(pl.col(p)==1)\n",
    "        .with_columns(\n",
    "            ibsc_vol_change = pl.col(f'TUF{period}c')-pl.col(f'TUF{period}p')\n",
    "        )\n",
    "        .rename({f'TUF{period}c':'ibsc_vol',f'TUF{period}p' : 'pri_ibsc_vol'})\n",
    "        .select(['IID','ibsc_vol','ibsc_vol_change','pri_ibsc_vol'])\n",
    "    )\n",
    "    df = (\n",
    "        df.join(source_df,on='IID',how='left')\n",
    "        .with_columns(\n",
    "            prc_ibsc_share = pl.col('cur_trx_vol')/pl.col('ibsc_vol'),\n",
    "            pri_prc_ibsc_share = pl.col('pri_trx_vol')/pl.col('pri_ibsc_vol')\n",
    "        )\n",
    "        .fill_nan(0)\n",
    "    )\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ba74128d-515d-4d34-92f0-ea8eb1db4b4b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#TRU : 6 , TAMT : 35, IRL : 37 | AMT alone is 7\n",
    "def process_8(df):\n",
    "    source_df_cur = (\n",
    "        all_products_tuf.filter(pl.col(p).is_in([6,35,37]))\n",
    "        .select(['IID',f'TUF{period}c',p])\n",
    "        .pivot(index='IID',values=f'TUF{period}c',columns=p)\n",
    "        .with_columns(pl.col('6').fill_null(0.0),pl.col('37').fill_null(0.0),pl.col('35').fill_null(0.0))\n",
    "    )\n",
    "    source_df_cur = source_df_cur.rename({f'{c}' : f'{c}_cur' for c in [i for i in source_df_cur.columns[1:]]})\n",
    "    \n",
    "    source_df_pri = (\n",
    "            all_products_tuf.filter(pl.col('product_id').is_in([6,35,37]))\n",
    "            .select(['IID',f'TUF{period}p',p])\n",
    "            .pivot(index = 'IID',values = f'TUF{period}p',columns=p)\n",
    "        )\n",
    "    source_df_pri = source_df_pri.rename({f'{c}' : f'{c}_pri' for c in [i for i in source_df_pri.columns[1:]]})\n",
    "    \n",
    "    df = (\n",
    "        df.join(source_df_cur,on='IID',how='left').join(source_df_pri,on='IID',how='left')\n",
    "        .with_columns(\n",
    "            prc_tru_share = pl.col('6_cur')/pl.col('ibsc_vol'),\n",
    "            prc_amt_share = pl.col('35_cur')/pl.col('ibsc_vol'),\n",
    "            prc_irl_share = pl.col('37_cur')/pl.col('ibsc_vol')\n",
    "        )\n",
    "        .with_columns(\n",
    "            pri_prc_tru_share = pl.col('6_pri')/pl.col('pri_ibsc_vol'),\n",
    "            pri_prc_amt_share = pl.col('35_pri')/pl.col('pri_ibsc_vol'),\n",
    "            pri_prc_irl_share = pl.col('37_pri')/pl.col('pri_ibsc_vol')\n",
    "        )\n",
    "        .drop([f'{i}_cur' for i in [6,35,37]] + [f'{i}_pri' for i in [6,35,37]])\n",
    "        .fill_nan(0)\n",
    "    )\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c85d74ad-c19c-4736-910c-569d86937924",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# #indicator metrics\n",
    "def vol_change_ind(df,col,pri_col):\n",
    "    px = pl.when(pl.col(pri_col) * 0.01 > 2).then(pl.col(pri_col) * 0.01).otherwise(2).alias('threshold')\n",
    "    df = (\n",
    "        df\n",
    "        .with_columns(px)\n",
    "        .with_columns(\n",
    "            pl.when(pl.col(f'{col}').is_null()).then(pl.lit(''))\n",
    "            .when(pl.col(f'{col}') > pl.col('threshold')).then(pl.lit('P'))\n",
    "            .when(pl.col(f'{col}') < -1 * pl.col('threshold')).then(pl.lit('Q'))\n",
    "            .otherwise(pl.lit(''))\n",
    "            .alias(f'{col}_ind')\n",
    "        )\n",
    "        .drop([pri_col,'threshold'])\n",
    "    )\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "87d58174-3184-43e5-a777-fb8e6bac70d3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def shr_change_ind(df,col,pri_col):\n",
    "    px = pl.lit(0.05).alias('threshold')\n",
    "\n",
    "    df = (\n",
    "        df\n",
    "        .with_columns(px)\n",
    "        .with_columns(change_col = pl.col(col)-pl.col(pri_col))\n",
    "        .with_columns(\n",
    "            pl.when(pl.col('change_col').is_null()).then(pl.lit(''))\n",
    "            .when(pl.col(pri_col)==0).then(pl.lit(''))\n",
    "            .when(pl.col(col)==0).then(pl.lit(''))\n",
    "            .when(pl.col('change_col') > pl.col('threshold')).then(pl.lit('P'))\n",
    "            .when(pl.col('change_col') < -1 * pl.col('threshold')).then(pl.lit('Q'))\n",
    "            .otherwise(pl.lit(''))\n",
    "            .alias(f'{col}_ind')\n",
    "        )\n",
    "        .drop([pri_col,'change_col','threshold'])\n",
    "    )\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4064c642-946a-4317-bf66-4b8050692d7a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# To make feed Ready- \n",
    "def get_feed(df):\n",
    "    col_mapping = {\n",
    "        'IID':'Physician_ID',\n",
    "        'geography_id':'Geography_id',\n",
    "        'cur_trx_vol':'NumberMetric1',\n",
    "        'trx_vol_change':'NumberMetric2',\n",
    "        'cur_nrx_vol':'NumberMetric4',\n",
    "        'nrx_vol_change':'NumberMetric5',\n",
    "        'run_rate_trx_4v13':'NumberMetric3',\n",
    "        'run_rate_nrx_4v13':'NumberMetric6',\n",
    "        'refill_rate':'NumberMetric7',\n",
    "        'prc_trx_lin72':'NumberMetric8',\n",
    "        'prc_trx_lin145':'NumberMetric9',\n",
    "        'prc_trx_lin290':'NumberMetric10',\n",
    "        'avg_trx_size':'NumberMetric11',\n",
    "        'avg_trx_size_ch':'NumberMetric12',\n",
    "        'trx_90day_pct':'NumberMetric13',\n",
    "        'ibsc_vol':'NumberMetric14',\n",
    "        'ibsc_vol_change':'NumberMetric15',\n",
    "        'prc_ibsc_share':'NumberMetric16',\n",
    "        'prc_tru_share':'NumberMetric17',\n",
    "        'prc_amt_share':'NumberMetric18',\n",
    "        'prc_irl_share':'NumberMetric19',\n",
    "        'trx_vol_change_ind' : 'StringMetric8',\n",
    "        'nrx_vol_change_ind' : 'StringMetric9',\n",
    "        'prc_trx_lin72_ind' : 'StringMetric1',\n",
    "        'prc_trx_lin145_ind' : 'StringMetric2',\n",
    "        'prc_trx_lin290_ind' : 'StringMetric3',\n",
    "        'ibsc_vol_change_ind' : 'StringMetric10',\n",
    "        'prc_ibsc_share_ind' : 'StringMetric4',\n",
    "        'prc_tru_share_ind' : 'StringMetric5',\n",
    "        'prc_amt_share_ind' : 'StringMetric6',\n",
    "        'prc_irl_share_ind' : 'StringMetric7',\n",
    "    }\n",
    "    final_feed = (\n",
    "        df\n",
    "        .rename(col_mapping)\n",
    "        #.with_columns([pl.lit('\\\\N').alias(c) for c in [f'StringMetric{i}' for i in range(1,11)]])\n",
    "        .select(['Physician_ID','Geography_id'] + [f'NumberMetric{i}' for i in range(1,20)] +  [f'StringMetric{i}' for i in range(1,11)])\n",
    "    )\n",
    "    return(final_feed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544a9374-a7de-415a-a516-bbd52ec36623",
   "metadata": {},
   "source": [
    "### Period Loop -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c37c34d4-2a70-4fef-bb4d-e5be24f906d6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# for trvializing formula : \n",
    "p,sg,spc,d = 'product_id','segment','specialty_group','decile'\n",
    "levels = ['geography_id','region_geography_id','area_geography_id','nation_geography_id']\n",
    "OUT = 's3://vortex-staging-a65ced90/BIT/output/LinzessSnapshot/Weekly/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9b8fec9e-c171-4750-92ae-be9a1231a656",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LS Sales Perf feed 2 done\n",
      "LS Sales Perf feed 3 done\n"
     ]
    }
   ],
   "source": [
    "for period_num,PN in zip([4,13],[2,3]):\n",
    "    period = f'_{period_num}'\n",
    "    temp1 = mp_spec_seg_dec.select(['IID','geography_id'])\n",
    "    temp1 = process_1(temp1,'TUF','trx')\n",
    "    temp1 = process_1(temp1,'NUF','nrx')\n",
    "    temp1 = process_2(temp1,'TUF','trx')\n",
    "    temp1 = process_2(temp1,'NUF','nrx')\n",
    "    temp1 = process_3(temp1)\n",
    "    temp1 = process_4(temp1)\n",
    "    temp1 = process_5(temp1)\n",
    "    temp1 = process_6(temp1)\n",
    "    temp1 = process_7(temp1)\n",
    "    temp1 = process_8(temp1)\n",
    "    \n",
    "    # Filter Step - \n",
    "    temp1 = (\n",
    "        temp1\n",
    "        .filter(\n",
    "            #((pl.col('ibsc_vol').is_not_null()) & (pl.col('ibsc_vol')!=0)) | ((pl.col('trx_vol_change').is_not_null()) & (pl.col('trx_vol_change')!=0))\n",
    "            ((pl.col('cur_trx_vol').is_not_null())&(pl.col('cur_trx_vol')!=0)) | ((pl.col('trx_vol_change').is_not_null()) & (pl.col('trx_vol_change')!=0))\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # String Metrics - \n",
    "    temp1 = vol_change_ind(temp1,'trx_vol_change','pri_trx_vol')\n",
    "    temp1 = vol_change_ind(temp1,'nrx_vol_change','pri_nrx_vol')\n",
    "    temp1 = vol_change_ind(temp1,'ibsc_vol_change','pri_ibsc_vol')\n",
    "    temp1 = shr_change_ind(temp1,'prc_trx_lin72','pri_prc_trx_lin72')\n",
    "    temp1 = shr_change_ind(temp1,'prc_trx_lin145','pri_prc_trx_lin145')\n",
    "    temp1 = shr_change_ind(temp1,'prc_trx_lin290','pri_prc_trx_lin290')\n",
    "    temp1 = shr_change_ind(temp1,'prc_ibsc_share','pri_prc_ibsc_share')\n",
    "    temp1 = shr_change_ind(temp1,'prc_tru_share','pri_prc_tru_share')\n",
    "    temp1 = shr_change_ind(temp1,'prc_amt_share','pri_prc_amt_share')\n",
    "    temp1 = shr_change_ind(temp1,'prc_irl_share','pri_prc_irl_share')\n",
    "\n",
    "    # ROUNDING FIXES HERE -  (BEFROE DTYPE BCOMES MIXED CUZ OF PDRP OVERRDIDE)\n",
    "    temp1 = temp1.with_columns(\n",
    "        pl.col('ibsc_vol_change').round(1)\n",
    "    )\n",
    "\n",
    "    # PDRP Overrides - \n",
    "    temp1 = temp1.join(MASTER_UNI.select(['IID','PDRPOptOutFlag']),on='IID',how='left')\n",
    "    override_columns =  temp1.columns[2:]\n",
    "    expression_list = [\n",
    "        pl.when(pl.col('PDRPOptOutFlag')=='Y').then(pl.lit('\\\\N')).otherwise(pl.col(c)).alias(c)\n",
    "        for c in override_columns\n",
    "    ]\n",
    "    temp1 = temp1.with_columns(expression_list).drop('PDRPOptOutFlag')\n",
    "    \n",
    "    feed_dataset = get_feed(temp1)\n",
    "    \n",
    "    #Exporting Feeds-\n",
    "    OUT = 's3://vortex-staging-a65ced90/BIT/output/LinzessSnapshot/Weekly/'\n",
    "    feed_dataset.to_pandas().to_csv(f'{OUT}Weekly_LinzessSnapshot_MetricPerformance_P{PN}_Feed.txt',sep='|',lineterminator='\\r\\n',index=False)\n",
    "    print(f'LS Sales Perf feed {PN} done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698b75fe-9c38-408f-8d57-7cf1f7abf193",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
