{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calls and samples & abbv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T14:39:50.637395Z",
     "iopub.status.busy": "2024-08-06T14:39:50.636923Z",
     "iopub.status.idle": "2024-08-06T14:39:51.271170Z",
     "shell.execute_reply": "2024-08-06T14:39:51.270252Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "import json\n",
    "import gc\n",
    "from datetime import datetime, timedelta,date\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T14:39:51.278713Z",
     "iopub.status.busy": "2024-08-06T14:39:51.278102Z",
     "iopub.status.idle": "2024-08-06T14:39:51.286089Z",
     "shell.execute_reply": "2024-08-06T14:39:51.285032Z"
    }
   },
   "outputs": [],
   "source": [
    "# load variables from JSON\n",
    "with open('vars_wk.json', 'r') as json_file:\n",
    "    js = json.load(json_file)\n",
    "\n",
    "data_date = js['data_date']\n",
    "qtr_data = js['qtr_data']\n",
    "qtr_ntnw = js['qtr_ntnw']\n",
    "fir_nqrt = datetime.strptime(js['fir_nqrt'],'%Y-%m-%d').date()\n",
    "targeting_folder = js['targeting_folder']\n",
    "working_day_file = js['working_day_file']\n",
    "roster_file = js['roster_file']\n",
    "curr_date = datetime.strptime(js['curr_date'], '%Y-%m-%d').date()\n",
    "quarter_start = datetime.strptime(js['quarter_start'], '%Y-%m-%d').date()\n",
    "num_weeks_calls = js['num_weeks_calls']\n",
    "num_weeks_rx = js['num_weeks_rx']\n",
    "curr_date_p26 = curr_date- timedelta(weeks=26)\n",
    "curr_date_p13 = curr_date- timedelta(weeks=13) \n",
    "curr_date_m13 = curr_date - timedelta(weeks=53)\n",
    "\n",
    "bucket = js['bucket']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T14:39:51.291082Z",
     "iopub.status.busy": "2024-08-06T14:39:51.290145Z",
     "iopub.status.idle": "2024-08-06T14:39:51.296259Z",
     "shell.execute_reply": "2024-08-06T14:39:51.295158Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "frzmstr = f's3://{bucket}/PYADM/quaterly/{qtr_data}/reference/'\n",
    "master = f's3://{bucket}/PYADM/weekly/archive/{data_date}/reference/'\n",
    "inex = f's3://{bucket}/PYADM/reference/{qtr_data}/'\n",
    "geo = f's3://{bucket}/PYADM/quaterly/{qtr_data}/geography/'\n",
    "lincall = f's3://{bucket}/PYADM/quaterly/{qtr_data}/target/post/'\n",
    "dflib = f's3://{bucket}/BIT/dataframes/'\n",
    "call = f's3://{bucket}/PYADM/weekly/archive/{data_date}/calls_samples/'\n",
    "xpn = f's3://{bucket}/PYADM/weekly/archive/{data_date}/xponent/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T14:39:51.301993Z",
     "iopub.status.busy": "2024-08-06T14:39:51.301394Z",
     "iopub.status.idle": "2024-08-06T14:39:53.381230Z",
     "shell.execute_reply": "2024-08-06T14:39:53.379832Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Utility Functions -\n",
    "def load(df, lib=dflib):\n",
    "    globals()[df] = pl.read_parquet(f'{lib}{df}.parquet')\n",
    "# Dependencies - \n",
    "terr_mapping = pl.read_csv(f's3://{bucket}/BIT/docs/geo_id_mapping.txt',separator='|')\n",
    "load('mp_spec_seg_dec')\n",
    "load('MASTER_UNI')\n",
    "\n",
    "# Roster-\n",
    "roster = (\n",
    "    pl.read_parquet(f's3://{bucket}/BIT/roster/MasterRoster_{roster_file}.parquet')\n",
    "    .with_columns(\n",
    "        pl.col('SalesRepIID').cast(pl.Int64),\n",
    "        GEO = pl.concat_str(\n",
    "            pl.lit('1111-'),pl.col('GeoCode'),pl.lit('-11')\n",
    "        )\n",
    "    )\n",
    "    .select(['SalesRepIID','GEO'])\n",
    ")\n",
    "roster.to_pandas().to_parquet(dflib+'roster.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T14:39:53.386204Z",
     "iopub.status.busy": "2024-08-06T14:39:53.385506Z",
     "iopub.status.idle": "2024-08-06T14:39:53.399948Z",
     "shell.execute_reply": "2024-08-06T14:39:53.398947Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def intck(interval, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Calculates the difference between two dates in terms of the specified interval.\n",
    "\n",
    "    Args:\n",
    "        interval (str): The interval ('DAY', 'MONTH', 'WEEK', etc.).\n",
    "        start_date (datetime.date): The start date.\n",
    "        end_date (datetime.date): The end date.\n",
    "\n",
    "    Returns:\n",
    "        int: The difference between the dates in terms of the specified interval.\n",
    "    \"\"\"\n",
    "    if interval == 'DAY':\n",
    "        return (end_date - start_date).days\n",
    "    elif interval == 'MONTH':\n",
    "        end_date_m = end_date.replace(day=1)\n",
    "        start_date_m = start_date.replace(day = 1)\n",
    "        rd = relativedelta(end_date_m, start_date_m)\n",
    "        return rd.years * 12 + rd.months\n",
    "    elif interval == 'WEEK':\n",
    "        return (end_date - start_date).days // 7\n",
    "    # Add more intervals as needed\n",
    "\n",
    "# Example usage\n",
    "# start_date = date(2023, 1, 1)\n",
    "# end_date = date(2023, 2, 15)\n",
    "# interval = 'DAY'\n",
    "\n",
    "# result = intck(interval, start_date, end_date)\n",
    "# print(f\"Difference in {interval}: {result}\")\n",
    "    \n",
    "def filter_duplicate(df,col,val,new):\n",
    "    dict = {val:new}\n",
    "    filtered_df = df.filter(pl.col(col)==val)\n",
    "    filtered_df = filtered_df.with_columns([\n",
    "        pl.col(col).map_elements(lambda x : dict.get(x,x)).cast(pl.Utf8)\n",
    "    ])\n",
    "    return (df.vstack(filtered_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T14:39:53.404287Z",
     "iopub.status.busy": "2024-08-06T14:39:53.403584Z",
     "iopub.status.idle": "2024-08-06T14:39:57.938548Z",
     "shell.execute_reply": "2024-08-06T14:39:57.936471Z"
    }
   },
   "outputs": [],
   "source": [
    "# All Calls-\n",
    "\n",
    "# Specifiing which columns to keep-\n",
    "read_cols = ['CallID','CallProductDescription','CallDateTime','SalesRepIID','AttendeeIID','CallProductQuantity',\n",
    "             'CALL_VARNM','SalesRepTerritoryID','PhysicianTerritoryID','CallType']\n",
    "\n",
    "# Reading the file from ADM - \n",
    "AC = pl.read_parquet(f'{call}ALL_CALLS.parquet',columns=read_cols)\n",
    "\n",
    "# Adding CallDate column - \n",
    "AC = AC.with_columns(pl.col(\"CallDateTime\").cast(pl.Date).alias('CallDate'))\n",
    "AC = AC.drop(\"CallDateTime\") # dropping redundant column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T14:39:57.945825Z",
     "iopub.status.busy": "2024-08-06T14:39:57.945495Z",
     "iopub.status.idle": "2024-08-06T14:39:58.219990Z",
     "shell.execute_reply": "2024-08-06T14:39:58.218924Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filtering for just current \n",
    "active_calls = AC.filter(\n",
    "    (pl.col('CallDate') >= curr_date_m13) & (pl.col('CallDate') <= curr_date)\n",
    ") #used to be pr_13_wk_date\n",
    "active_calls = active_calls.with_columns(pl.col('CALL_VARNM').str.slice(3,3).alias('product'))\n",
    "active_calls = active_calls.with_columns(pl.col('CALL_VARNM').str.slice(0,3).alias('source'))\n",
    "active_calls = active_calls.with_columns(pl.col('CALL_VARNM').str.slice(7,2).alias('type'))\n",
    "active_calls = active_calls.with_columns(pl.col('CALL_VARNM').str.slice(6,1).alias('priority'))\n",
    "\n",
    "active_calls = active_calls.drop('CALL_VARNM')\n",
    "active_calls = active_calls.with_columns(pl.col('AttendeeIID').cast(pl.Int64))\n",
    "\n",
    "del AC\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T14:39:58.225130Z",
     "iopub.status.busy": "2024-08-06T14:39:58.224137Z",
     "iopub.status.idle": "2024-08-06T14:39:58.237552Z",
     "shell.execute_reply": "2024-08-06T14:39:58.236477Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (7, 13)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>CallID</th><th>CallProductDescription</th><th>SalesRepIID</th><th>AttendeeIID</th><th>CallProductQuantity</th><th>SalesRepTerritoryID</th><th>PhysicianTerritoryID</th><th>CallType</th><th>CallDate</th><th>product</th><th>source</th><th>type</th><th>priority</th></tr><tr><td>str</td><td>str</td><td>i64</td><td>i64</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>date</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;20420557&quot;</td><td>&quot;145 mcg&quot;</td><td>17959355</td><td>2233025</td><td>4.0</td><td>&quot;1111-20607-11&quot;</td><td>&quot;1111-20607-11 - San Diego CA&quot;</td><td>&quot;Detail with Sample&quot;</td><td>2024-07-02</td><td>&quot;LIN&quot;</td><td>&quot;IRN&quot;</td><td>&quot;CS&quot;</td><td>&quot;P&quot;</td></tr><tr><td>&quot;20420557&quot;</td><td>&quot;145 mcg&quot;</td><td>17959355</td><td>2233025</td><td>4.0</td><td>&quot;1111-20607-11&quot;</td><td>&quot;1111-20607-11 - San Diego CA&quot;</td><td>&quot;Detail with Sample&quot;</td><td>2024-07-02</td><td>&quot;LIN&quot;</td><td>&quot;IRN&quot;</td><td>&quot;CS&quot;</td><td>&quot;P&quot;</td></tr><tr><td>&quot;20420557&quot;</td><td>&quot;290 mcg&quot;</td><td>17959355</td><td>2233025</td><td>4.0</td><td>&quot;1111-20607-11&quot;</td><td>&quot;1111-20607-11 - San Diego CA&quot;</td><td>&quot;Detail with Sample&quot;</td><td>2024-07-02</td><td>&quot;LIN&quot;</td><td>&quot;IRN&quot;</td><td>&quot;CS&quot;</td><td>&quot;P&quot;</td></tr><tr><td>&quot;20420557&quot;</td><td>&quot;290 mcg&quot;</td><td>17959355</td><td>2233025</td><td>4.0</td><td>&quot;1111-20607-11&quot;</td><td>&quot;1111-20607-11 - San Diego CA&quot;</td><td>&quot;Detail with Sample&quot;</td><td>2024-07-02</td><td>&quot;LIN&quot;</td><td>&quot;IRN&quot;</td><td>&quot;CS&quot;</td><td>&quot;P&quot;</td></tr><tr><td>&quot;20420557&quot;</td><td>&quot;72 mcg&quot;</td><td>17959355</td><td>2233025</td><td>4.0</td><td>&quot;1111-20607-11&quot;</td><td>&quot;1111-20607-11 - San Diego CA&quot;</td><td>&quot;Detail with Sample&quot;</td><td>2024-07-02</td><td>&quot;LIN&quot;</td><td>&quot;IRN&quot;</td><td>&quot;CS&quot;</td><td>&quot;P&quot;</td></tr><tr><td>&quot;20420557&quot;</td><td>&quot;72 mcg&quot;</td><td>17959355</td><td>2233025</td><td>4.0</td><td>&quot;1111-20607-11&quot;</td><td>&quot;1111-20607-11 - San Diego CA&quot;</td><td>&quot;Detail with Sample&quot;</td><td>2024-07-02</td><td>&quot;LIN&quot;</td><td>&quot;IRN&quot;</td><td>&quot;CS&quot;</td><td>&quot;P&quot;</td></tr><tr><td>&quot;20456341&quot;</td><td>null</td><td>17959355</td><td>2233025</td><td>null</td><td>&quot;1111-20607-11&quot;</td><td>null</td><td>&quot;Detail Only&quot;</td><td>2024-07-17</td><td>&quot;LIN&quot;</td><td>&quot;IRN&quot;</td><td>&quot;CO&quot;</td><td>&quot;P&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (7, 13)\n",
       "┌──────────┬──────────────────┬─────────────┬─────────────┬───┬─────────┬────────┬──────┬──────────┐\n",
       "│ CallID   ┆ CallProductDescr ┆ SalesRepIID ┆ AttendeeIID ┆ … ┆ product ┆ source ┆ type ┆ priority │\n",
       "│ ---      ┆ iption           ┆ ---         ┆ ---         ┆   ┆ ---     ┆ ---    ┆ ---  ┆ ---      │\n",
       "│ str      ┆ ---              ┆ i64         ┆ i64         ┆   ┆ str     ┆ str    ┆ str  ┆ str      │\n",
       "│          ┆ str              ┆             ┆             ┆   ┆         ┆        ┆      ┆          │\n",
       "╞══════════╪══════════════════╪═════════════╪═════════════╪═══╪═════════╪════════╪══════╪══════════╡\n",
       "│ 20420557 ┆ 145 mcg          ┆ 17959355    ┆ 2233025     ┆ … ┆ LIN     ┆ IRN    ┆ CS   ┆ P        │\n",
       "│ 20420557 ┆ 145 mcg          ┆ 17959355    ┆ 2233025     ┆ … ┆ LIN     ┆ IRN    ┆ CS   ┆ P        │\n",
       "│ 20420557 ┆ 290 mcg          ┆ 17959355    ┆ 2233025     ┆ … ┆ LIN     ┆ IRN    ┆ CS   ┆ P        │\n",
       "│ 20420557 ┆ 290 mcg          ┆ 17959355    ┆ 2233025     ┆ … ┆ LIN     ┆ IRN    ┆ CS   ┆ P        │\n",
       "│ 20420557 ┆ 72 mcg           ┆ 17959355    ┆ 2233025     ┆ … ┆ LIN     ┆ IRN    ┆ CS   ┆ P        │\n",
       "│ 20420557 ┆ 72 mcg           ┆ 17959355    ┆ 2233025     ┆ … ┆ LIN     ┆ IRN    ┆ CS   ┆ P        │\n",
       "│ 20456341 ┆ null             ┆ 17959355    ┆ 2233025     ┆ … ┆ LIN     ┆ IRN    ┆ CO   ┆ P        │\n",
       "└──────────┴──────────────────┴─────────────┴─────────────┴───┴─────────┴────────┴──────┴──────────┘"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_calls.filter(AttendeeIID = 2233025).sort('CallDate').filter(source = 'IRN').filter(pl.col('CallDate')>=quarter_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### temp_calls\n",
    "- this should containt all non frx and non sample only rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T14:39:58.244006Z",
     "iopub.status.busy": "2024-08-06T14:39:58.243380Z",
     "iopub.status.idle": "2024-08-06T14:40:05.378288Z",
     "shell.execute_reply": "2024-08-06T14:40:05.377234Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#/*Eliminating all calls made by FRX and Sample Only calls*/\n",
    "temp_calls = active_calls.filter(\n",
    "    (pl.col('source').is_in(['EGM', 'IRN', 'REG', 'RFT', 'ROT', 'RTE', 'RWE', 'RZO'])) & ~\n",
    "    (pl.col('type').is_in(['SO']))\n",
    ")\n",
    "\n",
    "# Adding week number and month number - \n",
    "temp_calls = temp_calls.with_columns(\n",
    "    pl.col('CallDate')\n",
    "    .map_elements(\n",
    "        lambda x : (intck('DAY',x,curr_date) // 7) + 1,return_dtype=pl.Int64\n",
    "    )\n",
    "    .alias('call_week')\n",
    ")\n",
    "\n",
    "temp_calls = temp_calls.with_columns(\n",
    "    pl.col('CallDate')\n",
    "    .map_elements(\n",
    "        lambda x : intck('MONTH',x,curr_date) + 1,return_dtype=pl.Int64\n",
    "    )\n",
    "    .alias('call_month')\n",
    ")\n",
    "\n",
    "temp_calls = temp_calls.filter(pl.col('call_month')<=13) # only have 13 months of data\n",
    "\n",
    "# #Filter to Drop Invalid Calls -\n",
    "# temp_calls = (\n",
    "#     temp_calls\n",
    "#     .join(MASTER_UNI.select(['IID','Territory']),left_on = 'AttendeeIID', right_on = 'IID')\n",
    "#     .join(roster, on = 'SalesRepIID' , how = 'left')\n",
    "#     .filter(pl.col('SalesRepTerritoryID')==pl.col('GEO'))\n",
    "#     .drop(['GEO'])\n",
    "# )\n",
    "\n",
    "temp_calls.to_pandas().to_parquet(dflib+'temp_calls.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### temp_samples\n",
    "- this should contain all rows with CallType = 'Group Detail with Sample' or 'Detail with Sample'\n",
    "- source should still be non FRX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T14:40:05.387891Z",
     "iopub.status.busy": "2024-08-06T14:40:05.387543Z",
     "iopub.status.idle": "2024-08-06T14:40:09.171103Z",
     "shell.execute_reply": "2024-08-06T14:40:09.169212Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_CallProductDescriptions = [\"72 MCG\",\"145 MCG\",\"145 MCG SAMPLE 30CT\",\"290 MCG\",\"290 MCG SAMPLE 30CT\",\"CANASA\",\"DELZICOL\"]\n",
    "sample_CallTypes = ['Group Detail with Sample','Detail with Sample']\n",
    "in_active_samples = active_calls.filter(\n",
    "    (pl.col('CallProductDescription').str.to_uppercase().is_in(sample_CallProductDescriptions)) & (pl.col('CallType').is_in(sample_CallTypes))\n",
    ")\n",
    "temp_samples = in_active_samples.filter(\n",
    "    pl.col('source').is_in(['EGM', 'IRN', 'REG', 'RFT', 'ROT', 'RTE', 'RWE', 'RZO'])\n",
    ")\n",
    "# Adding week number and month number - \n",
    "temp_samples = temp_samples.with_columns(\n",
    "    pl.col('CallDate')\n",
    "    .map_elements(\n",
    "        lambda x : (intck('DAY',x,curr_date) // 7) + 1,return_dtype=pl.Int64\n",
    "    )\n",
    "    .alias('sample_week')\n",
    ")\n",
    "\n",
    "temp_samples = temp_samples.with_columns(\n",
    "    pl.col('CallDate')\n",
    "    .map_elements(\n",
    "        lambda x : intck('MONTH',x,curr_date) + 1,return_dtype=pl.Int64\n",
    "    )\n",
    "    .alias('sample_month')\n",
    ")\n",
    "\n",
    "temp_samples = temp_samples.filter(pl.col('sample_month')<=13) # only have 13 months of data\n",
    "temp_samples.to_pandas().to_parquet(dflib+'temp_samples.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### temp_abbv\n",
    "- this should contain all FRX and AEM rows with non Sample Only Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T14:40:09.177932Z",
     "iopub.status.busy": "2024-08-06T14:40:09.175185Z",
     "iopub.status.idle": "2024-08-06T14:40:16.458468Z",
     "shell.execute_reply": "2024-08-06T14:40:16.457281Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "temp_abbv = active_calls.filter(\n",
    "    (pl.col('source').is_in(['FRX','AEM'])) & \n",
    "    (pl.col('type') != 'SO')\n",
    ")\n",
    "# Adding week number and month number - \n",
    "temp_abbv = temp_abbv.with_columns(\n",
    "    pl.col('CallDate')\n",
    "    .map_elements(\n",
    "        lambda x : (intck('DAY',x,curr_date) // 7) + 1,return_dtype=pl.Int64\n",
    "    )\n",
    "    .alias('call_week')\n",
    ")\n",
    "\n",
    "temp_abbv = temp_abbv.with_columns(\n",
    "    pl.col('CallDate')\n",
    "    .map_elements(\n",
    "        lambda x : intck('MONTH',x,curr_date) + 1,return_dtype=pl.Int64\n",
    "    )\n",
    "    .alias('call_month')\n",
    ")\n",
    "\n",
    "temp_abbv = temp_abbv.filter(pl.col('call_month')<=13) # only have 13 months of data\n",
    "\n",
    "# temp_abbv = (\n",
    "#     temp_abbv\n",
    "#     .join(mp_spec_seg_dec.select(['IID','geography_id']), left_on = 'AttendeeIID', right_on = 'IID', how = 'left')\n",
    "#     .join(terr_mapping, left_on ='geography_id', right_on='geo_id', how='left')\n",
    "#     .filter(pl.col('SalesRepTerritoryID')==pl.col('code'))\n",
    "#     .drop(['geography_id','code'])\n",
    "# )\n",
    "\n",
    "temp_abbv.to_pandas().to_parquet(dflib+'temp_abbv.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Working Day File\n",
    "- Used to get number of working days (aggregated at rep_id level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T14:40:16.466419Z",
     "iopub.status.busy": "2024-08-06T14:40:16.465496Z",
     "iopub.status.idle": "2024-08-06T14:40:19.903117Z",
     "shell.execute_reply": "2024-08-06T14:40:19.902115Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#importing working day file \n",
    "wd_raw = pl.from_pandas(pd.read_excel(f's3://{bucket}/BIT/working_day/Working Day Data for KMK_{working_day_file}.xlsx'))\n",
    "wd_raw.columns = ['rep_name','rep_id','day','wd']\n",
    "wd_raw = (\n",
    "    wd_raw\n",
    "    .with_columns(pl.col('day').cast(pl.Date))\n",
    "    .filter((pl.col('day') >= quarter_start) & (pl.col('day') <= curr_date))\n",
    "    .group_by(['rep_name','rep_id'])\n",
    "    .agg(days_in_field=pl.col('wd').sum())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T14:40:19.912574Z",
     "iopub.status.busy": "2024-08-06T14:40:19.911703Z",
     "iopub.status.idle": "2024-08-06T14:40:20.400714Z",
     "shell.execute_reply": "2024-08-06T14:40:20.397498Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# roster\n",
    "roster = pl.read_parquet(\n",
    "    f's3://{bucket}/BIT/roster/MasterRoster_{roster_file}.parquet',columns = ['EmpCode','SalesRepIID']\n",
    ")\n",
    "roster = roster.with_columns(pl.col('EmpCode').cast(pl.Int64))\n",
    "roster = roster.with_columns(pl.col('SalesRepIID').cast(pl.Int64))\n",
    "\n",
    "#\n",
    "wd_raw = wd_raw.join(roster,left_on= 'rep_id',right_on = 'EmpCode' ,how = 'left')\n",
    "wd_raw.to_pandas().to_parquet(dflib+'wd_raw.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### call plan file import \n",
    "- importing and exporting ironwood call plan (we use the call_freq column here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T14:40:20.405012Z",
     "iopub.status.busy": "2024-08-06T14:40:20.404345Z",
     "iopub.status.idle": "2024-08-06T14:40:20.916295Z",
     "shell.execute_reply": "2024-08-06T14:40:20.914071Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "lirwd_call_plan = pl.read_parquet(lincall + 'IRWD_CALL_PLAN.parquet',\n",
    "                                  columns=['IID','CALL_FREQ'])\n",
    "lirwd_call_plan.columns = ['IID','call_freq_quarter']\n",
    "lirwd_call_plan.to_pandas().to_parquet(dflib+'lirwd_call_plan.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T14:40:20.921842Z",
     "iopub.status.busy": "2024-08-06T14:40:20.920981Z",
     "iopub.status.idle": "2024-08-06T14:40:21.075681Z",
     "shell.execute_reply": "2024-08-06T14:40:21.074755Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Cleaning up to make space for RX import\n",
    "del wd_raw\n",
    "del lirwd_call_plan\n",
    "del temp_abbv\n",
    "del temp_calls\n",
    "del temp_samples\n",
    "del active_calls\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T14:40:21.083175Z",
     "iopub.status.busy": "2024-08-06T14:40:21.080321Z",
     "iopub.status.idle": "2024-08-06T14:40:23.440758Z",
     "shell.execute_reply": "2024-08-06T14:40:23.439652Z"
    }
   },
   "outputs": [],
   "source": [
    "# importing mp so that we can pull in geo_id and roll up rx data\n",
    "mp_spec_seg_dec = pl.read_parquet(dflib+'mp_spec_seg_dec.parquet')\n",
    "\n",
    "#load xpn-\n",
    "laxdn = pl.read_parquet(xpn+'LAX_DN.parquet',columns=['IID'] + [f'LINFTUF{i}' for i in range(1,num_weeks_rx+1)]\n",
    ").with_columns(wk_qtd = pl.sum_horizontal([f'LINFTUF{i}' for i in range(1,num_weeks_rx+1)])\n",
    ").join(mp_spec_seg_dec[['IID','geography_id']],on = 'IID', how = 'left'\n",
    ").group_by('geography_id').agg(wk_qtd = pl.col('wk_qtd').sum())\n",
    "\n",
    "# load voucher-\n",
    "vch = pl.read_parquet(xpn+'LIN_VOUCHER.parquet',columns=['IID'] + [f'LINVTUF{i}' for i in range(1,num_weeks_rx+1)]\n",
    ").with_columns(vwk_qtd = pl.sum_horizontal([f'LINVTUF{i}' for i in range(1,num_weeks_rx+1)])\n",
    ").join(mp_spec_seg_dec[['IID','geography_id']],on = 'IID', how = 'left'\n",
    ").group_by('geography_id').agg(vwk_qtd = pl.col('vwk_qtd').sum())\n",
    "\n",
    "laxdn = laxdn.join(vch,on='geography_id',how='left').with_columns(\n",
    "    wk_qtd = pl.col('wk_qtd') - pl.col('vwk_qtd')\n",
    ").drop('vwk_qtd')\n",
    "\n",
    "laxdn.to_pandas().to_parquet(dflib+'laxdn_geoid_sum.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
