{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "577489f5-d2a0-441f-83f4-791099666d24",
   "metadata": {},
   "source": [
    "# DenormalizedPrescriber MetricPerformance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a8509ce-a98e-4f2d-9acc-34ce63b237f7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "import gc\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4a4da14-d88a-4c44-82f1-4abeb917bfda",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# load variables from JSON\n",
    "with open('vars_wk.json', 'r') as json_file:\n",
    "    js = json.load(json_file)\n",
    "\n",
    "data_date = js['data_date']\n",
    "num_weeks_rx = js['num_weeks_rx']\n",
    "qtr_data = js['qtr_data']\n",
    "bucket = js['bucket']\n",
    "YTD = js['YTD']\n",
    "QTD_m = js['QTD_m']\n",
    "monthly_data_date = js['monthly_data_date']\n",
    "\n",
    "dflib = f's3://{bucket}/BIT/dataframes/'\n",
    "geo = f's3://{bucket}/PYADM/quaterly/{qtr_data}/geography/'\n",
    "xpn = f's3://{bucket}/PYADM/weekly/archive/{data_date}/xponent/'\n",
    "mxpn = f's3://{bucket}/PYADM/monthly/archive/{monthly_data_date}/xponent/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df51ae7d-b204-4760-ba71-6dca3a220381",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Utility Functions -\n",
    "def load(df, lib=dflib):\n",
    "    globals()[df] = pl.read_parquet(f'{lib}{df}.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea96570b-bc6d-4f7c-b325-9a811fc8c513",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Importing Dependencies\n",
    "load('mp_spec_seg_dec')\n",
    "load('MASTER_UNI')\n",
    "prod_mapping = pl.read_csv(f's3://{bucket}/BIT/docs/productmapping_pybit.txt',separator='|')\n",
    "fetch_products = ['LI1','LI2','LI3','TRU','AMT','LAC','MOT','LUB','IRL']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae282c58-222e-41bd-965d-b610ae092fc2",
   "metadata": {},
   "source": [
    "Generator Functions \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67302953-46fb-4fb3-aeb1-44c8f430bef7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# For Voucher Removal - \n",
    "def get_lin_voucher():\n",
    "    vch = pl.read_parquet(f'{mxpn}LIN_VOUCHER.parquet') \n",
    "    vch1 = pl.DataFrame()\n",
    "    for prod in ['LIN1','LIN2','LIN3']: # LINV\n",
    "        vch_prod = (\n",
    "            vch.select(\n",
    "                pl.col('IID'),\n",
    "                pl.col(f'{prod}TUF1').alias(f'vTUF_1c'),\n",
    "                pl.sum_horizontal([f'{prod}TUF{i}' for i in range(1,4)]).alias(f'vTUF_3c'),\n",
    "                pl.sum_horizontal([f'{prod}TUF{i}' for i in range(1,7)]).alias(f'vTUF_6c'),\n",
    "                pl.sum_horizontal([f'{prod}TUF{i}' for i in range(1,13)]).alias(f'vTUF_12c'),\n",
    "                pl.sum_horizontal([f'{prod}TUF{i}' for i in range(QTD_m+1,QTD_m+4)]).alias(f'vTUF_pqtrc'),\n",
    "                pl.sum_horizontal([f'{prod}TUF{i}' for i in range(1,YTD+1)]).alias(f'vTUF_ytdc'),\n",
    "                pl.col(f'{prod}TUF2').alias(f'vTUF_1p'),\n",
    "                pl.sum_horizontal([f'{prod}TUF{i}' for i in range(4,7)]).alias(f'vTUF_3p'),\n",
    "                pl.sum_horizontal([f'{prod}TUF{i}' for i in range(7,13)]).alias(f'vTUF_6p'),\n",
    "                pl.sum_horizontal([f'{prod}TUF{i}' for i in range(13,25)]).alias(f'vTUF_12p'),\n",
    "                pl.sum_horizontal([f'{prod}TUF{i}' for i in  range(QTD_m+4,QTD_m+7)]).alias(f'vTUF_pqtrp'),\n",
    "                pl.sum_horizontal([f'{prod}TUF{i}' for i in range(13,13+YTD)]).alias(f'vTUF_ytdp'),\n",
    "                pl.sum_horizontal([f'{prod}TUF{i}' for i in range(1,25)]).alias(f'vTUF_all') #added 105 week datacut\n",
    "            )\n",
    "            .with_columns(pl.lit(f'LI{prod[-1]}').alias('PROD_CD'))\n",
    "        )\n",
    "        if prod[-1] == '1':\n",
    "            vch1 = vch_prod.clone()\n",
    "        else:\n",
    "            vch1 = pl.concat([vch1, vch_prod])\n",
    "\n",
    "    # voucher_mapping = {'LI1': 4, 'LI2': 5, 'LI3': 3, 'LIV': 2}\n",
    "    vch1 = vch1.fill_null(0)\n",
    "    return(vch1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d342766-3198-4cd9-810f-b4e61c7806c3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_summed_period_iid_metric(metric,prod_cd):\n",
    "    columns = ['IID','PROD_CD'] + [metric+str(i) for i in range(1,25)]\n",
    "    df = pl.read_parquet(mxpn+'LAX.parquet',columns=columns).filter(pl.col('PROD_CD').is_in(prod_cd))\n",
    "\n",
    "    # 1,3,6,12,pqtd,ytd for current and prior period for a given Metric\n",
    "    df = df.select(\n",
    "        pl.col('IID'),pl.col('PROD_CD'),\n",
    "        pl.col(metric+'1').alias(metric+'_1c'),\n",
    "        pl.sum_horizontal([metric+str(i) for i in range(1,4)]).alias(metric+'_3c'),\n",
    "        pl.sum_horizontal([metric+str(i) for i in range(1,7)]).alias(metric+'_6c'),\n",
    "        pl.sum_horizontal([metric+str(i) for i in range(1,13)]).alias(metric+'_12c'),\n",
    "        pl.sum_horizontal([metric+str(i) for i in range(QTD_m+1,QTD_m+4)]).alias(metric+'_pqtrc'),\n",
    "        pl.sum_horizontal([metric+str(i) for i in range(1,YTD+1)]).alias(metric+'_ytdc'),\n",
    "\n",
    "        pl.col(metric+'2').alias(metric+'_1p'),\n",
    "        pl.sum_horizontal([metric+str(i) for i in range(4,7)]).alias(metric+'_3p'),\n",
    "        pl.sum_horizontal([metric+str(i) for i in range(7,13)]).alias(metric+'_6p'),\n",
    "        pl.sum_horizontal([metric+str(i) for i in range(13,25)]).alias(metric+'_12p'),\n",
    "        pl.sum_horizontal([metric+str(i) for i in  range(QTD_m+4,QTD_m+7)]).alias(metric+'_pqtrp'),\n",
    "        pl.sum_horizontal([metric+str(i) for i in range(13,13+YTD)]).alias(metric+'_ytdp'),\n",
    "\n",
    "        pl.sum_horizontal([metric+str(i) for i in range(1,25)]).alias(metric+'_all')\n",
    "    )\n",
    "\n",
    "    # For Voucher Removal - \n",
    "    if metric == 'TUF':\n",
    "        dfv = get_lin_voucher()\n",
    "        df = df.join(dfv,on=['IID','PROD_CD'],how='left').fill_null(0)\n",
    "        cols_to_remove = dfv.columns[1:-1]\n",
    "        df = df.with_columns(\n",
    "            pl.col(f'{metric}_1c') -  pl.col(f'v{metric}_1c').alias(f'{metric}_1c'),\n",
    "            pl.col(f'{metric}_3c') -  pl.col(f'v{metric}_3c').alias(f'{metric}_3c'),\n",
    "            pl.col(f'{metric}_6c') -  pl.col(f'v{metric}_6c').alias(f'{metric}_6c'),\n",
    "            pl.col(f'{metric}_12c') -  pl.col(f'v{metric}_12c').alias(f'{metric}_12c'),\n",
    "            pl.col(f'{metric}_pqtrc') -  pl.col(f'v{metric}_pqtrc').alias(f'{metric}_pqtrc'),\n",
    "            pl.col(f'{metric}_ytdc') -  pl.col(f'v{metric}_ytdc').alias(f'{metric}_ytdc'),\n",
    "            pl.col(f'{metric}_1p') -  pl.col(f'v{metric}_1p').alias(f'{metric}_1p'),\n",
    "            pl.col(f'{metric}_3p') -  pl.col(f'v{metric}_3p').alias(f'{metric}_3p'),\n",
    "            pl.col(f'{metric}_6p') -  pl.col(f'v{metric}_6p').alias(f'{metric}_6p'),\n",
    "            pl.col(f'{metric}_12p') -  pl.col(f'v{metric}_12p').alias(f'{metric}_12p'),\n",
    "            pl.col(f'{metric}_pqtrp') -  pl.col(f'v{metric}_pqtrp').alias(f'{metric}_pqtrp'),\n",
    "            pl.col(f'{metric}_ytdp') -  pl.col(f'v{metric}_ytdp').alias(f'{metric}_ytdp'),\n",
    "            pl.col(f'{metric}_all') -  pl.col(f'v{metric}_all').alias(f'{metric}_all')\n",
    "        ).drop(cols_to_remove)\n",
    "\n",
    "    # Adding MP related columns\n",
    "    df = df.join(mp_spec_seg_dec,on='IID',how='left').filter(pl.col('geography_id').is_not_null())\n",
    "\n",
    "    return(df.drop(['specialty_group','segment','decile','geography_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e525e15-902f-4330-98b0-799e857b877d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# RAW DATA PREP -\n",
    "\n",
    "all_products_tuf = get_summed_period_iid_metric('TUF',fetch_products)\n",
    "all_products_nuf = get_summed_period_iid_metric('NUF',fetch_products)\n",
    "all_products_tuf_nuf = (\n",
    "    all_products_tuf\n",
    "    .join(all_products_nuf,on = ['IID','PROD_CD'] ,how='left')\n",
    "    .join(\n",
    "        prod_mapping[['code','product_id']],\n",
    "        left_on = 'PROD_CD',right_on='code',how='left'\n",
    "    ).drop('PROD_CD')\n",
    "    .select(['IID','product_id','TUF_1c','TUF_1p','TUF_pqtrc','TUF_pqtrp','NUF_1c','NUF_1p','NUF_pqtrc','NUF_pqtrp'])\n",
    ")\n",
    "\n",
    "lax_tuf_nuf = all_products_tuf_nuf.group_by('IID').agg(\n",
    "    TUF_1c_LAX = pl.col('TUF_1c').sum(),TUF_pqtrc_LAX = pl.col('TUF_pqtrc').sum(),\n",
    "    TUF_1p_LAX = pl.col('TUF_1p').sum(),TUF_pqtrp_LAX = pl.col('TUF_pqtrp').sum(),\n",
    "    NUF_1c_LAX = pl.col('NUF_1c').sum(),NUF_pqtrc_LAX = pl.col('NUF_pqtrc').sum(),\n",
    "    NUF_1p_LAX = pl.col('NUF_1p').sum(),NUF_pqtrp_LAX = pl.col('NUF_pqtrp').sum()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41b459d-2fc7-47b9-ac45-e369f2c6c8e8",
   "metadata": {},
   "source": [
    "Functions \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab31fd15-efc2-40f6-9d43-aa3bb4f8079d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_linzess_strength_columns(df,prod_id_list,prod):\n",
    "    df = df.join(\n",
    "        all_products_tuf_nuf.filter(pl.col('product_id').is_in(prod_id_list)),\n",
    "        on = 'IID', how = 'left'\n",
    "    )\n",
    "    df = df.group_by('IID').agg(\n",
    "        TUF_1c_prod = pl.col('TUF_1c').sum(),TUF_pqtrc_prod = pl.col('TUF_pqtrc').sum(),\n",
    "        TUF_1p_prod = pl.col('TUF_1p').sum(),TUF_pqtrp_prod = pl.col('TUF_pqtrp').sum(),\n",
    "        NUF_1c_prod = pl.col('NUF_1c').sum(),NUF_pqtrc_prod = pl.col('NUF_pqtrc').sum(),\n",
    "        NUF_1p_prod = pl.col('NUF_1p').sum(),NUF_pqtrp_prod = pl.col('NUF_pqtrp').sum()\n",
    "    )\n",
    "    df = df.join(\n",
    "        lax_tuf_nuf,on = 'IID',how = 'left'\n",
    "    )\n",
    "    expn_dict = {\n",
    "        f'{prod}_pqtr_trx_cur_vol' : pl.col('TUF_pqtrc_prod'),\n",
    "        f'{prod}_pqtr_trx_pri_vol' : pl.col('TUF_pqtrp_prod'),\n",
    "        f'{prod}_pqtr_trx_vol_change' : (pl.col('TUF_pqtrc_prod')-pl.col('TUF_pqtrp_prod')),\n",
    "        f'{prod}_pqtr_trx_share' : (pl.col('TUF_pqtrc_prod')/pl.col('TUF_pqtrc_LAX')),\n",
    "\n",
    "        f'{prod}_pqtr_nrx_cur_vol' : pl.col('NUF_pqtrc_prod'),\n",
    "        f'{prod}_pqtr_nrx_pri_vol' : pl.col('NUF_pqtrp_prod'),\n",
    "        f'{prod}_pqtr_nrx_vol_change' : (pl.col('NUF_pqtrc_prod')-pl.col('NUF_pqtrp_prod')),\n",
    "        f'{prod}_pqtr_nrx_share' : (pl.col('NUF_pqtrc_prod')/pl.col('NUF_pqtrc_LAX')),\n",
    "\n",
    "        f'{prod}_1_trx_cur_vol' : pl.col('TUF_1c_prod'),\n",
    "        f'{prod}_1_trx_pri_vol' : pl.col('TUF_1p_prod'),\n",
    "        f'{prod}_1_trx_vol_change' : (pl.col('TUF_1c_prod')-pl.col('TUF_1p_prod')),\n",
    "        f'{prod}_1_trx_share' : (pl.col('TUF_1c_prod')/pl.col('TUF_1c_LAX')),\n",
    "\n",
    "        f'{prod}_1_nrx_cur_vol' : pl.col('NUF_1c_prod'),\n",
    "        f'{prod}_1_nrx_pri_vol' : pl.col('NUF_1p_prod'),\n",
    "        f'{prod}_1_nrx_vol_change' : (pl.col('NUF_1c_prod')-pl.col('NUF_1p_prod')),\n",
    "        f'{prod}_1_nrx_share' : (pl.col('NUF_1c_prod')/pl.col('NUF_1c_LAX')),\n",
    "    }\n",
    "    # adding columns now :\n",
    "    df2 = df.with_columns(**expn_dict).select(['IID']+list(expn_dict.keys()))\n",
    "\n",
    "    df2 = df2.with_columns(\n",
    "        pl.when((pl.col(f'{prod}_pqtr_trx_vol_change')/pl.col(f'{prod}_pqtr_trx_pri_vol')) > 0.02).then(pl.lit('P'))\n",
    "        .when((pl.col(f'{prod}_pqtr_trx_vol_change')/pl.col(f'{prod}_pqtr_trx_pri_vol')) < -0.02).then(pl.lit('Q'))\n",
    "        .when(pl.col(f'{prod}_pqtr_trx_vol_change')==0).then(pl.lit('\\\\N'))\n",
    "        .otherwise(pl.lit('\\\\N')).alias(f'{prod}_pqtr_vol_change_ind_trx'),\n",
    "        \n",
    "        pl.when((pl.col(f'{prod}_pqtr_nrx_vol_change')/pl.col(f'{prod}_pqtr_nrx_pri_vol')) > 0.02).then(pl.lit('P'))\n",
    "        .when((pl.col(f'{prod}_pqtr_nrx_vol_change')/pl.col(f'{prod}_pqtr_nrx_pri_vol')) < -0.02).then(pl.lit('Q'))\n",
    "        .when(pl.col(f'{prod}_pqtr_nrx_vol_change')==0).then(pl.lit('\\\\N'))\n",
    "        .otherwise(pl.lit('\\\\N')).alias(f'{prod}_pqtr_vol_change_ind_nrx'),\n",
    "\n",
    "        pl.when((pl.col(f'{prod}_1_trx_vol_change')/pl.col(f'{prod}_1_trx_pri_vol')) > 0.02).then(pl.lit('P'))\n",
    "        .when((pl.col(f'{prod}_1_trx_vol_change')/pl.col(f'{prod}_1_trx_pri_vol')) < -0.02).then(pl.lit('Q'))\n",
    "        .when(pl.col(f'{prod}_1_trx_vol_change')==0).then(pl.lit('\\\\N'))\n",
    "        .otherwise(pl.lit('\\\\N')).alias(f'{prod}_1_vol_change_ind_trx'),\n",
    "        \n",
    "        pl.when((pl.col(f'{prod}_1_nrx_vol_change')/pl.col(f'{prod}_1_nrx_pri_vol')) > 0.02).then(pl.lit('P'))\n",
    "        .when((pl.col(f'{prod}_1_nrx_vol_change')/pl.col(f'{prod}_1_nrx_pri_vol')) < -0.02).then(pl.lit('Q'))\n",
    "        .when(pl.col(f'{prod}_1_nrx_vol_change')==0).then(pl.lit('\\\\N'))\n",
    "        .otherwise(pl.lit('\\\\N')).alias(f'{prod}_1_vol_change_ind_nrx')\n",
    "    )\n",
    "\n",
    "    #dropping shr columns if not whole family\n",
    "    if prod != 'LIN':\n",
    "        df2 = df2.drop([col for col in df2.columns if 'share' in col])\n",
    "\n",
    "    return(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef47630a-4c70-412e-843d-5c79e9143689",
   "metadata": {},
   "source": [
    "Processing \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1be178a-4d10-4c3d-8446-0ab7dd8ff76a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Processing\n",
    "temp1 = mp_spec_seg_dec.select(['IID','geography_id'])\n",
    "\n",
    "LIN_cols = get_linzess_strength_columns(temp1,[3,4,5],'LIN')\n",
    "LI1_cols = get_linzess_strength_columns(temp1,[3],'LI1')\n",
    "LI2_cols = get_linzess_strength_columns(temp1,[4],'LI2')\n",
    "LI3_cols = get_linzess_strength_columns(temp1,[5],'LI3')\n",
    "\n",
    "# join all of them back to temp1\n",
    "temp1 = temp1.join(LIN_cols,on='IID',how='left'\n",
    ").join(LI1_cols,on='IID',how='left'\n",
    ").join(LI2_cols,on='IID',how='left'\n",
    ").join(LI3_cols,on='IID',how='left'\n",
    ").with_columns(Product_id = pl.lit(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8b3f250-19d8-4469-a75b-ae189ff35094",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# for filtering extra obs\n",
    "check_cols = []\n",
    "for col in temp1.columns:\n",
    "    if ((col.startswith('LIN')) & ('ind' not in col) & ('share' not in col) & ('change' not in col)):\n",
    "        check_cols.append(col)\n",
    "temp1 = (\n",
    "    temp1\n",
    "    .with_columns(\n",
    "        qc=pl.sum_horizontal(check_cols)\n",
    "    )\n",
    "    .filter(\n",
    "        (pl.col('qc') != 0)\n",
    "    )\n",
    "    .drop(['qc'])\n",
    ")\n",
    "\n",
    "for c in ['LIN_pqtr_trx_share','LIN_pqtr_nrx_share','LIN_1_trx_share','LIN_1_nrx_share']: # convert NaN to 0.0\n",
    "    temp1 = temp1.with_columns(pl.col(c).replace(np.nan,0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d8c0efc-c5ee-49a8-8ff6-7ab120fbee79",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# PDRP Overrides - \n",
    "temp1 = temp1.join(MASTER_UNI.select(['IID','PDRPOptOutFlag']),on='IID',how='left')\n",
    "override_columns =  temp1.columns[2:-2]\n",
    "expression_list = [\n",
    "    pl.when(pl.col('PDRPOptOutFlag')=='Y').then(pl.lit('\\\\N')).otherwise(pl.col(c)).alias(c)\n",
    "    for c in override_columns\n",
    "]\n",
    "temp1 = temp1.with_columns(expression_list).drop('PDRPOptOutFlag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "090642cb-a79e-4374-b2ec-4d7962dc880c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Making Data Feed Ready-\n",
    "\n",
    "col_mapping = {\n",
    "    'IID':'Physician_ID',\n",
    "    'geography_id':'Geography_id',\n",
    "    'LIN_pqtr_trx_cur_vol':'NumberMetric1',\n",
    "    'LIN_pqtr_trx_pri_vol':'NumberMetric2',\n",
    "    'LIN_pqtr_trx_vol_change':'NumberMetric3',\n",
    "    'LIN_pqtr_trx_share':'NumberMetric4',\n",
    "    'LIN_pqtr_nrx_cur_vol':'NumberMetric6',\n",
    "    'LIN_pqtr_nrx_pri_vol':'NumberMetric7',\n",
    "    'LIN_pqtr_nrx_vol_change':'NumberMetric8',\n",
    "    'LIN_pqtr_nrx_share':'NumberMetric9',\n",
    "    'LIN_1_trx_cur_vol':'NumberMetric11',\n",
    "    'LIN_1_trx_pri_vol':'NumberMetric12',\n",
    "    'LIN_1_trx_vol_change':'NumberMetric13',\n",
    "    'LIN_1_trx_share':'NumberMetric14',\n",
    "    'LIN_1_nrx_cur_vol':'NumberMetric16',\n",
    "    'LIN_1_nrx_pri_vol':'NumberMetric17',\n",
    "    'LIN_1_nrx_vol_change':'NumberMetric18',\n",
    "    'LIN_1_nrx_share':'NumberMetric19',\n",
    "    'LI1_pqtr_trx_cur_vol':'NumberMetric21',\n",
    "    'LI1_pqtr_trx_pri_vol':'NumberMetric22',\n",
    "    'LI1_pqtr_trx_vol_change':'NumberMetric23',\n",
    "    'LI1_pqtr_nrx_cur_vol':'NumberMetric24',\n",
    "    'LI1_pqtr_nrx_pri_vol':'NumberMetric25',\n",
    "    'LI1_pqtr_nrx_vol_change':'NumberMetric26',\n",
    "    'LI1_1_trx_cur_vol':'NumberMetric27',\n",
    "    'LI1_1_trx_pri_vol':'NumberMetric28',\n",
    "    'LI1_1_trx_vol_change':'NumberMetric29',\n",
    "    'LI1_1_nrx_cur_vol':'NumberMetric30',\n",
    "    'LI1_1_nrx_pri_vol':'NumberMetric31',\n",
    "    'LI1_1_nrx_vol_change':'NumberMetric32',\n",
    "    'LI2_pqtr_trx_cur_vol':'NumberMetric81',\n",
    "    'LI2_pqtr_trx_pri_vol':'NumberMetric82',\n",
    "    'LI2_pqtr_trx_vol_change':'NumberMetric83',\n",
    "    'LI2_pqtr_nrx_cur_vol':'NumberMetric84',\n",
    "    'LI2_pqtr_nrx_pri_vol':'NumberMetric85',\n",
    "    'LI2_pqtr_nrx_vol_change':'NumberMetric86',\n",
    "    'LI2_1_trx_cur_vol':'NumberMetric87',\n",
    "    'LI2_1_trx_pri_vol':'NumberMetric88',\n",
    "    'LI2_1_trx_vol_change':'NumberMetric89',\n",
    "    'LI2_1_nrx_cur_vol':'NumberMetric90',\n",
    "    'LI2_1_nrx_pri_vol':'NumberMetric91',\n",
    "    'LI2_1_nrx_vol_change':'NumberMetric92',\n",
    "    'LI3_pqtr_trx_cur_vol':'NumberMetric69',\n",
    "    'LI3_pqtr_trx_pri_vol':'NumberMetric70',\n",
    "    'LI3_pqtr_trx_vol_change':'NumberMetric71',\n",
    "    'LI3_pqtr_nrx_cur_vol':'NumberMetric72',\n",
    "    'LI3_pqtr_nrx_pri_vol':'NumberMetric73',\n",
    "    'LI3_pqtr_nrx_vol_change':'NumberMetric74',\n",
    "    'LI3_1_trx_cur_vol':'NumberMetric75',\n",
    "    'LI3_1_trx_pri_vol':'NumberMetric76',\n",
    "    'LI3_1_trx_vol_change':'NumberMetric77',\n",
    "    'LI3_1_nrx_cur_vol':'NumberMetric78',\n",
    "    'LI3_1_nrx_pri_vol':'NumberMetric79',\n",
    "    'LI3_1_nrx_vol_change':'NumberMetric80',\n",
    "    'LIN_pqtr_vol_change_ind_trx':'StringMetric1',\n",
    "    'LIN_pqtr_vol_change_ind_nrx':'StringMetric2',\n",
    "    'LIN_1_vol_change_ind_trx':'StringMetric3',\n",
    "    'LIN_1_vol_change_ind_nrx':'StringMetric4',\n",
    "    'LI1_pqtr_vol_change_ind_trx':'StringMetric5',\n",
    "    'LI1_pqtr_vol_change_ind_nrx':'StringMetric6',\n",
    "    'LI1_1_vol_change_ind_trx':'StringMetric7',\n",
    "    'LI1_1_vol_change_ind_nrx':'StringMetric8',\n",
    "    'LI2_pqtr_vol_change_ind_trx':'StringMetric25',\n",
    "    'LI2_pqtr_vol_change_ind_nrx':'StringMetric26',\n",
    "    'LI2_1_vol_change_ind_trx':'StringMetric27',\n",
    "    'LI2_1_vol_change_ind_nrx':'StringMetric28',\n",
    "    'LI3_pqtr_vol_change_ind_trx':'StringMetric21',\n",
    "    'LI3_pqtr_vol_change_ind_nrx':'StringMetric22',\n",
    "    'LI3_1_vol_change_ind_trx':'StringMetric23',\n",
    "    'LI3_1_vol_change_ind_nrx':'StringMetric24'\n",
    "}\n",
    "final_feed = temp1.rename(col_mapping)\n",
    "#required new columns for feed\n",
    "cols_to_addna = [\n",
    "    'NumberMetric5', 'NumberMetric10', 'NumberMetric15', 'NumberMetric20',\n",
    "    'NumberMetric33', 'NumberMetric34', 'NumberMetric35', 'NumberMetric36',\n",
    "    'NumberMetric37', 'NumberMetric38', 'NumberMetric39', 'NumberMetric40',\n",
    "    'NumberMetric41', 'NumberMetric42', 'NumberMetric43', 'NumberMetric44',\n",
    "    'NumberMetric45', 'NumberMetric46', 'NumberMetric47', 'NumberMetric48',\n",
    "    'NumberMetric49', 'NumberMetric50', 'NumberMetric51', 'NumberMetric52',\n",
    "    'NumberMetric53', 'NumberMetric54', 'NumberMetric55', 'NumberMetric56',\n",
    "    'NumberMetric57', 'NumberMetric58', 'NumberMetric59', 'NumberMetric60',\n",
    "    'NumberMetric61', 'NumberMetric62', 'NumberMetric63', 'NumberMetric64',\n",
    "    'NumberMetric65', 'NumberMetric66', 'NumberMetric67','NumberMetric68',\n",
    "    'StringMetric9', 'StringMetric10','StringMetric11','StringMetric12',\n",
    "    'StringMetric13', 'StringMetric14', 'StringMetric15', 'StringMetric16', \n",
    "    'StringMetric17', 'StringMetric18', 'StringMetric19', 'StringMetric20'\n",
    "]\n",
    "for my_col in cols_to_addna:\n",
    "        final_feed = final_feed.with_columns(pl.lit('\\\\N').alias(my_col))\n",
    "\n",
    "# rearranging columns accoring to feed.\n",
    "req_cols = variable_names = [\n",
    "    \"Physician_ID\", \"Geography_id\", \"Product_id\"] + ['NumberMetric' + str(i) for i in range(1,93)] + ['StringMetric' + str(i) for i in range(1,29)]\n",
    "final_feed = final_feed.select(req_cols)#final_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e14af39-dde0-4320-bfb9-8e8bd21ab7ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-01T08:24:06.839035Z",
     "iopub.status.busy": "2024-10-01T08:24:06.836870Z",
     "iopub.status.idle": "2024-10-01T08:24:17.271825Z",
     "shell.execute_reply": "2024-10-01T08:24:17.270714Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Denorm Presc Metric Feed Exported !\n"
     ]
    }
   ],
   "source": [
    "#Exporting Feeds-\n",
    "OUT = 's3://vortex-staging-a65ced90/BIT/output/DenormalizedPrescriber/Monthly/'\n",
    "final_feed.to_pandas().to_csv(f'{OUT}Monthly_DenormalizedPrescriber_MetricPerformance_Feed.txt',sep='|',lineterminator='\\r\\n',index=False)\n",
    "print('Denorm Presc Metric Feed Exported !')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64b7067-6946-47dc-b5a0-0cda6492a8a3",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
