{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f2da903-f13c-45dc-8129-b0235ceca334",
   "metadata": {},
   "source": [
    "# Prescriber View - Sales Performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f38a7590-18c9-4d39-b768-629444345018",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T10:02:47.699398Z",
     "iopub.status.busy": "2024-10-04T10:02:47.699007Z",
     "iopub.status.idle": "2024-10-04T10:02:48.414129Z",
     "shell.execute_reply": "2024-10-04T10:02:48.413133Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "import gc\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e0ab6e8-deb2-4fba-bbca-6542b20cc460",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T10:02:48.418066Z",
     "iopub.status.busy": "2024-10-04T10:02:48.417241Z",
     "iopub.status.idle": "2024-10-04T10:02:48.422774Z",
     "shell.execute_reply": "2024-10-04T10:02:48.421919Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# load variables from JSON\n",
    "with open('vars_wk.json', 'r') as json_file:\n",
    "    js = json.load(json_file)\n",
    "\n",
    "bucket = js['bucket']\n",
    "YTD = js['YTD']\n",
    "QTD_m = js['QTD_m']\n",
    "monthly_data_date = js['monthly_data_date']\n",
    "\n",
    "dflib = f's3://{bucket}/BIT/dataframes/'\n",
    "mxpn = f's3://{bucket}/PYADM/monthly/archive/{monthly_data_date}/xponent/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2180f2d-5f30-42bc-a33a-d863d29ee45e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T10:02:48.426503Z",
     "iopub.status.busy": "2024-10-04T10:02:48.425943Z",
     "iopub.status.idle": "2024-10-04T10:02:48.430531Z",
     "shell.execute_reply": "2024-10-04T10:02:48.429788Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Utility Functions -\n",
    "def load(df, lib=dflib):\n",
    "    globals()[df] = pl.read_parquet(f'{lib}{df}.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9fe7a19-45f3-4efd-a212-d204b38e6b0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T10:02:48.433569Z",
     "iopub.status.busy": "2024-10-04T10:02:48.433138Z",
     "iopub.status.idle": "2024-10-04T10:02:50.996513Z",
     "shell.execute_reply": "2024-10-04T10:02:50.995611Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Imporing Dependencies\n",
    "prod_mapping = pl.read_csv(f's3://{bucket}/BIT/docs/productmapping_pybit.txt',separator='|')\n",
    "geo_code_mapper = pl.from_pandas(pd.read_excel(f's3://{bucket}/BIT/docs/geo_id_full.xlsx'))\n",
    "load('mp_spec_seg_dec')\n",
    "load('MASTER_UNI')\n",
    "fetch_products = ['LI1','LI2','LI3','TRU','AMT','LAC','MOT','LUB','IRL']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef966dc-5a91-4d86-ac1c-d322ca8e304e",
   "metadata": {},
   "source": [
    "Generator Functions -\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41080c31-50c4-4ba3-a8b6-765dc71d65cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T10:02:51.009900Z",
     "iopub.status.busy": "2024-10-04T10:02:50.999770Z",
     "iopub.status.idle": "2024-10-04T10:02:51.035306Z",
     "shell.execute_reply": "2024-10-04T10:02:51.034147Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# For Voucher Removal - \n",
    "def get_lin_voucher():\n",
    "    vch = pl.read_parquet(f'{mxpn}LIN_VOUCHER.parquet') \n",
    "    vch1 = pl.DataFrame()\n",
    "    for prod in ['LIN1','LIN2','LIN3']: # LINV\n",
    "        vch_prod = (\n",
    "            vch.select(\n",
    "                pl.col('IID'),\n",
    "                pl.col(f'{prod}TUF1').alias(f'vTUF_1c'),\n",
    "                pl.sum_horizontal([f'{prod}TUF{i}' for i in range(1,4)]).alias(f'vTUF_3c'),\n",
    "                pl.sum_horizontal([f'{prod}TUF{i}' for i in range(1,7)]).alias(f'vTUF_6c'),\n",
    "                pl.sum_horizontal([f'{prod}TUF{i}' for i in range(1,13)]).alias(f'vTUF_12c'),\n",
    "                pl.sum_horizontal([f'{prod}TUF{i}' for i in range(QTD_m+1,QTD_m+4)]).alias(f'vTUF_pqtrc'),\n",
    "                pl.sum_horizontal([f'{prod}TUF{i}' for i in range(1,YTD+1)]).alias(f'vTUF_ytdc'),\n",
    "                pl.col(f'{prod}TUF2').alias(f'vTUF_1p'),\n",
    "                pl.sum_horizontal([f'{prod}TUF{i}' for i in range(4,7)]).alias(f'vTUF_3p'),\n",
    "                pl.sum_horizontal([f'{prod}TUF{i}' for i in range(7,13)]).alias(f'vTUF_6p'),\n",
    "                pl.sum_horizontal([f'{prod}TUF{i}' for i in range(13,25)]).alias(f'vTUF_12p'),\n",
    "                pl.sum_horizontal([f'{prod}TUF{i}' for i in  range(QTD_m+4,QTD_m+7)]).alias(f'vTUF_pqtrp'),\n",
    "                pl.sum_horizontal([f'{prod}TUF{i}' for i in range(13,13+YTD)]).alias(f'vTUF_ytdp'),\n",
    "                pl.sum_horizontal([f'{prod}TUF{i}' for i in range(1,25)]).alias(f'vTUF_all') #added 105 week datacut\n",
    "            )\n",
    "            .with_columns(pl.lit(f'LI{prod[-1]}').alias('PROD_CD'))\n",
    "        )\n",
    "        if prod[-1] == '1':\n",
    "            vch1 = vch_prod.clone()\n",
    "        else:\n",
    "            vch1 = pl.concat([vch1, vch_prod])\n",
    "\n",
    "    # voucher_mapping = {'LI1': 4, 'LI2': 5, 'LI3': 3, 'LIV': 2}\n",
    "    vch1 = vch1.fill_null(0)\n",
    "    return(vch1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b6abf16-0916-4855-943b-0a97c1675475",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T10:02:51.053130Z",
     "iopub.status.busy": "2024-10-04T10:02:51.051849Z",
     "iopub.status.idle": "2024-10-04T10:02:51.085322Z",
     "shell.execute_reply": "2024-10-04T10:02:51.083946Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_summed_period_iid_metric(metric,prod_cd):\n",
    "    columns = ['IID','PROD_CD'] + [metric+str(i) for i in range(1,25)]\n",
    "    df = pl.read_parquet(mxpn+'LAX.parquet',columns=columns).filter(pl.col('PROD_CD').is_in(prod_cd))\n",
    "\n",
    "    # 1,3,6,12,pqtd,ytd for current and prior period for a given Metric\n",
    "    df = df.select(\n",
    "        pl.col('IID'),pl.col('PROD_CD'),\n",
    "        pl.col(metric+'1').alias(metric+'_1c'),\n",
    "        pl.sum_horizontal([metric+str(i) for i in range(1,4)]).alias(metric+'_3c'),\n",
    "        pl.sum_horizontal([metric+str(i) for i in range(1,7)]).alias(metric+'_6c'),\n",
    "        pl.sum_horizontal([metric+str(i) for i in range(1,13)]).alias(metric+'_12c'),\n",
    "        pl.sum_horizontal([metric+str(i) for i in range(QTD_m+1,QTD_m+4)]).alias(metric+'_pqtrc'),\n",
    "        pl.sum_horizontal([metric+str(i) for i in range(1,YTD+1)]).alias(metric+'_ytdc'),\n",
    "\n",
    "        pl.col(metric+'2').alias(metric+'_1p'),\n",
    "        pl.sum_horizontal([metric+str(i) for i in range(4,7)]).alias(metric+'_3p'),\n",
    "        pl.sum_horizontal([metric+str(i) for i in range(7,13)]).alias(metric+'_6p'),\n",
    "        pl.sum_horizontal([metric+str(i) for i in range(13,25)]).alias(metric+'_12p'),\n",
    "        pl.sum_horizontal([metric+str(i) for i in  range(QTD_m+4,QTD_m+7)]).alias(metric+'_pqtrp'),\n",
    "        pl.sum_horizontal([metric+str(i) for i in range(13,13+YTD)]).alias(metric+'_ytdp'),\n",
    "\n",
    "        pl.sum_horizontal([metric+str(i) for i in range(1,25)]).alias(metric+'_all')\n",
    "    )\n",
    "\n",
    "    # For Voucher Removal - \n",
    "    if metric == 'TUF':\n",
    "        dfv = get_lin_voucher()\n",
    "        df = df.join(dfv,on=['IID','PROD_CD'],how='left').fill_null(0)\n",
    "        cols_to_remove = dfv.columns[1:-1]\n",
    "        df = df.with_columns(\n",
    "            pl.col(f'{metric}_1c') -  pl.col(f'v{metric}_1c').alias(f'{metric}_1c'),\n",
    "            pl.col(f'{metric}_3c') -  pl.col(f'v{metric}_3c').alias(f'{metric}_3c'),\n",
    "            pl.col(f'{metric}_6c') -  pl.col(f'v{metric}_6c').alias(f'{metric}_6c'),\n",
    "            pl.col(f'{metric}_12c') -  pl.col(f'v{metric}_12c').alias(f'{metric}_12c'),\n",
    "            pl.col(f'{metric}_pqtrc') -  pl.col(f'v{metric}_pqtrc').alias(f'{metric}_pqtrc'),\n",
    "            pl.col(f'{metric}_ytdc') -  pl.col(f'v{metric}_ytdc').alias(f'{metric}_ytdc'),\n",
    "            pl.col(f'{metric}_1p') -  pl.col(f'v{metric}_1p').alias(f'{metric}_1p'),\n",
    "            pl.col(f'{metric}_3p') -  pl.col(f'v{metric}_3p').alias(f'{metric}_3p'),\n",
    "            pl.col(f'{metric}_6p') -  pl.col(f'v{metric}_6p').alias(f'{metric}_6p'),\n",
    "            pl.col(f'{metric}_12p') -  pl.col(f'v{metric}_12p').alias(f'{metric}_12p'),\n",
    "            pl.col(f'{metric}_pqtrp') -  pl.col(f'v{metric}_pqtrp').alias(f'{metric}_pqtrp'),\n",
    "            pl.col(f'{metric}_ytdp') -  pl.col(f'v{metric}_ytdp').alias(f'{metric}_ytdp'),\n",
    "            pl.col(f'{metric}_all') -  pl.col(f'v{metric}_all').alias(f'{metric}_all')\n",
    "        ).drop(cols_to_remove)\n",
    "\n",
    "    # Adding MP related columns\n",
    "    df = df.join(mp_spec_seg_dec,on='IID',how='left').filter(pl.col('geography_id').is_not_null())\n",
    "\n",
    "    return(df.drop(['specialty_group','segment','decile','geography_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a35ae56-b274-4d40-901a-601036262eb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T10:02:51.090345Z",
     "iopub.status.busy": "2024-10-04T10:02:51.089534Z",
     "iopub.status.idle": "2024-10-04T10:02:51.098515Z",
     "shell.execute_reply": "2024-10-04T10:02:51.097547Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def add_parent_product_rows(df):\n",
    "    agg_dict = {}\n",
    "    for col in df.columns[2:]:\n",
    "        agg_dict[col] = pl.col(col).sum()\n",
    "    \n",
    "    #join_cols = ['geography_id','plan_type','PlanID','IID']\n",
    "\n",
    "    df = df.join(prod_mapping[['code','product_id','parent_product_id']], left_on = 'PROD_CD',right_on = 'code', how = 'left')\n",
    "    df_2_35 = df.filter(pl.col('parent_product_id').is_in([2,35]))\n",
    "    df_2_35 = df_2_35.group_by(['IID','parent_product_id']).agg(**agg_dict).rename({'parent_product_id':'product_id'})\n",
    "    \n",
    "    df_1 = df.group_by('IID').agg(**agg_dict).with_columns(product_id = pl.lit(1)).with_columns(pl.col('product_id').cast(pl.Int64))\n",
    "\n",
    "    # stack 1, 2_35 with df and return\n",
    "    df = df.drop(['PROD_CD','parent_product_id']) #dropping to make same shape\n",
    "    vstack_helper = df.columns\n",
    "    df = df.vstack(\n",
    "        df_2_35.select(vstack_helper)\n",
    "    ).vstack(\n",
    "        df_1.select(vstack_helper)\n",
    "    )\n",
    "\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3036c5f-61b9-4ab6-ae2f-8af51870e6ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T10:02:51.102596Z",
     "iopub.status.busy": "2024-10-04T10:02:51.102052Z",
     "iopub.status.idle": "2024-10-04T10:03:11.944781Z",
     "shell.execute_reply": "2024-10-04T10:03:11.943969Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Raw Data Prep \n",
    "all_products_tuf = get_summed_period_iid_metric('TUF',fetch_products)\n",
    "all_products_nuf = get_summed_period_iid_metric('NUF',fetch_products)\n",
    "all_products_trx = get_summed_period_iid_metric('TRX',fetch_products)\n",
    "all_products_nrx = get_summed_period_iid_metric('NRX',fetch_products)\n",
    "all_products_tun = get_summed_period_iid_metric('TUN',fetch_products)\n",
    "all_products_nun = get_summed_period_iid_metric('NUN',fetch_products)\n",
    "all_products_tuf = add_parent_product_rows(all_products_tuf)\n",
    "all_products_nuf = add_parent_product_rows(all_products_nuf)\n",
    "all_products_trx = add_parent_product_rows(all_products_trx)\n",
    "all_products_nrx = add_parent_product_rows(all_products_nrx)\n",
    "all_products_tun = add_parent_product_rows(all_products_tun)\n",
    "all_products_nun = add_parent_product_rows(all_products_nun)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9e9637-473a-44c1-9bc3-b0670f52dd9f",
   "metadata": {},
   "source": [
    "Functions ->\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9e548f0-efe4-4f09-8680-83e0b0d5b589",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T10:03:11.954125Z",
     "iopub.status.busy": "2024-10-04T10:03:11.953655Z",
     "iopub.status.idle": "2024-10-04T10:03:11.961009Z",
     "shell.execute_reply": "2024-10-04T10:03:11.960155Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def process_1(df):\n",
    "    cols = ['IID',p]\n",
    "    fetch_df = all_products_tuf[cols+[f'TUF{period}c',f'TUF{period}p']].join(\n",
    "        all_products_nuf[cols+[f'NUF{period}c',f'NUF{period}p']],on = cols,how = 'left'\n",
    "    )\n",
    "    df = df.join(fetch_df,on = 'IID',how = 'left'\n",
    "    ).filter(pl.col(p).is_not_null() #added this to remove people with no rx data.\n",
    "    ).rename({f'TUF{period}c':'cur_vol_trx',f'TUF{period}p' : 'pri_vol_trx',\n",
    "              f'NUF{period}c':'cur_vol_nrx',f'NUF{period}p' : 'pri_vol_nrx'\n",
    "    }).with_columns(\n",
    "        vol_change_trx = pl.col('cur_vol_trx')-pl.col('pri_vol_trx'),\n",
    "        vol_change_nrx = pl.col('cur_vol_nrx')-pl.col('pri_vol_nrx')\n",
    "\n",
    "    ).with_columns(\n",
    "        prc_vol_growth_trx = (pl.col('cur_vol_trx')/pl.col('pri_vol_trx'))-1,\n",
    "        prc_vol_growth_nrx = (pl.col('cur_vol_nrx')/pl.col('pri_vol_nrx'))-1\n",
    "    ).filter(\n",
    "        (pl.col('cur_vol_trx')!=0) | (pl.col('cur_vol_nrx')!=0) | (pl.col('pri_vol_trx')!=0) | (pl.col('pri_vol_nrx')!=0)\n",
    "\t)\n",
    "\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe767974-1f4f-4b6e-94f5-dd96472818b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T10:03:11.964242Z",
     "iopub.status.busy": "2024-10-04T10:03:11.963669Z",
     "iopub.status.idle": "2024-10-04T10:03:11.973563Z",
     "shell.execute_reply": "2024-10-04T10:03:11.972889Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Grower or Decliner (TYPE)\t\n",
    "def process_2(df):\n",
    "    source_df = (\n",
    "        all_products_tuf[['IID','product_id',f'TUF{period}c',f'TUF{period}p']]\n",
    "        .rename({f'TUF{period}c':'cur_vol',f'TUF{period}p':'pri_vol'})\n",
    "        .with_columns(pl.col('cur_vol').round(1),pl.col('pri_vol').round(1))\n",
    "        .with_columns(vol_change = pl.col('cur_vol')-pl.col('pri_vol'))\n",
    "        .with_columns(pl.col('vol_change').round(1)).join(mp_spec_seg_dec,on = 'IID',how = 'left').join(geo_code_mapper,on = levels[0],how ='left') \n",
    "    )\n",
    "    source_df_reduced = (\n",
    "        source_df\n",
    "        .join(MASTER_UNI.select(['IID','PDRPOptOutFlag']),on='IID',how='left')\n",
    "        .filter(pl.col('PDRPOptOutFlag')!='Y')\n",
    "        .filter(pl.col('segment')=='Target')\n",
    "        .filter((pl.col('pri_vol')!=0) & (pl.col('pri_vol').is_not_null()))\n",
    "        .filter((pl.col('vol_change')!=0))\n",
    "    )\n",
    "    \n",
    "    source_df_1 = source_df_reduced.filter(pl.col('vol_change')<0) # for 10th perc\n",
    "    source_df_2 = source_df_reduced.filter(pl.col('vol_change')>0) # for 90th perc\n",
    "    source_df_percentile_10 = source_df_1.group_by(levels[1],p).agg(ten_perc = pl.col('vol_change').quantile(0.1,interpolation='linear'))\n",
    "    source_df_percentile_90 = source_df_2.group_by(levels[1],p).agg(nin_perc = pl.col('vol_change').quantile(0.9,interpolation='linear'))\n",
    "    source_df_percentile = source_df_percentile_10.join(source_df_percentile_90,on=[levels[1],p],how='outer_coalesce')\n",
    "    source_df = source_df.join(source_df_percentile,on=[levels[1],p],how='left')\n",
    "    source_df = (\n",
    "        source_df\n",
    "        .with_columns(\n",
    "            pl.when((pl.col('vol_change')<=0) & (pl.col('vol_change') < pl.col('ten_perc'))).then(pl.lit('DECL'))\n",
    "            .when((pl.col('vol_change')>0) & (pl.col('vol_change') > pl.col('nin_perc'))).then(pl.lit('GROW'))\n",
    "            .otherwise(pl.lit(None))\n",
    "            .alias('TYPE_trx')\n",
    "        )\n",
    "        .select(['IID','product_id','TYPE_trx'])\n",
    "    )\n",
    "    # removing PDRP from source : \n",
    "    source_df= source_df.join(MASTER_UNI.select(['IID','PDRPOptOutFlag']),on='IID',how='left').with_columns(pl.col('PDRPOptOutFlag').fill_null('N'))\n",
    "    source_df = (source_df.filter(pl.col('PDRPOptOutFlag')!='Y').drop('PDRPOptOutFlag')) # to count correctly\n",
    "    df = df.join(source_df,on=('IID',p),how = 'left').with_columns(TYPE_nrx = pl.col('TYPE_trx'))\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "266d9483-eea7-4422-a829-dbd528676119",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T10:03:11.977107Z",
     "iopub.status.busy": "2024-10-04T10:03:11.976660Z",
     "iopub.status.idle": "2024-10-04T10:03:11.985043Z",
     "shell.execute_reply": "2024-10-04T10:03:11.983890Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# New Prescriber | PDRP | NC\n",
    "def process_3(df):\n",
    "    #load('MASTER_UNI')\n",
    "    source_df = all_products_tuf.select(['IID',p,'TUF_all']).join(\n",
    "        all_products_nuf.select(['IID',p,'NUF_all']),on=['IID',p],how='left'\n",
    "    )\n",
    "    df = (\n",
    "        df.join(source_df,on=['IID',p],how='left')\n",
    "        .join(MASTER_UNI[['IID','PDRPOptOutFlag']],on='IID',how='left')\n",
    "        .with_columns(\n",
    "            old_volume_trx = pl.col('TUF_all')-pl.col('cur_vol_trx'),\n",
    "            old_volume_nrx = pl.col('NUF_all')-pl.col('cur_vol_nrx')\n",
    "        )\n",
    "        .with_columns(\n",
    "            pl.when(pl.col('old_volume_trx') == 0)\n",
    "            .then(pl.lit('NP'))\n",
    "            .otherwise(pl.col('TYPE_trx'))\n",
    "            .alias('TYPE_trx'),\n",
    "\n",
    "            pl.when(pl.col('old_volume_nrx') == 0)\n",
    "            .then(pl.lit('NP'))\n",
    "            .otherwise(pl.col('TYPE_nrx'))\n",
    "            .alias('TYPE_nrx')\n",
    "        )\n",
    "        .with_columns(\n",
    "            pl.when(pl.col('vol_change_trx') == 0)\n",
    "            .then(pl.lit('NC'))\n",
    "            .otherwise(pl.col('TYPE_trx'))\n",
    "            .alias('TYPE_trx'),\n",
    "\n",
    "            pl.when(pl.col('vol_change_trx') == 0)\n",
    "            .then(pl.lit('NC'))\n",
    "            .otherwise(pl.col('TYPE_nrx'))\n",
    "            .alias('TYPE_nrx')\n",
    "        )\n",
    "        .with_columns(\n",
    "            pl.when(pl.col('PDRPOptOutFlag')=='Y')\n",
    "            .then(pl.lit('PDRP'))\n",
    "            .otherwise(pl.col('TYPE_trx'))\n",
    "            .alias('TYPE_trx'),\n",
    "\n",
    "            pl.when(pl.col('PDRPOptOutFlag')=='Y')\n",
    "            .then(pl.lit('PDRP'))\n",
    "            .otherwise(pl.col('TYPE_nrx'))\n",
    "            .alias('TYPE_nrx')\n",
    "        )\n",
    "        .drop(['old_volume_trx','old_volume_nrx','TUF_all','NUF_all','PDRPOptOutFlag'])\n",
    "    )\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "858fdbc4-ad0a-418e-ba7d-803b2687cc4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T10:03:11.988396Z",
     "iopub.status.busy": "2024-10-04T10:03:11.988132Z",
     "iopub.status.idle": "2024-10-04T10:03:11.997749Z",
     "shell.execute_reply": "2024-10-04T10:03:11.993445Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#volume change indicator\n",
    "def process_4(df):\n",
    "\n",
    "    expression_for_trx = pl.when(pl.col('pri_vol_trx')==0).then(pl.lit(None)\n",
    "    ).when(pl.col('vol_change_trx')/pl.col('pri_vol_trx') > 0.02).then(pl.lit('P')\n",
    "    ).when(pl.col('vol_change_trx')/pl.col('pri_vol_trx') < -0.02).then(pl.lit('Q')\n",
    "    ).when(pl.col('vol_change_trx')==0).then(None\n",
    "    ).otherwise(None).alias('vol_change_ind_trx')\n",
    "\n",
    "    expression_for_nrx = pl.when(pl.col('pri_vol_nrx')==0).then(pl.lit(None)\n",
    "    ).when(pl.col('vol_change_nrx')/pl.col('pri_vol_nrx') > 0.02).then(pl.lit('P')\n",
    "    ).when(pl.col('vol_change_nrx')/pl.col('pri_vol_nrx') < -0.02).then(pl.lit('Q')\n",
    "    ).when(pl.col('vol_change_nrx')==0).then(None\n",
    "    ).otherwise(None).alias('vol_change_ind_nrx')\n",
    "\n",
    "    return(df.with_columns(expression_for_trx,expression_for_nrx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0178167e-28eb-472a-8b63-480e3bdce3c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T10:03:12.011434Z",
     "iopub.status.busy": "2024-10-04T10:03:12.010522Z",
     "iopub.status.idle": "2024-10-04T10:03:12.020906Z",
     "shell.execute_reply": "2024-10-04T10:03:12.016757Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#current prior and share change\n",
    "def process_5(df):\n",
    "    df1 = df.filter(~pl.col('product_id').is_in([1,2,35])).group_by('IID').agg(\n",
    "        mkt_TUF_c = pl.col('cur_vol_trx').sum(),mkt_TUF_p = pl.col('pri_vol_trx').sum(),\n",
    "        mkt_NUF_c = pl.col('cur_vol_nrx').sum(),mkt_NUF_p = pl.col('pri_vol_nrx').sum()\n",
    "    )\n",
    "\n",
    "    return(\n",
    "    df.join(df1,on='IID',how='left').with_columns(\n",
    "        cur_shr_trx = pl.col('cur_vol_trx')/pl.col('mkt_TUF_c'),cur_shr_nrx = pl.col('cur_vol_nrx')/pl.col('mkt_NUF_c'),\n",
    "        pri_shr_trx = pl.col('pri_vol_trx')/pl.col('mkt_TUF_p'),pri_shr_nrx = pl.col('pri_vol_nrx')/pl.col('mkt_NUF_p')\n",
    "    ).with_columns(\n",
    "        shr_change_trx = pl.col('cur_shr_trx')-pl.col('pri_shr_trx'),shr_change_nrx = pl.col('cur_shr_nrx')-pl.col('pri_shr_nrx')\n",
    "    ).drop(['mkt_TUF_c','mkt_TUF_p','mkt_NUF_c','mkt_NUF_p'] # maybe consider not dropping it.\n",
    "    ) .with_columns(\n",
    "        prc_shr_growth_trx = (pl.col('cur_shr_trx')/pl.col('pri_shr_trx'))-1,\n",
    "        prc_shr_growth_nrx = (pl.col('cur_shr_nrx')/pl.col('pri_shr_nrx'))-1\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78edea54-e503-43db-8ee1-24371698dbb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T10:03:12.025295Z",
     "iopub.status.busy": "2024-10-04T10:03:12.024678Z",
     "iopub.status.idle": "2024-10-04T10:03:12.032563Z",
     "shell.execute_reply": "2024-10-04T10:03:12.031402Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#share change indicator\n",
    "def process_6(df):\n",
    "    return(\n",
    "        df.with_columns(\n",
    "            pl.when(pl.col('shr_change_trx') > 0.005).then(pl.lit('P'))\n",
    "            .when(pl.col('shr_change_trx') < -0.005).then(pl.lit('Q'))\n",
    "            .when(pl.col('shr_change_trx')==0).then(None)\n",
    "            .otherwise(None).alias('shr_change_ind_trx'),\n",
    "\n",
    "            pl.when(pl.col('shr_change_nrx') > 0.005).then(pl.lit('P'))\n",
    "            .when(pl.col('shr_change_nrx') < -0.005).then(pl.lit('Q'))\n",
    "            .when(pl.col('shr_change_nrx')==0).then(None)\n",
    "            .otherwise(None).alias('shr_change_ind_nrx')\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b591d9fd-0cf9-4aff-a161-18a8b313465d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T10:03:12.036700Z",
     "iopub.status.busy": "2024-10-04T10:03:12.035947Z",
     "iopub.status.idle": "2024-10-04T10:03:12.044348Z",
     "shell.execute_reply": "2024-10-04T10:03:12.043478Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Trx Size Metrics (copied values for nrx)\n",
    "def process_7(df):\n",
    "    cols = ['IID','product_id']\n",
    "    fetch_df = all_products_tun[cols+[f'TUN{period}c',f'TUN{period}p']].join(\n",
    "        all_products_trx[cols+[f'TRX{period}c',f'TRX{period}p']],on = cols,how = 'left'\n",
    "    )\n",
    "\n",
    "    df2 = df.join(fetch_df,on = ['IID','product_id'],how = 'left'\n",
    "    ).with_columns(\n",
    "        avg_trx_size = pl.col(f'TUN{period}c')/pl.col(f'TRX{period}c'),\n",
    "        pri_avg_trx_size = pl.col(f'TUN{period}p')/pl.col(f'TRX{period}p')\n",
    "    ).with_columns(\n",
    "        avg_trx_size_ch = (pl.col('avg_trx_size') - pl.col('pri_avg_trx_size')).round(2)\n",
    "    ).rename(\n",
    "        {f'TRX{period}c' : 'avg_trx_size_trx',f'TUN{period}c':'avg_trx_size_unit'}\n",
    "    ).with_columns(\n",
    "        avg_nrx_size = pl.col('avg_trx_size'),\n",
    "        avg_nrx_size_ch = pl.lit('\\\\N'), #not copying the raw data columns here nrx metric is not to be calc\n",
    "    ).drop([f'TUN{period}p',f'TRX{period}p','pri_avg_trx_size'])\n",
    "\n",
    "    return(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49adcfd1-31f1-4d78-8c75-f5de9d9d277b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T10:03:12.049494Z",
     "iopub.status.busy": "2024-10-04T10:03:12.048371Z",
     "iopub.status.idle": "2024-10-04T10:03:12.055905Z",
     "shell.execute_reply": "2024-10-04T10:03:12.055106Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#90 day trx perc (no values for nrx)\n",
    "# trx_90day_pct   =  ((tuf_rx_&ce. - ((tuf_units_&ce. - 90*tuf_rx_&ce.) / -60)) / tuf_rx_&ce.)\n",
    "#simplyfy z = (x-((y-90x)/-60))/x, where x = cur_vol, y = cur_tun\n",
    "# you get z = -(1/2) + (y/60x)\n",
    "def process_8(df):\n",
    "    cols = ['IID','product_id']\n",
    "    fetch_df = all_products_tun[cols+[f'TUN{period}c']].rename({f'TUN{period}c':'tuf_units'})\n",
    "\n",
    "    formula = -(1/2) + (pl.col('tuf_units')/(60*pl.col('cur_vol_trx')))\n",
    "\n",
    "    df2 = df.join(fetch_df,on=cols,how='left').with_columns(\n",
    "        trx_90day_pct = formula,\n",
    "        trx_90day_pct_nrx = None\n",
    "    ).drop('tuf_units')\n",
    "\n",
    "    return(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c460ea5b-ac2a-4b79-ae50-dd96eb11837a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T10:03:12.061302Z",
     "iopub.status.busy": "2024-10-04T10:03:12.060765Z",
     "iopub.status.idle": "2024-10-04T10:03:12.066944Z",
     "shell.execute_reply": "2024-10-04T10:03:12.066046Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# For Bench Mark Columns -\n",
    "def get_benchmark_cols(df,metric,b_metric,b_name):\n",
    "    df = (\n",
    "        df\n",
    "        .join(\n",
    "            mp_spec_seg_dec.drop('geography_id',d),on='IID',how='left'\n",
    "        )\n",
    "        .join(\n",
    "            terr_growths.select('geography_id',p,spc,sg,b_metric),\n",
    "            on = ['geography_id',spc,sg,p], how = 'left'\n",
    "        )\n",
    "        .rename(\n",
    "            {\n",
    "                f'{b_metric}_right':f'Prc_Benchmark_{b_name}_{metric}'\n",
    "            }\n",
    "        )\n",
    "        .with_columns(\n",
    "            pl.when(pl.col(b_metric)>pl.col(f'Prc_Benchmark_{b_name}_{metric}'))\n",
    "            .then(pl.lit('L'))\n",
    "            .otherwise(pl.lit(None))\n",
    "            .alias(f'{b_name}_Ind_{metric}')\n",
    "        )\n",
    "        .drop(spc,sg)\n",
    "    )\n",
    "\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dbdfd45a-7e5d-499c-8a6c-716599e3f698",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T10:03:12.071220Z",
     "iopub.status.busy": "2024-10-04T10:03:12.070897Z",
     "iopub.status.idle": "2024-10-04T10:03:12.089189Z",
     "shell.execute_reply": "2024-10-04T10:03:12.088122Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# For converting to Feed Ready Data -\n",
    "def get_feed(temp1):\n",
    "    final_feed = temp1.with_columns(\n",
    "        pl.col('avg_trx_size_trx').alias('avg_trx_size_trx_nrx')\n",
    "    ).with_columns(\n",
    "        pl.col('avg_trx_size_unit').alias('avg_trx_size_unit_nrx')\n",
    "    )\n",
    "    #function to diving dataframe in two levels('Trx','Nrx')\n",
    "    def select_columns_by_condition(df,metric):\n",
    "        # Get the column names to be excluded based on the condition\n",
    "        excluded_columns = [col for col in df.columns if not col.endswith(metric)]\n",
    "        \n",
    "        # Select all columns except the excluded ones\n",
    "        selected_df = df.select(excluded_columns)\n",
    "        return selected_df\n",
    "    #working on trx level\n",
    "    final_feed_trx = select_columns_by_condition(final_feed,'nrx')\n",
    "    final_feed_trx = final_feed_trx.drop(['avg_nrx_size','avg_nrx_size_ch'])\n",
    "    final_feed_trx = final_feed_trx.with_columns(\n",
    "        pl.lit('TRX').alias('Metric')\n",
    "    )\n",
    "    #working on nrx level\n",
    "    final_feed_nrx = select_columns_by_condition(final_feed,'trx')\n",
    "    final_feed_nrx = final_feed_nrx.drop(['avg_trx_size','avg_trx_size_trx','avg_trx_size_ch','trx_90day_pct','avg_trx_size_unit'])\n",
    "    final_feed_nrx = final_feed_nrx.with_columns(\n",
    "        pl.lit('NRX').alias('Metric')\n",
    "    )\n",
    "\n",
    "    #Filter to reduce nobs :\n",
    "    final_feed_trx = final_feed_trx.filter(\n",
    "        (pl.col('cur_vol_trx')!=0) | (pl.col('pri_vol_trx')!=0)\n",
    "    )\n",
    "    final_feed_nrx = final_feed_nrx.filter(\n",
    "        (pl.col('cur_vol_nrx')!=0) | (pl.col('pri_vol_nrx')!=0)\n",
    "    )\n",
    "\n",
    "    \n",
    "    #function to remove _trx or _nrx from final_feed_nrx and final_feed_trx\n",
    "    def rename_columns_by_condition(df,metric):\n",
    "        renamed_columns = {col: col[:-4] if col.endswith(metric) and col != 'avg_trx_size_trx' else col for col in df.columns}\n",
    "        renamed_df = df.rename(renamed_columns)\n",
    "        return renamed_df\n",
    "    # making trx feed columns and nrx feed columns similar so that we can vstack them\n",
    "    final_feed_nrx = rename_columns_by_condition(final_feed_nrx,'nrx')\n",
    "    final_feed_nrx = final_feed_nrx.rename({\n",
    "        'avg_nrx_size':'avg_trx_size',\n",
    "        'avg_nrx_size_ch':'avg_trx_size_ch'\n",
    "    })\n",
    "    final_feed_nrx = final_feed_nrx.with_columns(\n",
    "        pl.lit('\\\\N').alias('trx_90day_pct')\n",
    "    )\n",
    "    \n",
    "    final_feed_nrx = final_feed_nrx.select(['IID',\n",
    "     'geography_id',\n",
    "     'product_id',\n",
    "     'cur_vol',\n",
    "     'pri_vol',\n",
    "     'vol_change',\n",
    "     'prc_vol_growth',\n",
    "     'TYPE',\n",
    "     'vol_change_ind',\n",
    "     'cur_shr',\n",
    "     'pri_shr',\n",
    "     'shr_change',\n",
    "     'prc_shr_growth',\n",
    "     'shr_change_ind',\n",
    "     # 'product_id_right',\n",
    "     'avg_trx_size_unit',\n",
    "     'avg_trx_size_trx',\n",
    "     'avg_trx_size',\n",
    "     'avg_trx_size_ch',\n",
    "     'trx_90day_pct',\n",
    "     'Prc_Benchmark_Vol_Growth',\n",
    "     'Vol_Growth_Ind',\n",
    "     'Prc_Benchmark_Shr_Growth',\n",
    "     'Shr_Growth_Ind',\n",
    "     'Metric'])\n",
    "    #making final_feed_trx ready for vstack with final_feed_nrx \n",
    "    final_feed_trx = rename_columns_by_condition(final_feed_trx,'trx')\n",
    "    final_feed_trx = final_feed_trx.with_columns(\n",
    "        pl.col(\"avg_trx_size_ch\").cast(pl.String)\n",
    "        ).with_columns(\n",
    "            pl.col('trx_90day_pct').cast(pl.String)\n",
    "        )\n",
    "    final_feed = final_feed_trx.vstack(final_feed_nrx)\n",
    "    #removing extra columns a\\c to feed\n",
    "    #final_feed = final_feed.drop(['product_id_right'])\n",
    "    #Renaming existing columns according to feed\n",
    "    rnm_cols = {\n",
    "        'IID':'Physician_ID',\n",
    "        'geography_id':'Geography_id',\n",
    "        'product_id':'Product_id',\n",
    "        'cur_vol':'Current_Vol',\n",
    "        'pri_vol':'Prior_Vol',\n",
    "        'vol_change':'Vol_Change',\n",
    "        'prc_vol_growth':'Prc_Vol_Growth',\n",
    "        'TYPE':'Type',\n",
    "        'vol_change_ind':'Vol_Change_Ind',\n",
    "        'cur_shr':'Current_Shr',\n",
    "        'pri_shr':'Prior_Shr',\n",
    "        'shr_change':'Shr_Change',\n",
    "        'prc_shr_growth':'Prc_Shr_Growth',\n",
    "        'shr_change_ind':'Shr_Change_Ind',\n",
    "        'avg_trx_size_unit':'Avg_TRx_Size_Unit',\n",
    "        'avg_trx_size_trx':'Avg_TRx_Size_TRx',\n",
    "        'avg_trx_size':'Avg_TRx_Size',\n",
    "        'avg_trx_size_ch':'Avg_TRx_Size_Change',\n",
    "        'trx_90day_pct':'Ninty_Day_TRx_Prc',\n",
    "    }\n",
    "    final_feed = final_feed.rename(rnm_cols)\n",
    "    #required new columns for feed\n",
    "    col_to_addrt = ['ReportType']\n",
    "    col_to_addna = [\"Total_Num_Of_Redemptions\", \"Frozen_Competitor_Vol\", \"DS1_Current_Vol\", \"DS1_Prior_Vol\", \"DS2_Current_Vol\", \"DS2_Prior_Vol\"]\n",
    "    # func to add columns with desired value\n",
    "    def addcol(df,columns_to_add,wtl):\n",
    "        for my_col in columns_to_add:\n",
    "            df = df.with_columns(pl.lit(wtl).alias(my_col))\n",
    "        return df\n",
    "    final_feed = addcol(final_feed,col_to_addrt,'MONTHLY')\n",
    "    final_feed = final_feed.with_columns(pl.lit(f'{pld[PN]}').alias('Period'))\n",
    "    final_feed = addcol(final_feed,col_to_addna,'\\\\N')\n",
    "    # rearranging columns accoring to feed.\n",
    "    req_cols = [\n",
    "    \"Physician_ID\", \"Geography_id\", \"Product_id\", \"Metric\", \"ReportType\", \"Period\", \"Type\", \"Current_Vol\", \"Prior_Vol\", \"Vol_Change\", \n",
    "    \"Vol_Change_Ind\", \"Prc_Vol_Growth\", \"Prc_Benchmark_Vol_Growth\", \"Vol_Growth_Ind\", \"Current_Shr\", \"Prior_Shr\", \"Shr_Change\", \n",
    "    \"Shr_Change_Ind\", \"Prc_Shr_Growth\", \"Prc_Benchmark_Shr_Growth\", \"Shr_Growth_Ind\", \"Avg_TRx_Size\", \"Avg_TRx_Size_TRx\", \n",
    "    \"Avg_TRx_Size_Unit\", \"Total_Num_Of_Redemptions\", \"Frozen_Competitor_Vol\", \"DS1_Current_Vol\", \"DS1_Prior_Vol\", \"DS2_Current_Vol\", \n",
    "    \"DS2_Prior_Vol\", \"Avg_TRx_Size_Change\", \"Ninty_Day_TRx_Prc\"]\n",
    "    final_feed = final_feed.select(req_cols)# final data set\n",
    "    \n",
    "     #----------------------------------------------------------#\n",
    "    \n",
    "    columns_to_round1 = ['Vol_Change'] #, 'Avg_TRx_Size_Change'\n",
    "    columns_to_round2 = ['Avg_TRx_Size_Unit']\n",
    "    columns_to_round3 = ['Current_Vol', 'Prior_Vol', 'Prc_Vol_Growth', 'Prc_Benchmark_Vol_Growth', 'Prc_Shr_Growth', \n",
    "                          'Prc_Benchmark_Shr_Growth', 'Avg_TRx_Size', 'Avg_TRx_Size_TRx']\n",
    "    columns_to_round4 = ['Current_Shr', 'Prior_Shr', 'Shr_Change']\n",
    "    #columns_to_round10 = ['Ninty_Day_TRx_Prc']\n",
    "    \n",
    "    final_feed = final_feed.with_columns([\n",
    "        *[pl.col(col).round(1).alias(col) for col in columns_to_round1],\n",
    "        *[pl.col(col).round(2).alias(col) for col in columns_to_round2],\n",
    "        *[pl.col(col).round(3).alias(col) for col in columns_to_round3],\n",
    "        *[pl.col(col).round(4).alias(col) for col in columns_to_round4]\n",
    "    ])\n",
    "\n",
    "    #Type Flag Correction ->\n",
    "    final_feed = (\n",
    "        final_feed.with_columns(pl.when(pl.col('Type').is_null()).then(pl.lit('N')).otherwise(pl.col('Type')).alias('Type'))\n",
    "    )\n",
    "    #misc overrides -\n",
    "    final_feed = final_feed.with_columns(\n",
    "        pl.col('Ninty_Day_TRx_Prc').replace('\\\\N', '0.0'),\n",
    "        pl.col('Avg_TRx_Size_Change').replace(['\\\\N','NaN'], ['0.0','0.0'])\n",
    "    )\n",
    "\n",
    "    # PDRP OVER RIDE - \n",
    "    for col in final_feed.columns[7:]:\n",
    "        final_feed = final_feed.with_columns(\n",
    "            pl.when(pl.col(\"Type\") == \"PDRP\").then(pl.lit('\\\\N')).otherwise(pl.col(col)).alias(col)\n",
    "        )\n",
    "\n",
    "    \n",
    "    return (final_feed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b079f23-4901-46b2-a909-d97f56181c84",
   "metadata": {},
   "source": [
    "Period Loop -\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3ea2e5b-6629-4034-a822-be0cd475143b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T10:03:12.092310Z",
     "iopub.status.busy": "2024-10-04T10:03:12.091793Z",
     "iopub.status.idle": "2024-10-04T10:03:12.096341Z",
     "shell.execute_reply": "2024-10-04T10:03:12.095297Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# for trvializing formula : \n",
    "p,sg,spc,d = 'product_id','segment','specialty_group','decile'\n",
    "levels = ['geography_id','region_geography_id','area_geography_id','nation_geography_id']\n",
    "pld = {1:'1-MONTH',2:'3-MONTHS',3:'6-MONTHS',4:'12-MONTHS',6:'PQTD',7:'YTD'}\n",
    "OUT = 's3://vortex-staging-a65ced90/BIT/output/Prescriber/Monthly/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6496941-fca0-4e1e-881c-5bf6587f28ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T10:03:12.099421Z",
     "iopub.status.busy": "2024-10-04T10:03:12.098959Z",
     "iopub.status.idle": "2024-10-04T10:06:46.735117Z",
     "shell.execute_reply": "2024-10-04T10:06:46.734052Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported Feed 1!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported Feed 2!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported Feed 3!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported Feed 4!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported Feed 6!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported Feed 7!\n"
     ]
    }
   ],
   "source": [
    "for period_num,PN in zip([1,3,6,12,'pqtr','ytd'],[1,2,3,4,6,7]):\n",
    "    period = f'_{period_num}'\n",
    "    temp1 = mp_spec_seg_dec.select(['IID','geography_id'])\n",
    "    temp1 = process_1(temp1)\n",
    "    temp1 = process_2(temp1)\n",
    "    temp1 = process_3(temp1)\n",
    "    temp1 = process_4(temp1)\n",
    "    temp1 = process_5(temp1)\n",
    "    temp1 = process_6(temp1)\n",
    "    temp1 = process_7(temp1)\n",
    "    temp1 = process_8(temp1)\n",
    "    load(f'terr_growths_{PN}-m')\n",
    "    terr_growths = globals()[f'terr_growths_{PN}-m']\n",
    "    temp1 = get_benchmark_cols(temp1,'trx','prc_vol_growth_trx','Vol_Growth')\n",
    "    temp1 = get_benchmark_cols(temp1,'nrx','prc_vol_growth_nrx','Vol_Growth')\n",
    "    temp1 = get_benchmark_cols(temp1,'trx','prc_shr_growth_trx','Shr_Growth')\n",
    "    temp1 = get_benchmark_cols(temp1,'nrx','prc_shr_growth_nrx','Shr_Growth')\n",
    "\n",
    "    feed_dataset = get_feed(temp1)\n",
    "    # New Fixes - \n",
    "    for c in ['Vol_Change_Ind','Vol_Growth_Ind','Shr_Change_Ind','Shr_Growth_Ind']: #convert null to slash n\n",
    "        feed_dataset = feed_dataset.with_columns(pl.col(c).replace(None,'\\\\N'))\n",
    "    \n",
    "    for c in ['Prc_Benchmark_Vol_Growth','Prc_Benchmark_Shr_Growth'] : # convert null  to 0\n",
    "        feed_dataset = feed_dataset.with_columns(pl.col(c).replace(None,'0.0'))\n",
    "    \n",
    "    for c in ['Current_Shr','Prior_Shr','Shr_Change','Prc_Shr_Growth','Avg_TRx_Size','Ninty_Day_TRx_Prc'] :# Convert NaN to 0\n",
    "        feed_dataset = feed_dataset.with_columns(pl.col(c).replace('NaN','0.0'))\n",
    "    \n",
    "    for c in ['Prc_Vol_Growth','Prc_Benchmark_Vol_Growth','Prc_Shr_Growth','Prc_Benchmark_Shr_Growth','Ninty_Day_TRx_Prc'] :# Convert inf to 0\n",
    "        feed_dataset = feed_dataset.with_columns(pl.col(c).replace('inf','0.0'))\n",
    "        \n",
    "    \n",
    "     #===================================================\n",
    "    feed_dataset = feed_dataset.to_pandas()\n",
    "    # # Select columns of type 'object' (string)\n",
    "    # string_columns = feed_dataset.select_dtypes(include=['object']).columns.tolist()\n",
    "    \n",
    "    # feed_dataset[string_columns] = feed_dataset[string_columns].fillna('\\\\N')\n",
    "    # feed_dataset = feed_dataset.replace('NaN', '\\\\N')\n",
    "\n",
    "    # feed_dataset = feed_dataset.replace([np.nan, np.inf, -np.inf], '\\\\N')\n",
    "    \n",
    "    feed_dataset.to_csv(f'{OUT}Monthly_Prescriber_SalesPerformance_P{PN}_Feed.txt', sep='|',lineterminator='\\r\\n',index=False)\n",
    "    print(f'Exported Feed {PN}!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278f8e19-8012-4b71-99e1-91ca926572a5",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
