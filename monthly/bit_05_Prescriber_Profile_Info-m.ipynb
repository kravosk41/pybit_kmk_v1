{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3af2a416-034e-4c54-8192-4d7438076d28",
   "metadata": {},
   "source": [
    "# Prescriber View- profile info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85c29d89-624f-4586-9a7d-9a645a8d3e26",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "import gc\n",
    "import json\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta,date\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c258bff1-4597-459a-a68e-60a65459df36",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# load variables from JSON\n",
    "with open('vars_wk.json', 'r') as json_file:\n",
    "    js = json.load(json_file)\n",
    "\n",
    "data_date = js['data_date']\n",
    "num_weeks_rx = js['num_weeks_rx']\n",
    "num_weeks_calls = js['num_weeks_calls']\n",
    "IBSC_ptype_file = js['IBSC_ptype_file']\n",
    "quarter_start = datetime.strptime(js['quarter_start'], '%Y-%m-%d').date()\n",
    "qtr_data = js['qtr_data']\n",
    "bucket = js['bucket']\n",
    "YTD = js['YTD']\n",
    "monthly_data_date = js['monthly_data_date']\n",
    "\n",
    "dflib = f's3://{bucket}/BIT/dataframes/'\n",
    "xpn = f's3://{bucket}/PYADM/weekly/archive/{data_date}/xponent/'\n",
    "lincall = f's3://{bucket}/PYADM/quaterly/{qtr_data}/target/post/'\n",
    "mxpn = f's3://{bucket}/PYADM/monthly/archive/{monthly_data_date}/xponent/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d81adc76-0f53-4473-b139-61b989cba7c4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Utility Functions -\n",
    "def load(df, lib=dflib):\n",
    "    globals()[df] = pl.read_parquet(f'{lib}{df}.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea090eb1-56d1-4825-9d6a-8a18159d423f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Imporing Dependencies\n",
    "prod_mapping = pl.read_csv(f's3://{bucket}/BIT/docs/productmapping_pybit.txt',separator='|')\n",
    "geo_code_mapper = pl.from_pandas(pd.read_excel(f's3://{bucket}/BIT/docs/geo_id_full.xlsx'))\n",
    "ibsc_ptype = pl.from_pandas(pd.read_excel(f's3://{bucket}/BIT/docs/{IBSC_ptype_file}.xlsx'))\n",
    "load('mp_spec_seg_dec')\n",
    "load('MASTER_UNI')\n",
    "load('temp_calls')\n",
    "load('lirwd_call_plan')\n",
    "load('roster')\n",
    "fetch_products = ['LI1','LI2','LI3','TRU','AMT','LAC','MOT','LUB','IRL']\n",
    "geo_id_full = pl.from_pandas(pd.read_excel(f's3://{bucket}/BIT/docs/geo_id_full.xlsx'))\n",
    "\n",
    "#fixes for vortex import -> Probably caused by Polars Upgrades\n",
    "temp_calls = temp_calls.with_columns(pl.col('SalesRepIID').cast(pl.Int64))\n",
    "temp_calls_mp_spec = (\n",
    "    temp_calls\n",
    "    .join(mp_spec_seg_dec,left_on = 'AttendeeIID',right_on = 'IID', how = 'left').filter(pl.col('geography_id').is_not_null())\n",
    "    .join(geo_id_full,on = 'geography_id',how = 'left')\n",
    "    .join(lirwd_call_plan,left_on = 'AttendeeIID', right_on = 'IID', how = 'left')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13e82be-cd3e-4135-a2ac-f56fec373948",
   "metadata": {},
   "source": [
    "Generator Functions\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "551256d0-078a-4533-ac75-1aa5f3e0529b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# For Voucher Removal - \n",
    "def get_lin_voucher():\n",
    "    vch = pl.read_parquet(f'{mxpn}LIN_VOUCHER.parquet') \n",
    "    vch1 = pl.DataFrame()\n",
    "    for prod in ['LIN1','LIN2','LIN3']: # LINV\n",
    "        vch_prod = (\n",
    "            vch.select(\n",
    "                pl.col('IID'),\n",
    "                pl.col(f'{prod}TUF1').alias(f'vTUF_1c'),\n",
    "                pl.sum_horizontal([f'{prod}TUF{i}' for i in range(1,4)]).alias(f'vTUF_3c'),\n",
    "                pl.sum_horizontal([f'{prod}TUF{i}' for i in range(1,7)]).alias(f'vTUF_6c'),\n",
    "                pl.sum_horizontal([f'{prod}TUF{i}' for i in range(1,13)]).alias(f'vTUF_12c'),\n",
    "                pl.sum_horizontal([f'{prod}TUF{i}' for i in range(4,7)]).alias(f'vTUF_pqtrc'),\n",
    "                pl.sum_horizontal([f'{prod}TUF{i}' for i in range(1,YTD+1)]).alias(f'vTUF_ytdc'),\n",
    "                pl.col(f'{prod}TUF2').alias(f'vTUF_1p'),\n",
    "                pl.sum_horizontal([f'{prod}TUF{i}' for i in range(4,7)]).alias(f'vTUF_3p'),\n",
    "                pl.sum_horizontal([f'{prod}TUF{i}' for i in range(7,13)]).alias(f'vTUF_6p'),\n",
    "                pl.sum_horizontal([f'{prod}TUF{i}' for i in range(13,25)]).alias(f'vTUF_12p'),\n",
    "                pl.sum_horizontal([f'{prod}TUF{i}' for i in range(7,10)]).alias(f'vTUF_pqtrp'),\n",
    "                pl.sum_horizontal([f'{prod}TUF{i}' for i in range(13,13+YTD)]).alias(f'vTUF_ytdp'),\n",
    "                pl.sum_horizontal([f'{prod}TUF{i}' for i in range(1,25)]).alias(f'vTUF_all') #added 105 week datacut\n",
    "            )\n",
    "            .with_columns(pl.lit(f'LI{prod[-1]}').alias('PROD_CD'))\n",
    "        )\n",
    "        if prod[-1] == '1':\n",
    "            vch1 = vch_prod.clone()\n",
    "        else:\n",
    "            vch1 = pl.concat([vch1, vch_prod])\n",
    "\n",
    "    # voucher_mapping = {'LI1': 4, 'LI2': 5, 'LI3': 3, 'LIV': 2}\n",
    "    vch1 = vch1.fill_null(0)\n",
    "    return(vch1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e054578-458e-4e80-916e-42b2304fbcd6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_summed_period_iid_metric(metric,prod_cd):\n",
    "    columns = ['IID','PROD_CD'] + [metric+str(i) for i in range(1,25)]\n",
    "    df = pl.read_parquet(mxpn+'LAX.parquet',columns=columns).filter(pl.col('PROD_CD').is_in(prod_cd))\n",
    "\n",
    "    # 1,3,6,12,pqtd,ytd for current and prior period for a given Metric\n",
    "    df = df.select(\n",
    "        pl.col('IID'),pl.col('PROD_CD'),\n",
    "        pl.col(metric+'1').alias(metric+'_1c'),\n",
    "        pl.sum_horizontal([metric+str(i) for i in range(1,4)]).alias(metric+'_3c'),\n",
    "        pl.sum_horizontal([metric+str(i) for i in range(1,7)]).alias(metric+'_6c'),\n",
    "        pl.sum_horizontal([metric+str(i) for i in range(1,13)]).alias(metric+'_12c'),\n",
    "        pl.sum_horizontal([metric+str(i) for i in range(4,7)]).alias(metric+'_pqtrc'),\n",
    "        pl.sum_horizontal([metric+str(i) for i in range(1,YTD+1)]).alias(metric+'_ytdc'),\n",
    "\n",
    "        pl.col(metric+'2').alias(metric+'_1p'),\n",
    "        pl.sum_horizontal([metric+str(i) for i in range(4,7)]).alias(metric+'_3p'),\n",
    "        pl.sum_horizontal([metric+str(i) for i in range(7,13)]).alias(metric+'_6p'),\n",
    "        pl.sum_horizontal([metric+str(i) for i in range(13,25)]).alias(metric+'_12p'),\n",
    "        pl.sum_horizontal([metric+str(i) for i in range(7,10)]).alias(metric+'_pqtrp'),\n",
    "        pl.sum_horizontal([metric+str(i) for i in range(13,13+YTD)]).alias(metric+'_ytdp'),\n",
    "\n",
    "        pl.sum_horizontal([metric+str(i) for i in range(1,25)]).alias(metric+'_all')\n",
    "    )\n",
    "\n",
    "    # For Voucher Removal - \n",
    "    if metric == 'TUF':\n",
    "        dfv = get_lin_voucher()\n",
    "        df = df.join(dfv,on=['IID','PROD_CD'],how='left').fill_null(0)\n",
    "        cols_to_remove = dfv.columns[1:-1]\n",
    "        df = df.with_columns(\n",
    "            pl.col(f'{metric}_1c') -  pl.col(f'v{metric}_1c').alias(f'{metric}_1c'),\n",
    "            pl.col(f'{metric}_3c') -  pl.col(f'v{metric}_3c').alias(f'{metric}_3c'),\n",
    "            pl.col(f'{metric}_6c') -  pl.col(f'v{metric}_6c').alias(f'{metric}_6c'),\n",
    "            pl.col(f'{metric}_12c') -  pl.col(f'v{metric}_12c').alias(f'{metric}_12c'),\n",
    "            pl.col(f'{metric}_pqtrc') -  pl.col(f'v{metric}_pqtrc').alias(f'{metric}_pqtrc'),\n",
    "            pl.col(f'{metric}_ytdc') -  pl.col(f'v{metric}_ytdc').alias(f'{metric}_ytdc'),\n",
    "            pl.col(f'{metric}_1p') -  pl.col(f'v{metric}_1p').alias(f'{metric}_1p'),\n",
    "            pl.col(f'{metric}_3p') -  pl.col(f'v{metric}_3p').alias(f'{metric}_3p'),\n",
    "            pl.col(f'{metric}_6p') -  pl.col(f'v{metric}_6p').alias(f'{metric}_6p'),\n",
    "            pl.col(f'{metric}_12p') -  pl.col(f'v{metric}_12p').alias(f'{metric}_12p'),\n",
    "            pl.col(f'{metric}_pqtrp') -  pl.col(f'v{metric}_pqtrp').alias(f'{metric}_pqtrp'),\n",
    "            pl.col(f'{metric}_ytdp') -  pl.col(f'v{metric}_ytdp').alias(f'{metric}_ytdp'),\n",
    "            pl.col(f'{metric}_all') -  pl.col(f'v{metric}_all').alias(f'{metric}_all')\n",
    "        ).drop(cols_to_remove)\n",
    "\n",
    "    # Adding MP related columns\n",
    "    df = df.join(mp_spec_seg_dec,on='IID',how='left').filter(pl.col('geography_id').is_not_null())\n",
    "\n",
    "    return(df.drop(['specialty_group','segment','decile','geography_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "953bc736-86e1-4dbf-84c4-41b473611579",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def add_parent_product_rows_iid(df):\n",
    "    agg_dict = {}\n",
    "    for col in df.columns[2:]:\n",
    "        agg_dict[col] = pl.col(col).sum()\n",
    "    \n",
    "    #join_cols = ['geography_id','plan_type','PlanID','IID']\n",
    "\n",
    "    df = df.join(prod_mapping[['code','product_id','parent_product_id']], left_on = 'PROD_CD',right_on = 'code', how = 'left')\n",
    "    df_2_35 = df.filter(pl.col('parent_product_id').is_in([2,35]))\n",
    "    df_2_35 = df_2_35.group_by(['IID','parent_product_id']).agg(**agg_dict).rename({'parent_product_id':'product_id'})\n",
    "    \n",
    "    df_1 = df.group_by('IID').agg(**agg_dict).with_columns(product_id = pl.lit(1)).with_columns(pl.col('product_id').cast(pl.Int64))\n",
    "\n",
    "    # stack 1, 2_35 with df and return\n",
    "    df = df.drop(['PROD_CD','parent_product_id']) #dropping to make same shape\n",
    "    vstack_helper = df.columns\n",
    "    df = df.vstack(\n",
    "        df_2_35.select(vstack_helper)\n",
    "    ).vstack(\n",
    "        df_1.select(vstack_helper)\n",
    "    )\n",
    "\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20404f03-adec-4919-82e7-54ec60afe083",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "all_products_tuf = get_summed_period_iid_metric('TUF',fetch_products)\n",
    "all_products_nuf = get_summed_period_iid_metric('NUF',fetch_products)\n",
    "all_products_tuf = add_parent_product_rows(all_products_tuf)\n",
    "all_products_nuf = add_parent_product_rows(all_products_nuf)\n",
    "\n",
    "tuf1 = all_products_tuf.filter(pl.col('TUF_12c')!=0).select(['IID','product_id'])\n",
    "nuf1 = all_products_nuf.filter(pl.col('NUF_12c')!=0).select(['IID','product_id'])\n",
    "xponent = tuf1.join(nuf1,on=['IID','product_id'],how='outer_coalesce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22acb544-1126-4d07-a0cd-0c51b3823134",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "calls = (\n",
    "    temp_calls_mp_spec\n",
    "    .filter((pl.col('call_week')<=num_weeks_calls))\n",
    "    .filter(pl.col('CallDate')>= quarter_start)\n",
    "    .join(MASTER_UNI.select(['IID','Territory']),left_on = 'AttendeeIID', right_on = 'IID')\n",
    "    .join(roster, on = 'SalesRepIID' , how = 'left')\n",
    "    .filter(pl.col('Territory')==pl.col('GEO'))\n",
    "    .rename({'AttendeeIID':'IID'})\n",
    "    .select('IID').unique('IID')\n",
    "    .with_columns(product_id = pl.lit(2)).with_columns(pl.col('product_id').cast(pl.Int64))\n",
    ")\n",
    "\n",
    "xponent_calls = xponent.join(calls,on=['IID','product_id'],how='outer_coalesce')\n",
    "\n",
    "#delete extra dfs when optimizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71f0822a-8eef-4d8d-b30f-4ffb31a54ff8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Manual Addition for Call Plan HCPs \n",
    "peds = pl.DataFrame(mp_spec_seg_dec.filter(pl.col('specialty_group')=='PED')['IID'])\n",
    "callplan_peds = lirwd_call_plan[['IID']].vstack(peds)\n",
    "\n",
    "callplan_peds = (\n",
    "    callplan_peds.with_columns(pl.lit(1).alias('product_id'))\n",
    "    .vstack(\n",
    "        callplan_peds.with_columns(pl.lit(2).alias('product_id'))\n",
    "    )\n",
    "    .with_columns(pl.col('product_id').cast(pl.Int64))\n",
    ")\n",
    "\n",
    "#Merging back with xponent_calls \n",
    "xponent_calls = xponent_calls.vstack(callplan_peds).unique(['IID','product_id'])\n",
    "# Note : Xponent_calls is the main filtering dataset. Any IIDs not present in it , will get dropped out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d917e73-6b46-4699-a444-19fca7927d7f",
   "metadata": {},
   "source": [
    "Processing Data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98d1d74e-08c3-40e0-9c44-e100842b559a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Getting Utility Columns from main MP\n",
    "temp1 = MASTER_UNI.select(\n",
    "    [\n",
    "        'IID','FirstName','LastName','CREDENTIAL','PDRPOptOutFlag','DECILE',\n",
    "        'AddressLine1','AddressLine2','AddressLine3','AddressLine4','CityName','StateCode','ZIP',\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92fafb70-7dfe-4b1b-ba62-098eb0ba6b19",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Cleaning and Formatting Prec Info | Applying Flags etc\n",
    "temp1 = MASTER_UNI.select(\n",
    "    [\n",
    "        'IID','FirstName','LastName','CREDENTIAL','PDRPOptOutFlag','DECILE',\n",
    "        'AddressLine1','AddressLine2','AddressLine3','AddressLine4','CityName','StateCode','ZIP',\n",
    "    ]\n",
    ").with_columns(\n",
    "    pl.concat_str([pl.col('AddressLine1'),pl.col('AddressLine2'),pl.col('AddressLine3'),pl.col('AddressLine4')],separator=' ',ignore_nulls=True).alias('Address'),\n",
    "    pl.concat_str([pl.col('LastName'),pl.col('FirstName')],separator=', ',ignore_nulls=True).alias('Physician_Name'),\n",
    "    pl.when(pl.col('PDRPOptOutFlag')=='Y').then(1).otherwise(0).alias('PDRPOptOutFlag')\n",
    ").join(\n",
    "    mp_spec_seg_dec,on='IID',how='left'\n",
    ").join(\n",
    "    ibsc_ptype,on='IID',how='left'\n",
    ").drop(['AddressLine1','AddressLine2','AddressLine3','AddressLine4','FirstName','LastName','decile'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204954bf-f478-4ade-9fe5-bf26b9ee750f",
   "metadata": {},
   "source": [
    "Adding Product Id\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3c555bd-7596-45b1-86b8-1de2793fbdbe",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#calls and Rx-\n",
    "temp1 = temp1.join(xponent_calls,on='IID',how='left').unique(['IID','product_id'])\n",
    "\n",
    "#Target\n",
    "temp1 = temp1.with_columns(\n",
    "    pl.when((pl.col('segment')=='Target')&(pl.col('product_id').is_null()))\n",
    "    .then(pl.lit(2)).otherwise(pl.col('product_id')).alias('product_id')\n",
    ")\n",
    "\n",
    "#PED\n",
    "temp1 = temp1.with_columns(\n",
    "    pl.when((pl.col('specialty_group')=='PED')&(pl.col('product_id').is_null()))\n",
    "    .then(pl.lit(1)).otherwise(pl.col('product_id')).alias('product_id')\n",
    ")\n",
    "\n",
    "#Dropping nulls:\n",
    "temp1 = temp1.filter(pl.col('product_id').is_not_null())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1029630-7673-4b6a-949d-ca3fe9bc920a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# For Converting to Feed ready data\n",
    "def get_feed(temp1):\n",
    "    final_feed = temp1\n",
    "    #adding extra columns according to feed.\n",
    "    #required new columns for feed\n",
    "    col_to_addrt = ['ReportType']\n",
    "    col_to_addna = ['Urgent_Care_HCP','IMS_HCE_ID','NPI_ID','IC_Geography','AOSegment']\n",
    "    for my_col in col_to_addna:\n",
    "            final_feed = final_feed.with_columns(pl.lit('\\\\N').alias(my_col))\n",
    "      \n",
    "    final_feed = final_feed.with_columns(pl.lit('MONTHLY').alias('ReportType'))\n",
    "    #Renaming columns\n",
    "    new_col_mapping = {\n",
    "        'IID':'Physician_ID',\n",
    "        'product_id':'Product_id',\n",
    "        'segment': 'Segment',\n",
    "        'specialty_group': 'Specialty',\n",
    "        'CREDENTIAL':'Credential',\n",
    "        'PDRPOptOutFlag':'IsPDRP',\n",
    "        'DECILE':'Decile',\n",
    "        'CityName':'City',\n",
    "        'StateCode':'State',\n",
    "        'ZIP':'Zip',\n",
    "        'geography_id':'Geography_id',\n",
    "        'IBSC_VALUE':'IBSCPrimaryPayerType',\n",
    "    }\n",
    "    final_feed = final_feed.rename(new_col_mapping)\n",
    "    # changing value of column to match with sas - 06/21\n",
    "    final_feed = final_feed.with_columns(\n",
    "        pl.when(pl.col('Segment')=='ALG-ONLY-TARGET')\n",
    "        .then(pl.lit('AGNT'))\n",
    "        .when(pl.col('Segment')=='Target')\n",
    "        .then(pl.lit('T'))\n",
    "        .when(pl.col('Segment')=='Non-Target')\n",
    "        .then(pl.lit('NT'))\n",
    "        .alias('Segment'))\n",
    "    \n",
    "    # rearranging columns accoring to feed.\n",
    "    req_cols = ['Physician_Name', 'Physician_ID', 'Geography_id','Product_id', 'ReportType', 'Specialty', 'Segment', \n",
    "                'Urgent_Care_HCP', 'Decile', 'Address', 'City', 'State', 'Zip', 'IsPDRP', 'IMS_HCE_ID', 'NPI_ID', \n",
    "                'IBSCPrimaryPayerType', 'IC_Geography', 'AOSegment', 'Credential']\n",
    "    final_feed = final_feed.select(req_cols)#Final Dataset\n",
    "\n",
    "    final_feed = final_feed.with_columns(pl.col('IBSCPrimaryPayerType').fill_null('N/A'))\n",
    "\n",
    "    final_feed = (final_feed.filter(~(pl.col('Physician_Name').str.starts_with('ZIP'))))\n",
    "    \n",
    "    return final_feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12dda9c1-7964-40c4-ac78-9df2b3cf50b5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Presc Profile Info Exported !\n"
     ]
    }
   ],
   "source": [
    "#Exporting Feeds-\n",
    "OUT = 's3://vortex-staging-a65ced90/BIT/output/Prescriber/Monthly/'\n",
    "feed_dataset = get_feed(temp1)\n",
    "#-----------------------------------#\n",
    "feed_dataset = feed_dataset.to_pandas()\n",
    "# Select columns of type 'object' (string)\n",
    "string_columns = feed_dataset.select_dtypes(include=['object']).columns.tolist()\n",
    "feed_dataset[string_columns] = feed_dataset[string_columns].fillna('\\\\N')\n",
    "feed_dataset = feed_dataset.replace('NaN', '\\\\N')\n",
    "feed_dataset = feed_dataset.replace([np.nan, np.inf, -np.inf], '\\\\N')\n",
    "feed_dataset.to_csv(f'{OUT}Monthly_Prescriber_ProfileInfo_Feed.txt', sep='|', lineterminator='\\r\\n',index=False)\n",
    "print('Presc Profile Info Exported !')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
